{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_quantization import tensor_quant\n",
    "\n",
    "from torch import nn, outer\n",
    "\n",
    "from pytorch_quantization import tensor_quant\n",
    "import pytorch_quantization.nn as quant_nn\n",
    "import pytorch_quantization\n",
    "pytorch_quantization.__version__\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.yolo import YOLO\n",
    "from engine.detector import Detector\n",
    "from model.squeezedet import SqueezeDet, SqueezeDetWithLoss\n",
    "from utils.config import Config\n",
    "from utils.model import load_model\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from utils.misc import init_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arch                           mobilenet_v2\n",
      "batch_size                     1\n",
      "bbox_loss_weight               20.0\n",
      "chunk_sizes                    [32]\n",
      "class_loss_weight              1.0\n",
      "data_dir                       /media/gj_data/datasets\n",
      "dataset                        yolo\n",
      "debug                          0\n",
      "debug_dir                      /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib/debug\n",
      "device                         cuda\n",
      "drift_prob                     1.0\n",
      "dropout_prob                   0\n",
      "exp_dir                        /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp\n",
      "exp_id                         test_veh_det_trt_calib\n",
      "flip_prob                      0.5\n",
      "forbid_resize                  False\n",
      "gpus                           [0]\n",
      "gpus_str                       0\n",
      "grad_norm                      0.5\n",
      "keep_top_k                     64\n",
      "load_model                     ../exp/exp5_traj_sq_with_mobilenetv2_3more_IRblocks_all_data/model_best.pth\n",
      "load_pretrained                False\n",
      "log_file                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib/training_logs.txt\n",
      "lr                             0.001\n",
      "master_batch_size              32\n",
      "mode                           eval\n",
      "momentum                       0.9\n",
      "negative_score_loss_weight     100.0\n",
      "nms_thresh                     0.4\n",
      "no_eval                        False\n",
      "not_cuda_benchmark             False\n",
      "num_epochs                     100\n",
      "num_iters                      -1\n",
      "num_workers                    0\n",
      "positive_score_loss_weight     3.75\n",
      "print_interval                 20\n",
      "qat                            False\n",
      "root_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch\n",
      "save_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib\n",
      "save_intervals                 1\n",
      "score_thresh                   0.5\n",
      "seed                           42\n",
      "stride                         8\n",
      "val_intervals                  1\n",
      "weight_decay                   0.0001\n"
     ]
    }
   ],
   "source": [
    "args = {'_': '_'}\n",
    "cfg = Config().parse(args)\n",
    "\n",
    "init_env(cfg) \n",
    " \n",
    "cfg.mode = 'eval'\n",
    "cfg.exp_id = \"test_veh_det_trt_calib\"\n",
    "cfg.dataset = 'yolo'\n",
    "cfg.load_model = '../exp/exp5_traj_sq_with_mobilenetv2_3more_IRblocks_all_data/model_best.pth' \n",
    "cfg.batch_size = 1\n",
    "cfg.arch = 'mobilenet_v2'\n",
    "cfg.num_workers = 0\n",
    "cfg.save_intervals = 1\n",
    "cfg.stride = 8\n",
    "cfg.debug = 0\n",
    "\n",
    "def update_exp_dir(cfg, exp_id):\n",
    "    cfg.save_dir = os.path.join(cfg.exp_dir, exp_id)\n",
    "    os.makedirs(cfg.save_dir, exist_ok=True)\n",
    "    cfg.log_file = os.path.join(cfg.save_dir, 'training_logs.txt')\n",
    "    os.remove(cfg.log_file) if os.path.exists(cfg.log_file) else None\n",
    "    cfg.debug_dir = os.path.join(cfg.save_dir, 'debug')\n",
    "\n",
    "update_exp_dir(cfg, cfg.exp_id)\n",
    "\n",
    "Config().print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from eval import eval\n",
    "# eval(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine.detector import Detector\n",
    "from model.squeezedet import SqueezeDetWithLoss\n",
    "from utils.model import load_model\n",
    "from utils.misc import load_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchors                        [[  4.   4.  32.  20.]\n",
      " [  4.   4.  61.  42.]\n",
      " [  4.   4.  59.  97.]\n",
      " ...\n",
      " [444. 252. 160. 152.]\n",
      " [444. 252. 211. 201.]\n",
      " [444. 252. 343. 205.]]\n",
      "anchors_per_grid               9\n",
      "arch                           mobilenet_v2\n",
      "batch_size                     1\n",
      "bbox_loss_weight               20.0\n",
      "chunk_sizes                    [32]\n",
      "class_loss_weight              1.0\n",
      "class_names                    ('bike', 'car', 'bus')\n",
      "data_dir                       /media/gj_data/datasets\n",
      "dataset                        yolo\n",
      "debug                          0\n",
      "debug_dir                      /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib/debug\n",
      "device                         cuda\n",
      "drift_prob                     1.0\n",
      "dropout_prob                   0\n",
      "exp_dir                        /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp\n",
      "exp_id                         test_veh_det_trt_calib\n",
      "flip_prob                      0.5\n",
      "forbid_resize                  False\n",
      "gpus                           [0]\n",
      "gpus_str                       0\n",
      "grad_norm                      0.5\n",
      "grid_size                      (32, 56)\n",
      "input_size                     (256, 448)\n",
      "keep_top_k                     64\n",
      "load_model                     ../exp/exp5_traj_sq_with_mobilenetv2_3more_IRblocks_all_data/model_best.pth\n",
      "load_pretrained                False\n",
      "log_file                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib/training_logs.txt\n",
      "lr                             0.001\n",
      "master_batch_size              32\n",
      "mode                           eval\n",
      "momentum                       0.9\n",
      "negative_score_loss_weight     100.0\n",
      "nms_thresh                     0.4\n",
      "no_eval                        False\n",
      "not_cuda_benchmark             False\n",
      "num_anchors                    16128\n",
      "num_classes                    3\n",
      "num_epochs                     100\n",
      "num_iters                      -1\n",
      "num_workers                    0\n",
      "positive_score_loss_weight     3.75\n",
      "print_interval                 20\n",
      "qat                            False\n",
      "rgb_mean                       [[[104.90631 105.41336 104.70162]]]\n",
      "rgb_std                        [[[50.69564  49.60443  50.158844]]]\n",
      "root_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch\n",
      "save_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib\n",
      "save_intervals                 1\n",
      "score_thresh                   0.5\n",
      "seed                           42\n",
      "stride                         8\n",
      "val_intervals                  1\n",
      "weight_decay                   0.0001\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(cfg.dataset)('val', cfg)\n",
    "cfg = Config().update_dataset_info(cfg, dataset)\n",
    "Config().print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n"
     ]
    }
   ],
   "source": [
    "print (dataset.phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model ../exp/exp5_traj_sq_with_mobilenetv2_3more_IRblocks_all_data/model_best.pth, epoch 44\n",
      "Model successfully loaded.\n",
      "SqueezeDetWithLoss(\n",
      "  (base): SqueezeDetBase(\n",
      "    (quant): QuantStub()\n",
      "    (dequant): DeQuantStub()\n",
      "    (features): Sequential(\n",
      "      (0): ConvBNReLU(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (8): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (9): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (10): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (11): ConvBNReLU(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (convdet): Conv2d(256, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resolver): PredictionResolver()\n",
      "  (loss): Loss(\n",
      "    (resolver): PredictionResolver()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if cfg.mode=='eval':\n",
    "        model = SqueezeDetWithLoss(cfg)\n",
    "        model = load_model(model, cfg.load_model, cfg)\n",
    "\n",
    "\n",
    "detect = model.detect\n",
    "model.detect = True\n",
    "detector = Detector(model, cfg)\n",
    "print(detector.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)  # Disable logging as they are too noisy in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_desc_input = QuantDescriptor(calib_method='histogram')\n",
    "quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)\n",
    "quant_nn.QuantLinear.set_default_quant_desc_input(quant_desc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import quant_modules\n",
    "quant_modules.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeDetWithLoss(\n",
      "  (base): SqueezeDetBase(\n",
      "    (quant): QuantStub()\n",
      "    (dequant): DeQuantStub()\n",
      "    (features): Sequential(\n",
      "      (0): ConvBNReLU(\n",
      "        (0): QuantConv2d(\n",
      "          3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): QuantConv2d(\n",
      "            32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "          )\n",
      "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): QuantConv2d(\n",
      "            96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "          )\n",
      "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): QuantConv2d(\n",
      "            144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "          )\n",
      "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): QuantConv2d(\n",
      "            144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "          )\n",
      "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): QuantConv2d(\n",
      "            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "          )\n",
      "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): QuantConv2d(\n",
      "            192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "          )\n",
      "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): QuantConv2d(\n",
      "            192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "          )\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (8): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): QuantConv2d(\n",
      "            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "          )\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (9): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): QuantConv2d(\n",
      "            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "          )\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (10): InvertedResidual(\n",
      "        (conv): Sequential(\n",
      "          (0): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ConvBNReLU(\n",
      "            (0): QuantConv2d(\n",
      "              384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "              (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "            )\n",
      "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): QuantConv2d(\n",
      "            384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "            (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "          )\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (11): ConvBNReLU(\n",
      "        (0): QuantConv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (convdet): QuantConv2d(\n",
      "      256, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "      (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "    )\n",
      "  )\n",
      "  (resolver): PredictionResolver()\n",
      "  (loss): Loss(\n",
      "    (resolver): PredictionResolver()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(detector.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_stats(model, data_loader, num_batches):\n",
    "    \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "    # Enable calibrators\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.disable_quant()\n",
    "                module.enable_calib()\n",
    "            else:\n",
    "                module.disable()\n",
    "\n",
    "    # for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "    #     model(image.cuda())\n",
    "    #     if i >= num_batches:\n",
    "    #         break\n",
    "    # since yolo/lpr dataloader return a dict, so writing it in this way\n",
    "    for i, (batch) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "        for k in batch:\n",
    "                if 'image_meta' not in k:\n",
    "                    batch[k] = batch[k].to(device=cfg.device, non_blocking=True)\n",
    "        model(batch)\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "\n",
    "    # Disable calibrators\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.enable_quant()\n",
    "                module.disable_calib()\n",
    "            else:\n",
    "                module.enable()\n",
    "            \n",
    "def compute_amax(model, **kwargs):\n",
    "    # Load calib result\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                    module.load_calib_amax()\n",
    "                else:\n",
    "                    module.load_calib_amax(**kwargs)\n",
    "#             print(F\"{name:40}: {module}\")\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "\n",
    "from datasets.base import BaseDataset\n",
    "from utils.boxes import generate_anchors\n",
    "from PIL import Image\n",
    "from torchvision.datasets.folder import default_loader\n",
    "\n",
    "\n",
    "class YOLO_CalibTRT(BaseDataset):\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(YOLO_CalibTRT, self).__init__(phase, cfg)\n",
    "\n",
    "        self.input_size = (256, 448)  # (height, width), both dividable by 16\n",
    "        self.class_names = ('bike', 'car', 'bus')\n",
    "        # real_filtered mean and std\n",
    "        # self.rgb_mean = np.array([94.87347, 96.89165, 94.70493], dtype=np.float32).reshape(1, 1, 3)\n",
    "        # self.rgb_std = np.array([53.869507, 53.936283, 55.2807], dtype=np.float32).reshape(1, 1, 3)\n",
    "        \n",
    "        # real_filtered plus all_sites_seatbelt mean and std\n",
    "        self.rgb_mean = np.array([104.90631, 105.41336, 104.70162], dtype=np.float32).reshape(1, 1, 3)\n",
    "        self.rgb_std = np.array([50.69564, 49.60443, 50.158844], dtype=np.float32).reshape(1, 1, 3)\n",
    "        self.num_classes = len(self.class_names)\n",
    "        self.class_ids_dict = {cls_name: cls_id for cls_id, cls_name in enumerate(self.class_names)}\n",
    "\n",
    "        self.data_dir = os.path.join(cfg.data_dir, 'all_real_plus_synth_8sites_plus_SVsynth_plus_seatbelt_plus_new_trajectory_data_kitti_format_5percentofwidth_filtered')\n",
    "        self.sample_ids, self.sample_set_path = self.get_sample_ids()\n",
    "\n",
    "        self.grid_size = tuple(x //cfg.stride  for x in self.input_size)  # anchors grid \n",
    "        # self.anchors_seed = np.array([[ 29, 17], [46, 32], [69, 52],\n",
    "        #                                 [109, 68], [84, 127], [155, 106], \n",
    "        #                                 [255, 145], [183, 215], [371, 221]], dtype=np.float32) ## real_filtered anchors\n",
    "        \n",
    "        self.anchors_seed = np.array( [[ 32, 20], [ 61, 42], [ 59, 97],\n",
    "                                        [103, 66], [122, 114], [183, 96],\n",
    "                                        [160, 152], [211, 201], [343, 205]], dtype=np.float32) ## real_filtered plus all_sites_seatbelt anchors\n",
    "\n",
    "        self.anchors = generate_anchors(self.grid_size, self.input_size, self.anchors_seed)\n",
    "        self.anchors_per_grid = self.anchors_seed.shape[0]\n",
    "        self.num_anchors = self.anchors.shape[0]\n",
    "\n",
    "        self.results_dir = os.path.join(cfg.save_dir, 'results')\n",
    "\n",
    "    def get_sample_ids(self):\n",
    "        #a dirty duct tape to load preprocessing of val phase but load dataset for train phase for trt calib\n",
    "        sample_set_name = 'train.txt' if self.phase == 'train' \\\n",
    "            else 'train.txt' if self.phase == 'val' \\\n",
    "            else 'trainval.txt' if self.phase == 'trainval' \\\n",
    "            else None\n",
    "\n",
    "        sample_ids_path = os.path.join(self.data_dir, 'image_sets', sample_set_name)\n",
    "        with open(sample_ids_path, 'r') as fp:\n",
    "            sample_ids = fp.readlines()\n",
    "        sample_ids = tuple(x.strip() for x in sample_ids)\n",
    "\n",
    "        return sample_ids, sample_ids_path\n",
    "\n",
    "    def load_image(self, index):\n",
    "        image_id = self.sample_ids[index]\n",
    "        image_path = os.path.join(self.data_dir, 'training/image_2', image_id + '.jpg')\n",
    "        image = default_loader(image_path)\n",
    "        if image.mode == 'L':\n",
    "            image = image.convert('RGB')\n",
    "        image = np.array(image).astype(np.float32)\n",
    "        # image = skimage.io.imread(image_path).astype(np.float32)\n",
    "        return image, image_id\n",
    "\n",
    "    def load_annotations(self, index):\n",
    "        ann_id = self.sample_ids[index]\n",
    "        ann_path = os.path.join(self.data_dir, 'training/label_2', ann_id + '.txt')\n",
    "        with open(ann_path, 'r') as fp:\n",
    "            annotations = fp.readlines()\n",
    "\n",
    "        annotations = [ann.strip().split(' ') for ann in annotations]\n",
    "        class_ids, boxes = [], []\n",
    "        for ann in annotations:\n",
    "            if ann[0] not in self.class_names:\n",
    "                continue\n",
    "            class_ids.append(self.class_ids_dict[ann[0]])\n",
    "            box = [float(x) for x in ann[4:8]]\n",
    "            # if box[2] <= 0:\n",
    "            #     box[2] = 0.00001\n",
    "            # if box[3] <= 0:\n",
    "            #     box[3] = 0.00001\n",
    "            boxes.append(box)\n",
    "\n",
    "        class_ids = np.array(class_ids, dtype=np.int16)\n",
    "        boxes = np.array(boxes, dtype=np.float32)\n",
    "        if len(boxes):\n",
    "            return class_ids, boxes\n",
    "        boxes = None\n",
    "        return class_ids, boxes\n",
    "\n",
    "    # ========================================\n",
    "    #                evaluation\n",
    "    # ========================================\n",
    "\n",
    "    def save_results(self, results):\n",
    "        txt_dir = os.path.join(self.results_dir, 'data')\n",
    "        os.makedirs(txt_dir, exist_ok=True)\n",
    "\n",
    "        for res in results:\n",
    "            txt_path = os.path.join(txt_dir, res['image_meta']['image_id'] + '.txt')\n",
    "            if 'class_ids' not in res:\n",
    "                with open(txt_path, 'w') as fp:\n",
    "                    fp.write('')\n",
    "                continue\n",
    "\n",
    "            num_boxes = len(res['class_ids'])\n",
    "            with open(txt_path, 'w') as fp:\n",
    "                for i in range(num_boxes):\n",
    "                    class_name = self.class_names[res['class_ids'][i]].lower()\n",
    "                    score = res['scores'][i]\n",
    "                    bbox = res['boxes'][i, :]\n",
    "                    line = '{} -1 -1 0 {:.2f} {:.2f} {:.2f} {:.2f} 0 0 0 0 0 0 0 {:.3f}\\n'.format(\n",
    "                            class_name, *bbox, score)\n",
    "                    fp.write(line)\n",
    "\n",
    "    def evaluate(self):\n",
    "        kitti_eval_tool_path = os.path.join(self.cfg.root_dir, 'src/utils/kitti-eval/cpp/evaluate_object')\n",
    "        cmd = '{} {} {} {} {}'.format(kitti_eval_tool_path,\n",
    "                                      os.path.join(self.data_dir, 'training'),\n",
    "                                      self.sample_set_path,\n",
    "                                      self.results_dir,\n",
    "                                      len(self.sample_ids))\n",
    "\n",
    "        status = subprocess.call(cmd, shell=True)\n",
    "\n",
    "        aps = {}\n",
    "        for class_name in self.class_names:\n",
    "            map_path = os.path.join(self.results_dir, 'stats_{}_ap.txt'.format(class_name.lower()))\n",
    "            if os.path.exists(map_path):\n",
    "                with open(map_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                _aps = [float(line.split('=')[1].strip()) for line in lines]\n",
    "            else:\n",
    "                _aps = [0., 0., 0.]\n",
    "\n",
    "            aps[class_name + '_easy'] = _aps[0]\n",
    "            aps[class_name + '_moderate'] = _aps[1]\n",
    "            aps[class_name + '_hard'] = _aps[2]\n",
    "\n",
    "        aps['mAP'] = sum(aps.values()) / len(aps)\n",
    "\n",
    "        return aps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh_det_calib_dataset = YOLO_CalibTRT('val', cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_data_loader = torch.utils.data.DataLoader(veh_det_calib_dataset,\n",
    "                                                  batch_size=cfg.batch_size,\n",
    "                                                  num_workers=cfg.num_workers,\n",
    "                                                  pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (len(calib_data_loader))\n",
    "# inp  = next(iter(calib_data_loader))\n",
    "# print(inp['image'].shape)\n",
    "\n",
    "# for i, inp in enumerate(calib_data_loader, 0):\n",
    "#         print(inp['image'].shape)\n",
    "#         if i >= 10:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0815 14:48:31.602073 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.602469 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.602790 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.603070 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.603579 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.603878 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.604161 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.604446 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.604721 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.604993 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.605275 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.605566 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.605890 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.606189 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.606473 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.606964 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.607290 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.607568 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.607838 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.608114 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.608388 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.608651 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.608923 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.609178 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.609466 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.609722 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.609993 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.611321 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.611615 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.611876 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.612225 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.612562 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.612869 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.613160 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.613512 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.613819 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.614122 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.614504 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.614878 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.615773 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.616194 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.616511 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.616837 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.617157 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.617468 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.617822 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.618111 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.618401 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.619139 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.619439 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.619732 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.620003 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.620280 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.620544 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.620807 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.621067 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.621335 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.621594 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.621863 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.622111 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.622405 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.622663 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.622924 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.623182 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.623450 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.623707 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.623966 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.624227 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.624498 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.624754 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.625023 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.625277 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.625552 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.625803 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.626063 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.626336 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.626616 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.626880 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.627150 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.627506 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.629384 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.629728 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.630048 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.630352 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.630653 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.630933 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.631213 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.631483 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.631769 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.632475 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.632752 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.633027 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.633300 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.633565 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.633846 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.634111 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.634404 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.634846 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.635692 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.636022 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.636342 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.636668 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.637192 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.637486 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.637773 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.638055 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.638335 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.638607 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.638896 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.639164 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.642090 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.642408 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.642777 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.643086 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.643461 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.643744 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.644037 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.644308 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.644577 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.644852 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.645130 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.645416 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.646145 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.646439 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0815 14:48:31.646727 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.647002 140279568199872 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0815 14:48:31.647277 140279568199872 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0815 14:48:31.647621 140279568199872 tensor_quantizer.py:179] Enable MaxCalibrator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/90000 [00:00<?, ?it/s]I0815 14:48:31.795305 140279568199872 histogram.py:69] Calibrator encountered negative values. It shouldn't happen after ReLU. Make sure this is the right tensor to calibrate.\n",
      "I0815 14:48:31.802578 140279568199872 max.py:60] Calibrator encountered negative values. It shouldn't happen after ReLU. Make sure this is the right tensor to calibrate.\n",
      "  0%|          | 106/90000 [01:26<20:16:24,  1.23it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb#ch0000019?line=3'>4</a>\u001b[0m detector\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb#ch0000019?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb#ch0000019?line=5'>6</a>\u001b[0m     collect_stats(detector\u001b[39m.\u001b[39;49mmodel, calib_data_loader, num_batches\u001b[39m=\u001b[39;49m\u001b[39m90000\u001b[39;49m)\n",
      "\u001b[1;32m/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb Cell 20\u001b[0m in \u001b[0;36mcollect_stats\u001b[0;34m(model, data_loader, num_batches)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb#ch0000019?line=10'>11</a>\u001b[0m             module\u001b[39m.\u001b[39mdisable()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb#ch0000019?line=12'>13</a>\u001b[0m \u001b[39m# for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb#ch0000019?line=13'>14</a>\u001b[0m \u001b[39m#     model(image.cuda())\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb#ch0000019?line=14'>15</a>\u001b[0m \u001b[39m#     if i >= num_batches:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb#ch0000019?line=15'>16</a>\u001b[0m \u001b[39m#         break\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb#ch0000019?line=16'>17</a>\u001b[0m \u001b[39m# since yolo/lpr dataloader return a dict, so writing it in this way\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb#ch0000019?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (batch) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(data_loader), total\u001b[39m=\u001b[39mnum_batches):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb#ch0000019?line=18'>19</a>\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m batch:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/veh_det_trt_calib.ipynb#ch0000019?line=19'>20</a>\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mimage_meta\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m k:\n",
      "File \u001b[0;32m~/anaconda3/envs/squeezedet_qat_trt/lib/python3.8/site-packages/tqdm/std.py:1180\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1177\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1179\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1180\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1181\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1182\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/squeezedet_qat_trt/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/squeezedet_qat_trt/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/squeezedet_qat_trt/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/squeezedet_qat_trt/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/datasets/base.py:146\u001b[0m, in \u001b[0;36mBaseDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    140\u001b[0m gt_class_ids, gt_boxes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_annotations(index)\n\u001b[1;32m    142\u001b[0m image_meta \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m: index,\n\u001b[1;32m    143\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mimage_id\u001b[39m\u001b[39m'\u001b[39m: image_id,\n\u001b[1;32m    144\u001b[0m               \u001b[39m'\u001b[39m\u001b[39morig_size\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39marray(image\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)}\n\u001b[0;32m--> 146\u001b[0m image, image_visualize, image_meta, gt_boxes, gt_class_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess(image, image_meta, gt_boxes, gt_class_ids)\n\u001b[1;32m    147\u001b[0m gt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_annotations(gt_class_ids, gt_boxes)\n\u001b[1;32m    149\u001b[0m inp \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m: image,\n\u001b[1;32m    150\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mimage_meta\u001b[39m\u001b[39m'\u001b[39m: image_meta,\n\u001b[1;32m    151\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mgt\u001b[39m\u001b[39m'\u001b[39m: gt}\n",
      "File \u001b[0;32m~/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/datasets/base.py:203\u001b[0m, in \u001b[0;36mBaseDataset.preprocess\u001b[0;34m(self, image, image_meta, boxes, class_ids)\u001b[0m\n\u001b[1;32m    201\u001b[0m drift_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mdrift_prob \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mphase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0.\u001b[39m\n\u001b[1;32m    202\u001b[0m flip_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mflip_prob \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mphase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0.\u001b[39m\n\u001b[0;32m--> 203\u001b[0m image, image_meta \u001b[39m=\u001b[39m whiten(image, image_meta, mean\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrgb_mean, std\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrgb_std)\n\u001b[1;32m    204\u001b[0m image, image_meta, boxes \u001b[39m=\u001b[39m drift(image, image_meta, prob\u001b[39m=\u001b[39mdrift_prob, boxes\u001b[39m=\u001b[39mboxes)\n\u001b[1;32m    205\u001b[0m image, image_meta, boxes \u001b[39m=\u001b[39m flip(image, image_meta, prob\u001b[39m=\u001b[39mflip_prob, boxes\u001b[39m=\u001b[39mboxes)\n",
      "File \u001b[0;32m~/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/utils/image.py:17\u001b[0m, in \u001b[0;36mwhiten\u001b[0;34m(image, image_meta, mean, std)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwhiten\u001b[39m(image, image_meta, mean\u001b[39m=\u001b[39m\u001b[39m0.\u001b[39m, std\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m):\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m    :param image:\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m    :param image_meta:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m    :return:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     image \u001b[39m=\u001b[39m (image \u001b[39m-\u001b[39;49m mean) \u001b[39m/\u001b[39m std\n\u001b[1;32m     18\u001b[0m     image_meta\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mrgb_mean\u001b[39m\u001b[39m'\u001b[39m: mean, \u001b[39m'\u001b[39m\u001b[39mrgb_std\u001b[39m\u001b[39m'\u001b[39m: std})\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m image, image_meta\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_batches = int(len(veh_det_calib_dataset)/cfg.batch_size)\n",
    "print (num_batches)\n",
    "detector.model.eval()\n",
    "detector.model.cuda()\n",
    "with torch.no_grad():\n",
    "    collect_stats(detector.model, calib_data_loader, num_batches=90000)\n",
    "    # compute_amax(detector.model, method=\"percentile\", percentile=99.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (detector.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Different Scehmes and Eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.yolo import YOLO\n",
    "\n",
    "eval_dataset = YOLO('val', cfg)\n",
    "eval_dataset.phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 22:26:18.437037 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.437908 140513235423424 tensor_quantizer.py:238] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "W0813 22:26:18.438462 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 22:26:18.439009 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.439319 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 22:26:18.439835 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.440207 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0813 22:26:18.440666 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.440975 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([96, 1, 1, 1]).\n",
      "W0813 22:26:18.441492 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.441782 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([96, 1, 1, 1]).\n",
      "W0813 22:26:18.442301 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.442604 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([24, 1, 1, 1]).\n",
      "W0813 22:26:18.443115 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.443408 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([144, 1, 1, 1]).\n",
      "W0813 22:26:18.443909 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.444212 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([144, 1, 1, 1]).\n",
      "W0813 22:26:18.444729 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.445106 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([24, 1, 1, 1]).\n",
      "W0813 22:26:18.445566 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.445944 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([144, 1, 1, 1]).\n",
      "W0813 22:26:18.446394 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.446691 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([144, 1, 1, 1]).\n",
      "W0813 22:26:18.447197 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.447595 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 22:26:18.448097 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.448421 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 22:26:18.448974 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.449281 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 22:26:18.449808 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.450118 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 22:26:18.450594 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.450963 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 22:26:18.451591 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.451910 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 22:26:18.452439 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.452744 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 22:26:18.453320 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.453620 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 22:26:18.454142 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.454442 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 22:26:18.454944 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.455230 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0813 22:26:18.455744 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.456039 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 22:26:18.456553 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.456869 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 22:26:18.457327 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.457761 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0813 22:26:18.458297 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.458619 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 22:26:18.459144 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.459449 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 22:26:18.459939 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.460229 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0813 22:26:18.460777 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.461212 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 22:26:18.461761 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.462083 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 22:26:18.462625 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.463316 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0813 22:26:18.463952 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.464292 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0813 22:26:18.464820 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:26:18.465121 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([72, 1, 1, 1]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ############  percentile calibration ######################\n",
      "eval: [0/7902] | data 0.100s | net 0.040s\n",
      "eval: [20/7902] | data 0.072s | net 0.024s\n",
      "eval: [40/7902] | data 0.100s | net 0.025s\n",
      "eval: [60/7902] | data 0.046s | net 0.023s\n",
      "eval: [80/7902] | data 0.085s | net 0.023s\n",
      "eval: [100/7902] | data 0.084s | net 0.022s\n",
      "eval: [120/7902] | data 0.083s | net 0.022s\n",
      "eval: [140/7902] | data 0.081s | net 0.022s\n",
      "eval: [160/7902] | data 0.093s | net 0.022s\n",
      "eval: [180/7902] | data 0.078s | net 0.023s\n",
      "eval: [200/7902] | data 0.110s | net 0.024s\n",
      "eval: [220/7902] | data 0.100s | net 0.023s\n",
      "eval: [240/7902] | data 0.098s | net 0.024s\n",
      "eval: [260/7902] | data 0.078s | net 0.023s\n",
      "eval: [280/7902] | data 0.079s | net 0.023s\n",
      "eval: [300/7902] | data 0.083s | net 0.023s\n",
      "eval: [320/7902] | data 0.106s | net 0.023s\n",
      "eval: [340/7902] | data 0.083s | net 0.023s\n",
      "eval: [360/7902] | data 0.079s | net 0.023s\n",
      "eval: [380/7902] | data 0.080s | net 0.023s\n",
      "eval: [400/7902] | data 0.094s | net 0.024s\n",
      "eval: [420/7902] | data 0.103s | net 0.023s\n",
      "eval: [440/7902] | data 0.075s | net 0.023s\n",
      "eval: [460/7902] | data 0.027s | net 0.023s\n",
      "eval: [480/7902] | data 0.017s | net 0.023s\n",
      "eval: [500/7902] | data 0.019s | net 0.023s\n",
      "eval: [520/7902] | data 0.018s | net 0.024s\n",
      "eval: [540/7902] | data 0.018s | net 0.023s\n",
      "eval: [560/7902] | data 0.017s | net 0.023s\n",
      "eval: [580/7902] | data 0.018s | net 0.023s\n",
      "eval: [600/7902] | data 0.018s | net 0.023s\n",
      "eval: [620/7902] | data 0.017s | net 0.023s\n",
      "eval: [640/7902] | data 0.017s | net 0.023s\n",
      "eval: [660/7902] | data 0.017s | net 0.023s\n",
      "eval: [680/7902] | data 0.022s | net 0.023s\n",
      "eval: [700/7902] | data 0.018s | net 0.024s\n",
      "eval: [720/7902] | data 0.017s | net 0.023s\n",
      "eval: [740/7902] | data 0.018s | net 0.023s\n",
      "eval: [760/7902] | data 0.018s | net 0.023s\n",
      "eval: [780/7902] | data 0.018s | net 0.023s\n",
      "eval: [800/7902] | data 0.018s | net 0.023s\n",
      "eval: [820/7902] | data 0.018s | net 0.023s\n",
      "eval: [840/7902] | data 0.023s | net 0.025s\n",
      "eval: [860/7902] | data 0.018s | net 0.023s\n",
      "eval: [880/7902] | data 0.018s | net 0.023s\n",
      "eval: [900/7902] | data 0.018s | net 0.023s\n",
      "eval: [920/7902] | data 0.017s | net 0.023s\n",
      "eval: [940/7902] | data 0.018s | net 0.023s\n",
      "eval: [960/7902] | data 0.018s | net 0.023s\n",
      "eval: [980/7902] | data 0.021s | net 0.024s\n",
      "eval: [1000/7902] | data 0.018s | net 0.023s\n",
      "eval: [1020/7902] | data 0.017s | net 0.023s\n",
      "eval: [1040/7902] | data 0.017s | net 0.023s\n",
      "eval: [1060/7902] | data 0.018s | net 0.023s\n",
      "eval: [1080/7902] | data 0.022s | net 0.024s\n",
      "eval: [1100/7902] | data 0.030s | net 0.023s\n",
      "eval: [1120/7902] | data 0.021s | net 0.024s\n",
      "eval: [1140/7902] | data 0.018s | net 0.023s\n",
      "eval: [1160/7902] | data 0.018s | net 0.023s\n",
      "eval: [1180/7902] | data 0.018s | net 0.023s\n",
      "eval: [1200/7902] | data 0.017s | net 0.023s\n",
      "eval: [1220/7902] | data 0.018s | net 0.023s\n",
      "eval: [1240/7902] | data 0.018s | net 0.023s\n",
      "eval: [1260/7902] | data 0.017s | net 0.023s\n",
      "eval: [1280/7902] | data 0.017s | net 0.024s\n",
      "eval: [1300/7902] | data 0.017s | net 0.023s\n",
      "eval: [1320/7902] | data 0.019s | net 0.023s\n",
      "eval: [1340/7902] | data 0.017s | net 0.023s\n",
      "eval: [1360/7902] | data 0.017s | net 0.023s\n",
      "eval: [1380/7902] | data 0.018s | net 0.023s\n",
      "eval: [1400/7902] | data 0.022s | net 0.025s\n",
      "eval: [1420/7902] | data 0.018s | net 0.025s\n",
      "eval: [1440/7902] | data 0.018s | net 0.023s\n",
      "eval: [1460/7902] | data 0.012s | net 0.023s\n",
      "eval: [1480/7902] | data 0.013s | net 0.023s\n",
      "eval: [1500/7902] | data 0.013s | net 0.023s\n",
      "eval: [1520/7902] | data 0.012s | net 0.024s\n",
      "eval: [1540/7902] | data 0.011s | net 0.023s\n",
      "eval: [1560/7902] | data 0.012s | net 0.023s\n",
      "eval: [1580/7902] | data 0.011s | net 0.023s\n",
      "eval: [1600/7902] | data 0.012s | net 0.024s\n",
      "eval: [1620/7902] | data 0.011s | net 0.023s\n",
      "eval: [1640/7902] | data 0.011s | net 0.023s\n",
      "eval: [1660/7902] | data 0.014s | net 0.025s\n",
      "eval: [1680/7902] | data 0.012s | net 0.023s\n",
      "eval: [1700/7902] | data 0.011s | net 0.023s\n",
      "eval: [1720/7902] | data 0.013s | net 0.023s\n",
      "eval: [1740/7902] | data 0.013s | net 0.024s\n",
      "eval: [1760/7902] | data 0.011s | net 0.024s\n",
      "eval: [1780/7902] | data 0.011s | net 0.023s\n",
      "eval: [1800/7902] | data 0.011s | net 0.023s\n",
      "eval: [1820/7902] | data 0.012s | net 0.023s\n",
      "eval: [1840/7902] | data 0.011s | net 0.023s\n",
      "eval: [1860/7902] | data 0.011s | net 0.023s\n",
      "eval: [1880/7902] | data 0.014s | net 0.025s\n",
      "eval: [1900/7902] | data 0.012s | net 0.024s\n",
      "eval: [1920/7902] | data 0.012s | net 0.023s\n",
      "eval: [1940/7902] | data 0.011s | net 0.023s\n",
      "eval: [1960/7902] | data 0.012s | net 0.025s\n",
      "eval: [1980/7902] | data 0.012s | net 0.024s\n",
      "eval: [2000/7902] | data 0.011s | net 0.023s\n",
      "eval: [2020/7902] | data 0.011s | net 0.023s\n",
      "eval: [2040/7902] | data 0.011s | net 0.023s\n",
      "eval: [2060/7902] | data 0.011s | net 0.024s\n",
      "eval: [2080/7902] | data 0.011s | net 0.023s\n",
      "eval: [2100/7902] | data 0.014s | net 0.025s\n",
      "eval: [2120/7902] | data 0.011s | net 0.024s\n",
      "eval: [2140/7902] | data 0.011s | net 0.023s\n",
      "eval: [2160/7902] | data 0.012s | net 0.024s\n",
      "eval: [2180/7902] | data 0.011s | net 0.025s\n",
      "eval: [2200/7902] | data 0.013s | net 0.023s\n",
      "eval: [2220/7902] | data 0.011s | net 0.024s\n",
      "eval: [2240/7902] | data 0.011s | net 0.023s\n",
      "eval: [2260/7902] | data 0.011s | net 0.023s\n",
      "eval: [2280/7902] | data 0.011s | net 0.023s\n",
      "eval: [2300/7902] | data 0.012s | net 0.023s\n",
      "eval: [2320/7902] | data 0.011s | net 0.023s\n",
      "eval: [2340/7902] | data 0.011s | net 0.023s\n",
      "eval: [2360/7902] | data 0.011s | net 0.023s\n",
      "eval: [2380/7902] | data 0.012s | net 0.023s\n",
      "eval: [2400/7902] | data 0.012s | net 0.024s\n",
      "eval: [2420/7902] | data 0.011s | net 0.023s\n",
      "eval: [2440/7902] | data 0.011s | net 0.023s\n",
      "eval: [2460/7902] | data 0.037s | net 0.025s\n",
      "eval: [2480/7902] | data 0.059s | net 0.024s\n",
      "eval: [2500/7902] | data 0.057s | net 0.023s\n",
      "eval: [2520/7902] | data 0.052s | net 0.023s\n",
      "eval: [2540/7902] | data 0.054s | net 0.023s\n",
      "eval: [2560/7902] | data 0.054s | net 0.023s\n",
      "eval: [2580/7902] | data 0.055s | net 0.023s\n",
      "eval: [2600/7902] | data 0.053s | net 0.023s\n",
      "eval: [2620/7902] | data 0.056s | net 0.023s\n",
      "eval: [2640/7902] | data 0.029s | net 0.023s\n",
      "eval: [2660/7902] | data 0.054s | net 0.022s\n",
      "eval: [2680/7902] | data 0.067s | net 0.023s\n",
      "eval: [2700/7902] | data 0.031s | net 0.023s\n",
      "eval: [2720/7902] | data 0.029s | net 0.023s\n",
      "eval: [2740/7902] | data 0.053s | net 0.023s\n",
      "eval: [2760/7902] | data 0.057s | net 0.023s\n",
      "eval: [2780/7902] | data 0.056s | net 0.023s\n",
      "eval: [2800/7902] | data 0.054s | net 0.023s\n",
      "eval: [2820/7902] | data 0.053s | net 0.023s\n",
      "eval: [2840/7902] | data 0.055s | net 0.023s\n",
      "eval: [2860/7902] | data 0.052s | net 0.024s\n",
      "eval: [2880/7902] | data 0.051s | net 0.023s\n",
      "eval: [2900/7902] | data 0.029s | net 0.023s\n",
      "eval: [2920/7902] | data 0.051s | net 0.022s\n",
      "eval: [2940/7902] | data 0.053s | net 0.023s\n",
      "eval: [2960/7902] | data 0.056s | net 0.023s\n",
      "eval: [2980/7902] | data 0.059s | net 0.023s\n",
      "eval: [3000/7902] | data 0.021s | net 0.023s\n",
      "eval: [3020/7902] | data 0.057s | net 0.023s\n",
      "eval: [3040/7902] | data 0.054s | net 0.023s\n",
      "eval: [3060/7902] | data 0.050s | net 0.023s\n",
      "eval: [3080/7902] | data 0.056s | net 0.023s\n",
      "eval: [3100/7902] | data 0.050s | net 0.023s\n",
      "eval: [3120/7902] | data 0.058s | net 0.023s\n",
      "eval: [3140/7902] | data 0.056s | net 0.023s\n",
      "eval: [3160/7902] | data 0.052s | net 0.023s\n",
      "eval: [3180/7902] | data 0.078s | net 0.023s\n",
      "eval: [3200/7902] | data 0.055s | net 0.022s\n",
      "eval: [3220/7902] | data 0.052s | net 0.023s\n",
      "eval: [3240/7902] | data 0.056s | net 0.023s\n",
      "eval: [3260/7902] | data 0.054s | net 0.023s\n",
      "eval: [3280/7902] | data 0.056s | net 0.023s\n",
      "eval: [3300/7902] | data 0.053s | net 0.023s\n",
      "eval: [3320/7902] | data 0.030s | net 0.023s\n",
      "eval: [3340/7902] | data 0.048s | net 0.023s\n",
      "eval: [3360/7902] | data 0.071s | net 0.023s\n",
      "eval: [3380/7902] | data 0.029s | net 0.023s\n",
      "eval: [3400/7902] | data 0.054s | net 0.023s\n",
      "eval: [3420/7902] | data 0.022s | net 0.023s\n",
      "eval: [3440/7902] | data 0.052s | net 0.023s\n",
      "eval: [3460/7902] | data 0.091s | net 0.024s\n",
      "eval: [3480/7902] | data 0.056s | net 0.024s\n",
      "eval: [3500/7902] | data 0.063s | net 0.023s\n",
      "eval: [3520/7902] | data 0.055s | net 0.023s\n",
      "eval: [3540/7902] | data 0.055s | net 0.024s\n",
      "eval: [3560/7902] | data 0.062s | net 0.024s\n",
      "eval: [3580/7902] | data 0.054s | net 0.023s\n",
      "eval: [3600/7902] | data 0.060s | net 0.023s\n",
      "eval: [3620/7902] | data 0.073s | net 0.024s\n",
      "eval: [3640/7902] | data 0.055s | net 0.023s\n",
      "eval: [3660/7902] | data 0.062s | net 0.024s\n",
      "eval: [3680/7902] | data 0.055s | net 0.023s\n",
      "eval: [3700/7902] | data 0.059s | net 0.023s\n",
      "eval: [3720/7902] | data 0.038s | net 0.022s\n",
      "eval: [3740/7902] | data 0.043s | net 0.025s\n",
      "eval: [3760/7902] | data 0.060s | net 0.023s\n",
      "eval: [3780/7902] | data 0.035s | net 0.023s\n",
      "eval: [3800/7902] | data 0.034s | net 0.023s\n",
      "eval: [3820/7902] | data 0.043s | net 0.025s\n",
      "eval: [3840/7902] | data 0.049s | net 0.023s\n",
      "eval: [3860/7902] | data 0.036s | net 0.023s\n",
      "eval: [3880/7902] | data 0.038s | net 0.023s\n",
      "eval: [3900/7902] | data 0.047s | net 0.023s\n",
      "eval: [3920/7902] | data 0.047s | net 0.023s\n",
      "eval: [3940/7902] | data 0.037s | net 0.024s\n",
      "eval: [3960/7902] | data 0.061s | net 0.023s\n",
      "eval: [3980/7902] | data 0.035s | net 0.024s\n",
      "eval: [4000/7902] | data 0.035s | net 0.023s\n",
      "eval: [4020/7902] | data 0.042s | net 0.025s\n",
      "eval: [4040/7902] | data 0.034s | net 0.022s\n",
      "eval: [4060/7902] | data 0.035s | net 0.023s\n",
      "eval: [4080/7902] | data 0.042s | net 0.023s\n",
      "eval: [4100/7902] | data 0.034s | net 0.023s\n",
      "eval: [4120/7902] | data 0.034s | net 0.023s\n",
      "eval: [4140/7902] | data 0.056s | net 0.023s\n",
      "eval: [4160/7902] | data 0.034s | net 0.025s\n",
      "eval: [4180/7902] | data 0.034s | net 0.023s\n",
      "eval: [4200/7902] | data 0.036s | net 0.023s\n",
      "eval: [4220/7902] | data 0.058s | net 0.023s\n",
      "eval: [4240/7902] | data 0.045s | net 0.025s\n",
      "eval: [4260/7902] | data 0.047s | net 0.023s\n",
      "eval: [4280/7902] | data 0.035s | net 0.023s\n",
      "eval: [4300/7902] | data 0.033s | net 0.023s\n",
      "eval: [4320/7902] | data 0.048s | net 0.023s\n",
      "eval: [4340/7902] | data 0.035s | net 0.023s\n",
      "eval: [4360/7902] | data 0.034s | net 0.024s\n",
      "eval: [4380/7902] | data 0.050s | net 0.023s\n",
      "eval: [4400/7902] | data 0.079s | net 0.025s\n",
      "eval: [4420/7902] | data 0.045s | net 0.025s\n",
      "eval: [4440/7902] | data 0.038s | net 0.023s\n",
      "eval: [4460/7902] | data 0.052s | net 0.158s\n",
      "eval: [4480/7902] | data 0.048s | net 0.025s\n",
      "eval: [4500/7902] | data 0.047s | net 0.026s\n",
      "eval: [4520/7902] | data 0.049s | net 0.025s\n",
      "eval: [4540/7902] | data 0.050s | net 0.026s\n",
      "eval: [4560/7902] | data 0.052s | net 0.026s\n",
      "eval: [4580/7902] | data 0.053s | net 0.025s\n",
      "eval: [4600/7902] | data 0.061s | net 0.027s\n",
      "eval: [4620/7902] | data 0.047s | net 0.026s\n",
      "eval: [4640/7902] | data 0.063s | net 0.026s\n",
      "eval: [4660/7902] | data 0.036s | net 0.023s\n",
      "eval: [4680/7902] | data 0.040s | net 0.023s\n",
      "eval: [4700/7902] | data 0.041s | net 0.023s\n",
      "eval: [4720/7902] | data 0.067s | net 0.023s\n",
      "eval: [4740/7902] | data 0.063s | net 0.023s\n",
      "eval: [4760/7902] | data 0.073s | net 0.023s\n",
      "eval: [4780/7902] | data 0.067s | net 0.023s\n",
      "eval: [4800/7902] | data 0.026s | net 0.023s\n",
      "eval: [4820/7902] | data 0.062s | net 0.023s\n",
      "eval: [4840/7902] | data 0.062s | net 0.023s\n",
      "eval: [4860/7902] | data 0.055s | net 0.023s\n",
      "eval: [4880/7902] | data 0.053s | net 0.023s\n",
      "eval: [4900/7902] | data 0.055s | net 0.022s\n",
      "eval: [4920/7902] | data 0.057s | net 0.022s\n",
      "eval: [4940/7902] | data 0.025s | net 0.022s\n",
      "eval: [4960/7902] | data 0.060s | net 0.023s\n",
      "eval: [4980/7902] | data 0.102s | net 0.023s\n",
      "eval: [5000/7902] | data 0.090s | net 0.023s\n",
      "eval: [5020/7902] | data 0.125s | net 0.022s\n",
      "eval: [5040/7902] | data 0.084s | net 0.023s\n",
      "eval: [5060/7902] | data 0.120s | net 0.023s\n",
      "eval: [5080/7902] | data 0.098s | net 0.023s\n",
      "eval: [5100/7902] | data 0.118s | net 0.025s\n",
      "eval: [5120/7902] | data 0.092s | net 0.023s\n",
      "eval: [5140/7902] | data 0.092s | net 0.023s\n",
      "eval: [5160/7902] | data 0.096s | net 0.023s\n",
      "eval: [5180/7902] | data 0.096s | net 0.023s\n",
      "eval: [5200/7902] | data 0.233s | net 0.023s\n",
      "eval: [5220/7902] | data 0.235s | net 0.023s\n",
      "eval: [5240/7902] | data 0.236s | net 0.022s\n",
      "eval: [5260/7902] | data 0.233s | net 0.022s\n",
      "eval: [5280/7902] | data 0.232s | net 0.022s\n",
      "eval: [5300/7902] | data 0.236s | net 0.022s\n",
      "eval: [5320/7902] | data 0.232s | net 0.022s\n",
      "eval: [5340/7902] | data 0.238s | net 0.023s\n",
      "eval: [5360/7902] | data 0.237s | net 0.023s\n",
      "eval: [5380/7902] | data 0.231s | net 0.024s\n",
      "eval: [5400/7902] | data 0.252s | net 0.026s\n",
      "eval: [5420/7902] | data 0.257s | net 0.023s\n",
      "eval: [5440/7902] | data 0.229s | net 0.022s\n",
      "eval: [5460/7902] | data 0.229s | net 0.023s\n",
      "eval: [5480/7902] | data 0.228s | net 0.022s\n",
      "eval: [5500/7902] | data 0.244s | net 0.022s\n",
      "eval: [5520/7902] | data 0.242s | net 0.022s\n",
      "eval: [5540/7902] | data 0.243s | net 0.022s\n",
      "eval: [5560/7902] | data 0.274s | net 0.022s\n",
      "eval: [5580/7902] | data 0.233s | net 0.022s\n",
      "eval: [5600/7902] | data 0.033s | net 0.023s\n",
      "eval: [5620/7902] | data 0.032s | net 0.022s\n",
      "eval: [5640/7902] | data 0.058s | net 0.023s\n",
      "eval: [5660/7902] | data 0.036s | net 0.023s\n",
      "eval: [5680/7902] | data 0.033s | net 0.024s\n",
      "eval: [5700/7902] | data 0.038s | net 0.023s\n",
      "eval: [5720/7902] | data 0.073s | net 0.024s\n",
      "eval: [5740/7902] | data 0.032s | net 0.023s\n",
      "eval: [5760/7902] | data 0.032s | net 0.022s\n",
      "eval: [5780/7902] | data 0.033s | net 0.025s\n",
      "eval: [5800/7902] | data 0.071s | net 0.024s\n",
      "eval: [5820/7902] | data 0.039s | net 0.023s\n",
      "eval: [5840/7902] | data 0.033s | net 0.024s\n",
      "eval: [5860/7902] | data 0.033s | net 0.022s\n",
      "eval: [5880/7902] | data 0.040s | net 0.023s\n",
      "eval: [5900/7902] | data 0.067s | net 0.024s\n",
      "eval: [5920/7902] | data 0.032s | net 0.023s\n",
      "eval: [5940/7902] | data 0.049s | net 0.023s\n",
      "eval: [5960/7902] | data 0.062s | net 0.025s\n",
      "eval: [5980/7902] | data 0.052s | net 0.023s\n",
      "eval: [6000/7902] | data 0.048s | net 0.023s\n",
      "eval: [6020/7902] | data 0.053s | net 0.023s\n",
      "eval: [6040/7902] | data 0.052s | net 0.023s\n",
      "eval: [6060/7902] | data 0.066s | net 0.023s\n",
      "eval: [6080/7902] | data 0.050s | net 0.023s\n",
      "eval: [6100/7902] | data 0.049s | net 0.023s\n",
      "eval: [6120/7902] | data 0.056s | net 0.024s\n",
      "eval: [6140/7902] | data 0.064s | net 0.023s\n",
      "eval: [6160/7902] | data 0.049s | net 0.023s\n",
      "eval: [6180/7902] | data 0.053s | net 0.023s\n",
      "eval: [6200/7902] | data 0.056s | net 0.022s\n",
      "eval: [6220/7902] | data 0.053s | net 0.023s\n",
      "eval: [6240/7902] | data 0.062s | net 0.023s\n",
      "eval: [6260/7902] | data 0.057s | net 0.023s\n",
      "eval: [6280/7902] | data 0.058s | net 0.024s\n",
      "eval: [6300/7902] | data 0.055s | net 0.023s\n",
      "eval: [6320/7902] | data 0.054s | net 0.023s\n",
      "eval: [6340/7902] | data 0.056s | net 0.023s\n",
      "eval: [6360/7902] | data 0.057s | net 0.023s\n",
      "eval: [6380/7902] | data 0.061s | net 0.023s\n",
      "eval: [6400/7902] | data 0.059s | net 0.023s\n",
      "eval: [6420/7902] | data 0.060s | net 0.023s\n",
      "eval: [6440/7902] | data 0.074s | net 0.023s\n",
      "eval: [6460/7902] | data 0.059s | net 0.023s\n",
      "eval: [6480/7902] | data 0.063s | net 0.023s\n",
      "eval: [6500/7902] | data 0.070s | net 0.024s\n",
      "eval: [6520/7902] | data 0.058s | net 0.023s\n",
      "eval: [6540/7902] | data 0.062s | net 0.023s\n",
      "eval: [6560/7902] | data 0.063s | net 0.023s\n",
      "eval: [6580/7902] | data 0.070s | net 0.023s\n",
      "eval: [6600/7902] | data 0.064s | net 0.023s\n",
      "eval: [6620/7902] | data 0.063s | net 0.022s\n",
      "eval: [6640/7902] | data 0.070s | net 0.023s\n",
      "eval: [6660/7902] | data 0.072s | net 0.023s\n",
      "eval: [6680/7902] | data 0.072s | net 0.023s\n",
      "eval: [6700/7902] | data 0.069s | net 0.023s\n",
      "eval: [6720/7902] | data 0.068s | net 0.024s\n",
      "eval: [6740/7902] | data 0.070s | net 0.024s\n",
      "eval: [6760/7902] | data 0.067s | net 0.023s\n",
      "eval: [6780/7902] | data 0.071s | net 0.023s\n",
      "eval: [6800/7902] | data 0.069s | net 0.023s\n",
      "eval: [6820/7902] | data 0.068s | net 0.023s\n",
      "eval: [6840/7902] | data 0.069s | net 0.023s\n",
      "eval: [6860/7902] | data 0.069s | net 0.024s\n",
      "eval: [6880/7902] | data 0.069s | net 0.023s\n",
      "eval: [6900/7902] | data 0.069s | net 0.024s\n",
      "eval: [6920/7902] | data 0.291s | net 0.023s\n",
      "eval: [6940/7902] | data 0.155s | net 0.023s\n",
      "eval: [6960/7902] | data 0.271s | net 0.023s\n",
      "eval: [6980/7902] | data 0.269s | net 0.023s\n",
      "eval: [7000/7902] | data 0.282s | net 0.023s\n",
      "eval: [7020/7902] | data 0.271s | net 0.023s\n",
      "eval: [7040/7902] | data 0.257s | net 0.023s\n",
      "eval: [7060/7902] | data 0.262s | net 0.023s\n",
      "eval: [7080/7902] | data 0.282s | net 0.023s\n",
      "eval: [7100/7902] | data 0.292s | net 0.022s\n",
      "eval: [7120/7902] | data 0.289s | net 0.023s\n",
      "eval: [7140/7902] | data 0.319s | net 0.023s\n",
      "eval: [7160/7902] | data 0.164s | net 0.023s\n",
      "eval: [7180/7902] | data 0.309s | net 0.023s\n",
      "eval: [7200/7902] | data 0.300s | net 0.023s\n",
      "eval: [7220/7902] | data 0.181s | net 0.025s\n",
      "eval: [7240/7902] | data 0.309s | net 0.022s\n",
      "eval: [7260/7902] | data 0.324s | net 0.022s\n",
      "eval: [7280/7902] | data 0.300s | net 0.023s\n",
      "eval: [7300/7902] | data 0.178s | net 0.023s\n",
      "eval: [7320/7902] | data 0.303s | net 0.022s\n",
      "eval: [7340/7902] | data 0.319s | net 0.022s\n",
      "eval: [7360/7902] | data 0.356s | net 0.022s\n",
      "eval: [7380/7902] | data 0.188s | net 0.022s\n",
      "eval: [7400/7902] | data 0.333s | net 0.022s\n",
      "eval: [7420/7902] | data 0.328s | net 0.022s\n",
      "eval: [7440/7902] | data 0.324s | net 0.022s\n",
      "eval: [7460/7902] | data 0.327s | net 0.022s\n",
      "eval: [7480/7902] | data 0.327s | net 0.022s\n",
      "eval: [7500/7902] | data 0.189s | net 0.022s\n",
      "eval: [7520/7902] | data 0.303s | net 0.023s\n",
      "eval: [7540/7902] | data 0.297s | net 0.022s\n",
      "eval: [7560/7902] | data 0.296s | net 0.022s\n",
      "eval: [7580/7902] | data 0.166s | net 0.022s\n",
      "eval: [7600/7902] | data 0.312s | net 0.022s\n",
      "eval: [7620/7902] | data 0.311s | net 0.022s\n",
      "eval: [7640/7902] | data 0.163s | net 0.023s\n",
      "eval: [7660/7902] | data 0.300s | net 0.022s\n",
      "eval: [7680/7902] | data 0.280s | net 0.022s\n",
      "eval: [7700/7902] | data 0.290s | net 0.022s\n",
      "eval: [7720/7902] | data 0.334s | net 0.022s\n",
      "eval: [7740/7902] | data 0.282s | net 0.022s\n",
      "eval: [7760/7902] | data 0.308s | net 0.022s\n",
      "eval: [7780/7902] | data 0.328s | net 0.022s\n",
      "eval: [7800/7902] | data 0.295s | net 0.023s\n",
      "eval: [7820/7902] | data 0.299s | net 0.022s\n",
      "eval: [7840/7902] | data 0.305s | net 0.022s\n",
      "eval: [7860/7902] | data 0.304s | net 0.022s\n",
      "eval: [7880/7902] | data 0.291s | net 0.022s\n",
      "eval: [7900/7902] | data 0.312s | net 0.022s\n",
      "Elapsed 14.56min (110.5ms/image, 9.0frames/s)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bike_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bike_orientation.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (car_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (car_orientation.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bus_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bus_orientation.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for participating in our evaluation!\n",
      "Loading detections...\n",
      "  done.\n",
      "Your evaluation results are available in /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib/results\n",
      "bike_easy            0.290\n",
      "bike_moderate        0.291\n",
      "bike_hard            0.291\n",
      "car_easy             0.734\n",
      "car_moderate         0.729\n",
      "car_hard             0.729\n",
      "bus_easy             0.385\n",
      "bus_moderate         0.384\n",
      "bus_hard             0.384\n",
      "mAP                  0.469\n",
      " ############  mse calibration ######################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 22:41:01.803816 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:01.804579 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 22:41:02.576927 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:02.577594 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 22:41:03.639779 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:03.640609 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0813 22:41:04.583522 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:04.584186 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([96, 1, 1, 1]).\n",
      "W0813 22:41:05.551393 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:05.552058 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([96, 1, 1, 1]).\n",
      "W0813 22:41:06.455704 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:06.456369 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([24, 1, 1, 1]).\n",
      "W0813 22:41:07.358018 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:07.358709 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([144, 1, 1, 1]).\n",
      "W0813 22:41:08.419917 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:08.420607 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([144, 1, 1, 1]).\n",
      "W0813 22:41:09.576331 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:09.577071 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([24, 1, 1, 1]).\n",
      "W0813 22:41:10.398796 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:10.399495 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([144, 1, 1, 1]).\n",
      "W0813 22:41:11.165598 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:11.166326 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([144, 1, 1, 1]).\n",
      "W0813 22:41:12.446053 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:12.446722 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 22:41:13.385891 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:13.386549 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 22:41:15.075120 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:15.075863 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 22:41:16.658146 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:16.658847 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 22:41:17.556345 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:17.557228 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 22:41:18.805992 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:18.806690 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 22:41:20.036472 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:20.037156 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 22:41:21.035053 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:21.035731 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 22:41:22.248620 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:22.249320 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 22:41:23.514323 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:23.515018 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0813 22:41:24.531485 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:24.532183 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 22:41:25.850007 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:25.850703 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 22:41:27.052060 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:27.052746 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0813 22:41:28.177787 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:28.178480 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 22:41:29.152129 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:29.152797 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 22:41:30.628385 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:30.629082 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0813 22:41:31.916664 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:31.917357 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 22:41:33.066227 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:33.066916 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 22:41:35.089249 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:35.089899 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0813 22:41:35.850701 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:35.851309 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0813 22:41:36.894657 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:41:36.895354 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([72, 1, 1, 1]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: [0/7902] | data 0.101s | net 0.024s\n",
      "eval: [20/7902] | data 0.136s | net 0.025s\n",
      "eval: [40/7902] | data 0.073s | net 0.023s\n",
      "eval: [60/7902] | data 0.074s | net 0.022s\n",
      "eval: [80/7902] | data 0.114s | net 0.022s\n",
      "eval: [100/7902] | data 0.111s | net 0.023s\n",
      "eval: [120/7902] | data 0.116s | net 0.023s\n",
      "eval: [140/7902] | data 0.103s | net 0.023s\n",
      "eval: [160/7902] | data 0.139s | net 0.025s\n",
      "eval: [180/7902] | data 0.113s | net 0.023s\n",
      "eval: [200/7902] | data 0.105s | net 0.023s\n",
      "eval: [220/7902] | data 0.107s | net 0.025s\n",
      "eval: [240/7902] | data 0.111s | net 0.023s\n",
      "eval: [260/7902] | data 0.118s | net 0.023s\n",
      "eval: [280/7902] | data 0.115s | net 0.023s\n",
      "eval: [300/7902] | data 0.114s | net 0.024s\n",
      "eval: [320/7902] | data 0.114s | net 0.022s\n",
      "eval: [340/7902] | data 0.114s | net 0.022s\n",
      "eval: [360/7902] | data 0.116s | net 0.022s\n",
      "eval: [380/7902] | data 0.100s | net 0.023s\n",
      "eval: [400/7902] | data 0.125s | net 0.022s\n",
      "eval: [420/7902] | data 0.130s | net 0.023s\n",
      "eval: [440/7902] | data 0.128s | net 0.023s\n",
      "eval: [460/7902] | data 0.018s | net 0.024s\n",
      "eval: [480/7902] | data 0.017s | net 0.023s\n",
      "eval: [500/7902] | data 0.019s | net 0.024s\n",
      "eval: [520/7902] | data 0.018s | net 0.023s\n",
      "eval: [540/7902] | data 0.019s | net 0.024s\n",
      "eval: [560/7902] | data 0.018s | net 0.023s\n",
      "eval: [580/7902] | data 0.018s | net 0.024s\n",
      "eval: [600/7902] | data 0.018s | net 0.023s\n",
      "eval: [620/7902] | data 0.017s | net 0.023s\n",
      "eval: [640/7902] | data 0.017s | net 0.023s\n",
      "eval: [660/7902] | data 0.016s | net 0.023s\n",
      "eval: [680/7902] | data 0.022s | net 0.023s\n",
      "eval: [700/7902] | data 0.018s | net 0.023s\n",
      "eval: [720/7902] | data 0.017s | net 0.023s\n",
      "eval: [740/7902] | data 0.018s | net 0.023s\n",
      "eval: [760/7902] | data 0.018s | net 0.023s\n",
      "eval: [780/7902] | data 0.017s | net 0.023s\n",
      "eval: [800/7902] | data 0.022s | net 0.023s\n",
      "eval: [820/7902] | data 0.018s | net 0.024s\n",
      "eval: [840/7902] | data 0.018s | net 0.023s\n",
      "eval: [860/7902] | data 0.018s | net 0.023s\n",
      "eval: [880/7902] | data 0.017s | net 0.023s\n",
      "eval: [900/7902] | data 0.022s | net 0.024s\n",
      "eval: [920/7902] | data 0.017s | net 0.023s\n",
      "eval: [940/7902] | data 0.018s | net 0.022s\n",
      "eval: [960/7902] | data 0.018s | net 0.024s\n",
      "eval: [980/7902] | data 0.017s | net 0.023s\n",
      "eval: [1000/7902] | data 0.018s | net 0.023s\n",
      "eval: [1020/7902] | data 0.017s | net 0.023s\n",
      "eval: [1040/7902] | data 0.017s | net 0.023s\n",
      "eval: [1060/7902] | data 0.018s | net 0.023s\n",
      "eval: [1080/7902] | data 0.018s | net 0.025s\n",
      "eval: [1100/7902] | data 0.017s | net 0.023s\n",
      "eval: [1120/7902] | data 0.017s | net 0.023s\n",
      "eval: [1140/7902] | data 0.017s | net 0.023s\n",
      "eval: [1160/7902] | data 0.018s | net 0.023s\n",
      "eval: [1180/7902] | data 0.018s | net 0.023s\n",
      "eval: [1200/7902] | data 0.029s | net 0.023s\n",
      "eval: [1220/7902] | data 0.018s | net 0.024s\n",
      "eval: [1240/7902] | data 0.018s | net 0.023s\n",
      "eval: [1260/7902] | data 0.017s | net 0.023s\n",
      "eval: [1280/7902] | data 0.017s | net 0.023s\n",
      "eval: [1300/7902] | data 0.017s | net 0.023s\n",
      "eval: [1320/7902] | data 0.018s | net 0.022s\n",
      "eval: [1340/7902] | data 0.021s | net 0.024s\n",
      "eval: [1360/7902] | data 0.017s | net 0.023s\n",
      "eval: [1380/7902] | data 0.018s | net 0.023s\n",
      "eval: [1400/7902] | data 0.018s | net 0.023s\n",
      "eval: [1420/7902] | data 0.018s | net 0.023s\n",
      "eval: [1440/7902] | data 0.019s | net 0.023s\n",
      "eval: [1460/7902] | data 0.012s | net 0.023s\n",
      "eval: [1480/7902] | data 0.012s | net 0.023s\n",
      "eval: [1500/7902] | data 0.012s | net 0.023s\n",
      "eval: [1520/7902] | data 0.011s | net 0.023s\n",
      "eval: [1540/7902] | data 0.011s | net 0.025s\n",
      "eval: [1560/7902] | data 0.011s | net 0.023s\n",
      "eval: [1580/7902] | data 0.012s | net 0.023s\n",
      "eval: [1600/7902] | data 0.012s | net 0.023s\n",
      "eval: [1620/7902] | data 0.011s | net 0.024s\n",
      "eval: [1640/7902] | data 0.011s | net 0.024s\n",
      "eval: [1660/7902] | data 0.012s | net 0.024s\n",
      "eval: [1680/7902] | data 0.012s | net 0.023s\n",
      "eval: [1700/7902] | data 0.011s | net 0.024s\n",
      "eval: [1720/7902] | data 0.012s | net 0.023s\n",
      "eval: [1740/7902] | data 0.011s | net 0.024s\n",
      "eval: [1760/7902] | data 0.011s | net 0.024s\n",
      "eval: [1780/7902] | data 0.011s | net 0.024s\n",
      "eval: [1800/7902] | data 0.012s | net 0.024s\n",
      "eval: [1820/7902] | data 0.012s | net 0.023s\n",
      "eval: [1840/7902] | data 0.011s | net 0.023s\n",
      "eval: [1860/7902] | data 0.011s | net 0.023s\n",
      "eval: [1880/7902] | data 0.011s | net 0.023s\n",
      "eval: [1900/7902] | data 0.012s | net 0.025s\n",
      "eval: [1920/7902] | data 0.011s | net 0.023s\n",
      "eval: [1940/7902] | data 0.011s | net 0.023s\n",
      "eval: [1960/7902] | data 0.011s | net 0.023s\n",
      "eval: [1980/7902] | data 0.012s | net 0.023s\n",
      "eval: [2000/7902] | data 0.012s | net 0.023s\n",
      "eval: [2020/7902] | data 0.012s | net 0.023s\n",
      "eval: [2040/7902] | data 0.012s | net 0.023s\n",
      "eval: [2060/7902] | data 0.011s | net 0.023s\n",
      "eval: [2080/7902] | data 0.011s | net 0.023s\n",
      "eval: [2100/7902] | data 0.011s | net 0.023s\n",
      "eval: [2120/7902] | data 0.011s | net 0.023s\n",
      "eval: [2140/7902] | data 0.011s | net 0.023s\n",
      "eval: [2160/7902] | data 0.011s | net 0.023s\n",
      "eval: [2180/7902] | data 0.011s | net 0.023s\n",
      "eval: [2200/7902] | data 0.011s | net 0.023s\n",
      "eval: [2220/7902] | data 0.011s | net 0.023s\n",
      "eval: [2240/7902] | data 0.011s | net 0.023s\n",
      "eval: [2260/7902] | data 0.011s | net 0.024s\n",
      "eval: [2280/7902] | data 0.011s | net 0.023s\n",
      "eval: [2300/7902] | data 0.011s | net 0.023s\n",
      "eval: [2320/7902] | data 0.014s | net 0.025s\n",
      "eval: [2340/7902] | data 0.011s | net 0.023s\n",
      "eval: [2360/7902] | data 0.011s | net 0.023s\n",
      "eval: [2380/7902] | data 0.011s | net 0.024s\n",
      "eval: [2400/7902] | data 0.011s | net 0.023s\n",
      "eval: [2420/7902] | data 0.011s | net 0.023s\n",
      "eval: [2440/7902] | data 0.011s | net 0.023s\n",
      "eval: [2460/7902] | data 0.041s | net 0.023s\n",
      "eval: [2480/7902] | data 0.072s | net 0.024s\n",
      "eval: [2500/7902] | data 0.066s | net 0.023s\n",
      "eval: [2520/7902] | data 0.074s | net 0.023s\n",
      "eval: [2540/7902] | data 0.072s | net 0.023s\n",
      "eval: [2560/7902] | data 0.089s | net 0.023s\n",
      "eval: [2580/7902] | data 0.074s | net 0.023s\n",
      "eval: [2600/7902] | data 0.069s | net 0.023s\n",
      "eval: [2620/7902] | data 0.073s | net 0.024s\n",
      "eval: [2640/7902] | data 0.045s | net 0.022s\n",
      "eval: [2660/7902] | data 0.073s | net 0.022s\n",
      "eval: [2680/7902] | data 0.048s | net 0.023s\n",
      "eval: [2700/7902] | data 0.034s | net 0.023s\n",
      "eval: [2720/7902] | data 0.040s | net 0.025s\n",
      "eval: [2740/7902] | data 0.073s | net 0.024s\n",
      "eval: [2760/7902] | data 0.070s | net 0.023s\n",
      "eval: [2780/7902] | data 0.070s | net 0.023s\n",
      "eval: [2800/7902] | data 0.067s | net 0.023s\n",
      "eval: [2820/7902] | data 0.071s | net 0.023s\n",
      "eval: [2840/7902] | data 0.068s | net 0.024s\n",
      "eval: [2860/7902] | data 0.070s | net 0.023s\n",
      "eval: [2880/7902] | data 0.071s | net 0.024s\n",
      "eval: [2900/7902] | data 0.035s | net 0.023s\n",
      "eval: [2920/7902] | data 0.069s | net 0.023s\n",
      "eval: [2940/7902] | data 0.068s | net 0.023s\n",
      "eval: [2960/7902] | data 0.072s | net 0.023s\n",
      "eval: [2980/7902] | data 0.069s | net 0.024s\n",
      "eval: [3000/7902] | data 0.035s | net 0.023s\n",
      "eval: [3020/7902] | data 0.071s | net 0.023s\n",
      "eval: [3040/7902] | data 0.082s | net 0.023s\n",
      "eval: [3060/7902] | data 0.059s | net 0.023s\n",
      "eval: [3080/7902] | data 0.069s | net 0.023s\n",
      "eval: [3100/7902] | data 0.083s | net 0.023s\n",
      "eval: [3120/7902] | data 0.069s | net 0.023s\n",
      "eval: [3140/7902] | data 0.096s | net 0.023s\n",
      "eval: [3160/7902] | data 0.073s | net 0.023s\n",
      "eval: [3180/7902] | data 0.072s | net 0.023s\n",
      "eval: [3200/7902] | data 0.071s | net 0.023s\n",
      "eval: [3220/7902] | data 0.070s | net 0.024s\n",
      "eval: [3240/7902] | data 0.075s | net 0.024s\n",
      "eval: [3260/7902] | data 0.072s | net 0.023s\n",
      "eval: [3280/7902] | data 0.071s | net 0.023s\n",
      "eval: [3300/7902] | data 0.071s | net 0.025s\n",
      "eval: [3320/7902] | data 0.040s | net 0.023s\n",
      "eval: [3340/7902] | data 0.063s | net 0.023s\n",
      "eval: [3360/7902] | data 0.072s | net 0.023s\n",
      "eval: [3380/7902] | data 0.036s | net 0.023s\n",
      "eval: [3400/7902] | data 0.069s | net 0.023s\n",
      "eval: [3420/7902] | data 0.026s | net 0.023s\n",
      "eval: [3440/7902] | data 0.071s | net 0.023s\n",
      "eval: [3460/7902] | data 0.120s | net 0.023s\n",
      "eval: [3480/7902] | data 0.086s | net 0.023s\n",
      "eval: [3500/7902] | data 0.076s | net 0.024s\n",
      "eval: [3520/7902] | data 0.075s | net 0.024s\n",
      "eval: [3540/7902] | data 0.092s | net 0.024s\n",
      "eval: [3560/7902] | data 0.075s | net 0.024s\n",
      "eval: [3580/7902] | data 0.086s | net 0.023s\n",
      "eval: [3600/7902] | data 0.106s | net 0.023s\n",
      "eval: [3620/7902] | data 0.077s | net 0.023s\n",
      "eval: [3640/7902] | data 0.077s | net 0.023s\n",
      "eval: [3660/7902] | data 0.074s | net 0.022s\n",
      "eval: [3680/7902] | data 0.087s | net 0.024s\n",
      "eval: [3700/7902] | data 0.091s | net 0.024s\n",
      "eval: [3720/7902] | data 0.054s | net 0.022s\n",
      "eval: [3740/7902] | data 0.052s | net 0.023s\n",
      "eval: [3760/7902] | data 0.064s | net 0.025s\n",
      "eval: [3780/7902] | data 0.041s | net 0.024s\n",
      "eval: [3800/7902] | data 0.051s | net 0.023s\n",
      "eval: [3820/7902] | data 0.052s | net 0.023s\n",
      "eval: [3840/7902] | data 0.054s | net 0.023s\n",
      "eval: [3860/7902] | data 0.072s | net 0.022s\n",
      "eval: [3880/7902] | data 0.040s | net 0.023s\n",
      "eval: [3900/7902] | data 0.056s | net 0.023s\n",
      "eval: [3920/7902] | data 0.054s | net 0.023s\n",
      "eval: [3940/7902] | data 0.056s | net 0.023s\n",
      "eval: [3960/7902] | data 0.083s | net 0.023s\n",
      "eval: [3980/7902] | data 0.041s | net 0.023s\n",
      "eval: [4000/7902] | data 0.075s | net 0.023s\n",
      "eval: [4020/7902] | data 0.063s | net 0.023s\n",
      "eval: [4040/7902] | data 0.041s | net 0.023s\n",
      "eval: [4060/7902] | data 0.089s | net 0.023s\n",
      "eval: [4080/7902] | data 0.053s | net 0.023s\n",
      "eval: [4100/7902] | data 0.054s | net 0.023s\n",
      "eval: [4120/7902] | data 0.057s | net 0.023s\n",
      "eval: [4140/7902] | data 0.040s | net 0.023s\n",
      "eval: [4160/7902] | data 0.061s | net 0.024s\n",
      "eval: [4180/7902] | data 0.056s | net 0.023s\n",
      "eval: [4200/7902] | data 0.042s | net 0.023s\n",
      "eval: [4220/7902] | data 0.057s | net 0.024s\n",
      "eval: [4240/7902] | data 0.057s | net 0.023s\n",
      "eval: [4260/7902] | data 0.082s | net 0.023s\n",
      "eval: [4280/7902] | data 0.057s | net 0.023s\n",
      "eval: [4300/7902] | data 0.041s | net 0.023s\n",
      "eval: [4320/7902] | data 0.059s | net 0.023s\n",
      "eval: [4340/7902] | data 0.057s | net 0.023s\n",
      "eval: [4360/7902] | data 0.041s | net 0.023s\n",
      "eval: [4380/7902] | data 0.057s | net 0.023s\n",
      "eval: [4400/7902] | data 0.057s | net 0.023s\n",
      "eval: [4420/7902] | data 0.058s | net 0.023s\n",
      "eval: [4440/7902] | data 0.073s | net 0.023s\n",
      "eval: [4460/7902] | data 0.041s | net 0.023s\n",
      "eval: [4480/7902] | data 0.057s | net 0.023s\n",
      "eval: [4500/7902] | data 0.058s | net 0.024s\n",
      "eval: [4520/7902] | data 0.041s | net 0.023s\n",
      "eval: [4540/7902] | data 0.057s | net 0.023s\n",
      "eval: [4560/7902] | data 0.058s | net 0.023s\n",
      "eval: [4580/7902] | data 0.053s | net 0.023s\n",
      "eval: [4600/7902] | data 0.057s | net 0.023s\n",
      "eval: [4620/7902] | data 0.040s | net 0.023s\n",
      "eval: [4640/7902] | data 0.055s | net 0.023s\n",
      "eval: [4660/7902] | data 0.064s | net 0.023s\n",
      "eval: [4680/7902] | data 0.040s | net 0.023s\n",
      "eval: [4700/7902] | data 0.057s | net 0.023s\n",
      "eval: [4720/7902] | data 0.084s | net 0.023s\n",
      "eval: [4740/7902] | data 0.095s | net 0.023s\n",
      "eval: [4760/7902] | data 0.079s | net 0.023s\n",
      "eval: [4780/7902] | data 0.072s | net 0.023s\n",
      "eval: [4800/7902] | data 0.048s | net 0.023s\n",
      "eval: [4820/7902] | data 0.080s | net 0.024s\n",
      "eval: [4840/7902] | data 0.083s | net 0.023s\n",
      "eval: [4860/7902] | data 0.083s | net 0.022s\n",
      "eval: [4880/7902] | data 0.056s | net 0.023s\n",
      "eval: [4900/7902] | data 0.072s | net 0.023s\n",
      "eval: [4920/7902] | data 0.080s | net 0.023s\n",
      "eval: [4940/7902] | data 0.045s | net 0.023s\n",
      "eval: [4960/7902] | data 0.120s | net 0.023s\n",
      "eval: [4980/7902] | data 0.141s | net 0.023s\n",
      "eval: [5000/7902] | data 0.118s | net 0.022s\n",
      "eval: [5020/7902] | data 0.120s | net 0.023s\n",
      "eval: [5040/7902] | data 0.114s | net 0.022s\n",
      "eval: [5060/7902] | data 0.112s | net 0.023s\n",
      "eval: [5080/7902] | data 0.119s | net 0.024s\n",
      "eval: [5100/7902] | data 0.130s | net 0.022s\n",
      "eval: [5120/7902] | data 0.136s | net 0.022s\n",
      "eval: [5140/7902] | data 0.126s | net 0.022s\n",
      "eval: [5160/7902] | data 0.163s | net 0.023s\n",
      "eval: [5180/7902] | data 0.130s | net 0.023s\n",
      "eval: [5200/7902] | data 0.288s | net 0.022s\n",
      "eval: [5220/7902] | data 0.337s | net 0.022s\n",
      "eval: [5240/7902] | data 0.315s | net 0.022s\n",
      "eval: [5260/7902] | data 0.337s | net 0.023s\n",
      "eval: [5280/7902] | data 0.327s | net 0.022s\n",
      "eval: [5300/7902] | data 0.334s | net 0.023s\n",
      "eval: [5320/7902] | data 0.301s | net 0.023s\n",
      "eval: [5340/7902] | data 0.294s | net 0.022s\n",
      "eval: [5360/7902] | data 0.277s | net 0.022s\n",
      "eval: [5380/7902] | data 0.294s | net 0.022s\n",
      "eval: [5400/7902] | data 0.271s | net 0.022s\n",
      "eval: [5420/7902] | data 0.308s | net 0.022s\n",
      "eval: [5440/7902] | data 0.305s | net 0.022s\n",
      "eval: [5460/7902] | data 0.348s | net 0.022s\n",
      "eval: [5480/7902] | data 0.315s | net 0.022s\n",
      "eval: [5500/7902] | data 0.286s | net 0.022s\n",
      "eval: [5520/7902] | data 0.303s | net 0.023s\n",
      "eval: [5540/7902] | data 0.293s | net 0.023s\n",
      "eval: [5560/7902] | data 0.316s | net 0.022s\n",
      "eval: [5580/7902] | data 0.416s | net 0.022s\n",
      "eval: [5600/7902] | data 0.042s | net 0.023s\n",
      "eval: [5620/7902] | data 0.089s | net 0.022s\n",
      "eval: [5640/7902] | data 0.084s | net 0.023s\n",
      "eval: [5660/7902] | data 0.077s | net 0.023s\n",
      "eval: [5680/7902] | data 0.090s | net 0.022s\n",
      "eval: [5700/7902] | data 0.055s | net 0.022s\n",
      "eval: [5720/7902] | data 0.087s | net 0.023s\n",
      "eval: [5740/7902] | data 0.041s | net 0.023s\n",
      "eval: [5760/7902] | data 0.109s | net 0.023s\n",
      "eval: [5780/7902] | data 0.090s | net 0.022s\n",
      "eval: [5800/7902] | data 0.042s | net 0.023s\n",
      "eval: [5820/7902] | data 0.086s | net 0.022s\n",
      "eval: [5840/7902] | data 0.057s | net 0.023s\n",
      "eval: [5860/7902] | data 0.058s | net 0.022s\n",
      "eval: [5880/7902] | data 0.075s | net 0.022s\n",
      "eval: [5900/7902] | data 0.041s | net 0.023s\n",
      "eval: [5920/7902] | data 0.103s | net 0.023s\n",
      "eval: [5940/7902] | data 0.097s | net 0.023s\n",
      "eval: [5960/7902] | data 0.104s | net 0.024s\n",
      "eval: [5980/7902] | data 0.132s | net 0.022s\n",
      "eval: [6000/7902] | data 0.073s | net 0.023s\n",
      "eval: [6020/7902] | data 0.101s | net 0.023s\n",
      "eval: [6040/7902] | data 0.088s | net 0.025s\n",
      "eval: [6060/7902] | data 0.112s | net 0.022s\n",
      "eval: [6080/7902] | data 0.112s | net 0.023s\n",
      "eval: [6100/7902] | data 0.131s | net 0.022s\n",
      "eval: [6120/7902] | data 0.133s | net 0.022s\n",
      "eval: [6140/7902] | data 0.142s | net 0.022s\n",
      "eval: [6160/7902] | data 0.126s | net 0.022s\n",
      "eval: [6180/7902] | data 0.079s | net 0.023s\n",
      "eval: [6200/7902] | data 0.081s | net 0.023s\n",
      "eval: [6220/7902] | data 0.074s | net 0.022s\n",
      "eval: [6240/7902] | data 0.134s | net 0.022s\n",
      "eval: [6260/7902] | data 0.089s | net 0.023s\n",
      "eval: [6280/7902] | data 0.110s | net 0.022s\n",
      "eval: [6300/7902] | data 0.151s | net 0.022s\n",
      "eval: [6320/7902] | data 0.082s | net 0.022s\n",
      "eval: [6340/7902] | data 0.102s | net 0.023s\n",
      "eval: [6360/7902] | data 0.106s | net 0.023s\n",
      "eval: [6380/7902] | data 0.117s | net 0.022s\n",
      "eval: [6400/7902] | data 0.075s | net 0.023s\n",
      "eval: [6420/7902] | data 0.123s | net 0.023s\n",
      "eval: [6440/7902] | data 0.116s | net 0.023s\n",
      "eval: [6460/7902] | data 0.142s | net 0.022s\n",
      "eval: [6480/7902] | data 0.110s | net 0.023s\n",
      "eval: [6500/7902] | data 0.078s | net 0.022s\n",
      "eval: [6520/7902] | data 0.062s | net 0.023s\n",
      "eval: [6540/7902] | data 0.063s | net 0.022s\n",
      "eval: [6560/7902] | data 0.108s | net 0.023s\n",
      "eval: [6580/7902] | data 0.079s | net 0.023s\n",
      "eval: [6600/7902] | data 0.106s | net 0.023s\n",
      "eval: [6620/7902] | data 0.090s | net 0.023s\n",
      "eval: [6640/7902] | data 0.087s | net 0.023s\n",
      "eval: [6660/7902] | data 0.118s | net 0.022s\n",
      "eval: [6680/7902] | data 0.100s | net 0.023s\n",
      "eval: [6700/7902] | data 0.100s | net 0.023s\n",
      "eval: [6720/7902] | data 0.087s | net 0.023s\n",
      "eval: [6740/7902] | data 0.085s | net 0.023s\n",
      "eval: [6760/7902] | data 0.094s | net 0.023s\n",
      "eval: [6780/7902] | data 0.088s | net 0.023s\n",
      "eval: [6800/7902] | data 0.077s | net 0.023s\n",
      "eval: [6820/7902] | data 0.079s | net 0.023s\n",
      "eval: [6840/7902] | data 0.088s | net 0.024s\n",
      "eval: [6860/7902] | data 0.068s | net 0.023s\n",
      "eval: [6880/7902] | data 0.074s | net 0.023s\n",
      "eval: [6900/7902] | data 0.090s | net 0.024s\n",
      "eval: [6920/7902] | data 0.281s | net 0.022s\n",
      "eval: [6940/7902] | data 0.189s | net 0.024s\n",
      "eval: [6960/7902] | data 0.346s | net 0.024s\n",
      "eval: [6980/7902] | data 0.316s | net 0.024s\n",
      "eval: [7000/7902] | data 0.362s | net 0.023s\n",
      "eval: [7020/7902] | data 0.365s | net 0.023s\n",
      "eval: [7040/7902] | data 0.332s | net 0.023s\n",
      "eval: [7060/7902] | data 0.318s | net 0.023s\n",
      "eval: [7080/7902] | data 0.332s | net 0.024s\n",
      "eval: [7100/7902] | data 0.339s | net 0.022s\n",
      "eval: [7120/7902] | data 0.323s | net 0.023s\n",
      "eval: [7140/7902] | data 0.326s | net 0.022s\n",
      "eval: [7160/7902] | data 0.254s | net 0.022s\n",
      "eval: [7180/7902] | data 0.412s | net 0.022s\n",
      "eval: [7200/7902] | data 0.372s | net 0.023s\n",
      "eval: [7220/7902] | data 0.202s | net 0.023s\n",
      "eval: [7240/7902] | data 0.445s | net 0.023s\n",
      "eval: [7260/7902] | data 0.327s | net 0.022s\n",
      "eval: [7280/7902] | data 0.323s | net 0.022s\n",
      "eval: [7300/7902] | data 0.301s | net 0.022s\n",
      "eval: [7320/7902] | data 0.461s | net 0.022s\n",
      "eval: [7340/7902] | data 0.318s | net 0.023s\n",
      "eval: [7360/7902] | data 0.365s | net 0.023s\n",
      "eval: [7380/7902] | data 0.235s | net 0.023s\n",
      "eval: [7400/7902] | data 0.416s | net 0.023s\n",
      "eval: [7420/7902] | data 0.386s | net 0.023s\n",
      "eval: [7440/7902] | data 0.450s | net 0.023s\n",
      "eval: [7460/7902] | data 0.366s | net 0.023s\n",
      "eval: [7480/7902] | data 0.385s | net 0.022s\n",
      "eval: [7500/7902] | data 0.204s | net 0.024s\n",
      "eval: [7520/7902] | data 0.429s | net 0.023s\n",
      "eval: [7540/7902] | data 0.336s | net 0.022s\n",
      "eval: [7560/7902] | data 0.387s | net 0.022s\n",
      "eval: [7580/7902] | data 0.373s | net 0.022s\n",
      "eval: [7600/7902] | data 0.325s | net 0.023s\n",
      "eval: [7620/7902] | data 0.318s | net 0.022s\n",
      "eval: [7640/7902] | data 0.197s | net 0.023s\n",
      "eval: [7660/7902] | data 0.462s | net 0.022s\n",
      "eval: [7680/7902] | data 0.439s | net 0.022s\n",
      "eval: [7700/7902] | data 0.356s | net 0.023s\n",
      "eval: [7720/7902] | data 0.503s | net 0.023s\n",
      "eval: [7740/7902] | data 0.379s | net 0.023s\n",
      "eval: [7760/7902] | data 0.322s | net 0.023s\n",
      "eval: [7780/7902] | data 0.405s | net 0.023s\n",
      "eval: [7800/7902] | data 0.330s | net 0.023s\n",
      "eval: [7820/7902] | data 0.383s | net 0.023s\n",
      "eval: [7840/7902] | data 0.321s | net 0.022s\n",
      "eval: [7860/7902] | data 0.451s | net 0.022s\n",
      "eval: [7880/7902] | data 0.364s | net 0.022s\n",
      "eval: [7900/7902] | data 0.344s | net 0.022s\n",
      "Elapsed 17.99min (136.6ms/image, 7.3frames/s)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib/results/plot: File exists\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bike_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bike_orientation.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (car_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (car_orientation.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bus_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bus_orientation.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for participating in our evaluation!\n",
      "Loading detections...\n",
      "  done.\n",
      "Your evaluation results are available in /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib/results\n",
      "bike_easy            0.406\n",
      "bike_moderate        0.406\n",
      "bike_hard            0.406\n",
      "car_easy             0.758\n",
      "car_moderate         0.751\n",
      "car_hard             0.751\n",
      "bus_easy             0.447\n",
      "bus_moderate         0.394\n",
      "bus_hard             0.394\n",
      "mAP                  0.524\n",
      " ############  entropy calibration ######################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 22:59:46.658454 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:59:46.659085 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 22:59:51.492108 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 22:59:51.492670 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 23:00:00.013319 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:00:00.013832 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0813 23:00:06.607147 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:00:06.607678 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([96, 1, 1, 1]).\n",
      "W0813 23:00:14.147572 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:00:14.148137 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([96, 1, 1, 1]).\n",
      "W0813 23:00:20.039382 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:00:20.039907 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([24, 1, 1, 1]).\n",
      "W0813 23:00:26.735543 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:00:26.736070 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([144, 1, 1, 1]).\n",
      "W0813 23:00:35.386126 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:00:35.386714 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([144, 1, 1, 1]).\n",
      "W0813 23:00:45.731156 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:00:45.731655 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([24, 1, 1, 1]).\n",
      "W0813 23:00:51.130446 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:00:51.130975 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([144, 1, 1, 1]).\n",
      "W0813 23:00:56.271476 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:00:56.272009 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([144, 1, 1, 1]).\n",
      "W0813 23:01:03.964441 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:01:03.964981 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 23:01:07.941485 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:01:07.941996 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 23:01:21.378801 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:01:21.379331 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 23:01:35.482125 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:01:35.482660 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 23:01:40.104283 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:01:40.104811 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 23:01:51.544422 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:01:51.544981 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 23:02:02.949184 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:02:02.949728 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0813 23:02:10.684359 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:02:10.684894 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 23:02:21.768013 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:02:21.768547 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0813 23:02:33.580948 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:02:33.581454 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0813 23:02:41.799114 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:02:41.799647 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 23:02:55.315166 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:02:55.315704 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 23:03:05.055304 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:03:05.055798 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0813 23:03:15.000018 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:03:15.000579 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 23:03:22.373074 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:03:22.373601 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 23:03:38.529094 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:03:38.530177 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0813 23:03:51.424855 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:03:51.425391 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 23:04:01.331580 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:04:01.332118 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0813 23:04:30.330522 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:04:30.347584 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0813 23:04:35.303276 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:04:35.303815 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0813 23:04:42.215429 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0813 23:04:42.215952 140513235423424 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([72, 1, 1, 1]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: [0/7902] | data 0.112s | net 0.025s\n",
      "eval: [20/7902] | data 0.117s | net 0.024s\n",
      "eval: [40/7902] | data 0.076s | net 0.024s\n",
      "eval: [60/7902] | data 0.077s | net 0.023s\n",
      "eval: [80/7902] | data 0.112s | net 0.023s\n",
      "eval: [100/7902] | data 0.119s | net 0.023s\n",
      "eval: [120/7902] | data 0.130s | net 0.024s\n",
      "eval: [140/7902] | data 0.132s | net 0.022s\n",
      "eval: [160/7902] | data 0.159s | net 0.023s\n",
      "eval: [180/7902] | data 0.118s | net 0.023s\n",
      "eval: [200/7902] | data 0.178s | net 0.022s\n",
      "eval: [220/7902] | data 0.133s | net 0.023s\n",
      "eval: [240/7902] | data 0.110s | net 0.023s\n",
      "eval: [260/7902] | data 0.132s | net 0.022s\n",
      "eval: [280/7902] | data 0.133s | net 0.023s\n",
      "eval: [300/7902] | data 0.137s | net 0.023s\n",
      "eval: [320/7902] | data 0.131s | net 0.022s\n",
      "eval: [340/7902] | data 0.121s | net 0.022s\n",
      "eval: [360/7902] | data 0.209s | net 0.023s\n",
      "eval: [380/7902] | data 0.138s | net 0.023s\n",
      "eval: [400/7902] | data 0.136s | net 0.022s\n",
      "eval: [420/7902] | data 0.159s | net 0.023s\n",
      "eval: [440/7902] | data 0.127s | net 0.023s\n",
      "eval: [460/7902] | data 0.018s | net 0.023s\n",
      "eval: [480/7902] | data 0.017s | net 0.023s\n",
      "eval: [500/7902] | data 0.019s | net 0.023s\n",
      "eval: [520/7902] | data 0.018s | net 0.024s\n",
      "eval: [540/7902] | data 0.018s | net 0.024s\n",
      "eval: [560/7902] | data 0.017s | net 0.024s\n",
      "eval: [580/7902] | data 0.018s | net 0.024s\n",
      "eval: [600/7902] | data 0.018s | net 0.024s\n",
      "eval: [620/7902] | data 0.017s | net 0.024s\n",
      "eval: [640/7902] | data 0.017s | net 0.024s\n",
      "eval: [660/7902] | data 0.016s | net 0.023s\n",
      "eval: [680/7902] | data 0.018s | net 0.024s\n",
      "eval: [700/7902] | data 0.018s | net 0.023s\n",
      "eval: [720/7902] | data 0.021s | net 0.025s\n",
      "eval: [740/7902] | data 0.018s | net 0.024s\n",
      "eval: [760/7902] | data 0.017s | net 0.024s\n",
      "eval: [780/7902] | data 0.017s | net 0.023s\n",
      "eval: [800/7902] | data 0.018s | net 0.024s\n",
      "eval: [820/7902] | data 0.018s | net 0.024s\n",
      "eval: [840/7902] | data 0.018s | net 0.024s\n",
      "eval: [860/7902] | data 0.022s | net 0.024s\n",
      "eval: [880/7902] | data 0.017s | net 0.024s\n",
      "eval: [900/7902] | data 0.018s | net 0.023s\n",
      "eval: [920/7902] | data 0.021s | net 0.025s\n",
      "eval: [940/7902] | data 0.018s | net 0.024s\n",
      "eval: [960/7902] | data 0.016s | net 0.024s\n",
      "eval: [980/7902] | data 0.017s | net 0.024s\n",
      "eval: [1000/7902] | data 0.018s | net 0.023s\n",
      "eval: [1020/7902] | data 0.017s | net 0.024s\n",
      "eval: [1040/7902] | data 0.017s | net 0.024s\n",
      "eval: [1060/7902] | data 0.018s | net 0.024s\n",
      "eval: [1080/7902] | data 0.017s | net 0.023s\n",
      "eval: [1100/7902] | data 0.017s | net 0.024s\n",
      "eval: [1120/7902] | data 0.017s | net 0.024s\n",
      "eval: [1140/7902] | data 0.017s | net 0.024s\n",
      "eval: [1160/7902] | data 0.021s | net 0.024s\n",
      "eval: [1180/7902] | data 0.018s | net 0.024s\n",
      "eval: [1200/7902] | data 0.017s | net 0.023s\n",
      "eval: [1220/7902] | data 0.017s | net 0.024s\n",
      "eval: [1240/7902] | data 0.018s | net 0.024s\n",
      "eval: [1260/7902] | data 0.017s | net 0.024s\n",
      "eval: [1280/7902] | data 0.017s | net 0.024s\n",
      "eval: [1300/7902] | data 0.017s | net 0.024s\n",
      "eval: [1320/7902] | data 0.023s | net 0.023s\n",
      "eval: [1340/7902] | data 0.017s | net 0.023s\n",
      "eval: [1360/7902] | data 0.017s | net 0.023s\n",
      "eval: [1380/7902] | data 0.018s | net 0.024s\n",
      "eval: [1400/7902] | data 0.018s | net 0.023s\n",
      "eval: [1420/7902] | data 0.017s | net 0.024s\n",
      "eval: [1440/7902] | data 0.018s | net 0.024s\n",
      "eval: [1460/7902] | data 0.014s | net 0.025s\n",
      "eval: [1480/7902] | data 0.011s | net 0.024s\n",
      "eval: [1500/7902] | data 0.012s | net 0.023s\n",
      "eval: [1520/7902] | data 0.011s | net 0.024s\n",
      "eval: [1540/7902] | data 0.011s | net 0.023s\n",
      "eval: [1560/7902] | data 0.011s | net 0.023s\n",
      "eval: [1580/7902] | data 0.012s | net 0.023s\n",
      "eval: [1600/7902] | data 0.012s | net 0.023s\n",
      "eval: [1620/7902] | data 0.011s | net 0.024s\n",
      "eval: [1640/7902] | data 0.011s | net 0.023s\n",
      "eval: [1660/7902] | data 0.011s | net 0.024s\n",
      "eval: [1680/7902] | data 0.014s | net 0.025s\n",
      "eval: [1700/7902] | data 0.011s | net 0.024s\n",
      "eval: [1720/7902] | data 0.012s | net 0.024s\n",
      "eval: [1740/7902] | data 0.011s | net 0.024s\n",
      "eval: [1760/7902] | data 0.011s | net 0.024s\n",
      "eval: [1780/7902] | data 0.011s | net 0.024s\n",
      "eval: [1800/7902] | data 0.011s | net 0.024s\n",
      "eval: [1820/7902] | data 0.011s | net 0.024s\n",
      "eval: [1840/7902] | data 0.012s | net 0.024s\n",
      "eval: [1860/7902] | data 0.012s | net 0.024s\n",
      "eval: [1880/7902] | data 0.011s | net 0.024s\n",
      "eval: [1900/7902] | data 0.012s | net 0.024s\n",
      "eval: [1920/7902] | data 0.011s | net 0.024s\n",
      "eval: [1940/7902] | data 0.011s | net 0.024s\n",
      "eval: [1960/7902] | data 0.012s | net 0.024s\n",
      "eval: [1980/7902] | data 0.012s | net 0.024s\n",
      "eval: [2000/7902] | data 0.012s | net 0.024s\n",
      "eval: [2020/7902] | data 0.011s | net 0.024s\n",
      "eval: [2040/7902] | data 0.014s | net 0.025s\n",
      "eval: [2060/7902] | data 0.011s | net 0.024s\n",
      "eval: [2080/7902] | data 0.011s | net 0.024s\n",
      "eval: [2100/7902] | data 0.012s | net 0.024s\n",
      "eval: [2120/7902] | data 0.011s | net 0.024s\n",
      "eval: [2140/7902] | data 0.012s | net 0.024s\n",
      "eval: [2160/7902] | data 0.011s | net 0.024s\n",
      "eval: [2180/7902] | data 0.011s | net 0.024s\n",
      "eval: [2200/7902] | data 0.011s | net 0.024s\n",
      "eval: [2220/7902] | data 0.011s | net 0.023s\n",
      "eval: [2240/7902] | data 0.011s | net 0.024s\n",
      "eval: [2260/7902] | data 0.011s | net 0.024s\n",
      "eval: [2280/7902] | data 0.011s | net 0.025s\n",
      "eval: [2300/7902] | data 0.011s | net 0.024s\n",
      "eval: [2320/7902] | data 0.011s | net 0.023s\n",
      "eval: [2340/7902] | data 0.011s | net 0.024s\n",
      "eval: [2360/7902] | data 0.012s | net 0.023s\n",
      "eval: [2380/7902] | data 0.012s | net 0.023s\n",
      "eval: [2400/7902] | data 0.011s | net 0.023s\n",
      "eval: [2420/7902] | data 0.011s | net 0.023s\n",
      "eval: [2440/7902] | data 0.011s | net 0.024s\n",
      "eval: [2460/7902] | data 0.066s | net 0.025s\n",
      "eval: [2480/7902] | data 0.069s | net 0.023s\n",
      "eval: [2500/7902] | data 0.070s | net 0.023s\n",
      "eval: [2520/7902] | data 0.074s | net 0.023s\n",
      "eval: [2540/7902] | data 0.061s | net 0.023s\n",
      "eval: [2560/7902] | data 0.084s | net 0.025s\n",
      "eval: [2580/7902] | data 0.069s | net 0.024s\n",
      "eval: [2600/7902] | data 0.068s | net 0.023s\n",
      "eval: [2620/7902] | data 0.074s | net 0.023s\n",
      "eval: [2640/7902] | data 0.045s | net 0.023s\n",
      "eval: [2660/7902] | data 0.075s | net 0.023s\n",
      "eval: [2680/7902] | data 0.085s | net 0.024s\n",
      "eval: [2700/7902] | data 0.031s | net 0.023s\n",
      "eval: [2720/7902] | data 0.031s | net 0.023s\n",
      "eval: [2740/7902] | data 0.063s | net 0.023s\n",
      "eval: [2760/7902] | data 0.091s | net 0.024s\n",
      "eval: [2780/7902] | data 0.085s | net 0.025s\n",
      "eval: [2800/7902] | data 0.074s | net 0.023s\n",
      "eval: [2820/7902] | data 0.073s | net 0.024s\n",
      "eval: [2840/7902] | data 0.065s | net 0.023s\n",
      "eval: [2860/7902] | data 0.076s | net 0.023s\n",
      "eval: [2880/7902] | data 0.071s | net 0.024s\n",
      "eval: [2900/7902] | data 0.048s | net 0.023s\n",
      "eval: [2920/7902] | data 0.070s | net 0.023s\n",
      "eval: [2940/7902] | data 0.077s | net 0.024s\n",
      "eval: [2960/7902] | data 0.073s | net 0.023s\n",
      "eval: [2980/7902] | data 0.083s | net 0.023s\n",
      "eval: [3000/7902] | data 0.024s | net 0.023s\n",
      "eval: [3020/7902] | data 0.106s | net 0.023s\n",
      "eval: [3040/7902] | data 0.089s | net 0.023s\n",
      "eval: [3060/7902] | data 0.048s | net 0.023s\n",
      "eval: [3080/7902] | data 0.071s | net 0.023s\n",
      "eval: [3100/7902] | data 0.070s | net 0.023s\n",
      "eval: [3120/7902] | data 0.069s | net 0.023s\n",
      "eval: [3140/7902] | data 0.059s | net 0.023s\n",
      "eval: [3160/7902] | data 0.071s | net 0.023s\n",
      "eval: [3180/7902] | data 0.073s | net 0.024s\n",
      "eval: [3200/7902] | data 0.075s | net 0.023s\n",
      "eval: [3220/7902] | data 0.074s | net 0.023s\n",
      "eval: [3240/7902] | data 0.097s | net 0.025s\n",
      "eval: [3260/7902] | data 0.075s | net 0.024s\n",
      "eval: [3280/7902] | data 0.072s | net 0.024s\n",
      "eval: [3300/7902] | data 0.084s | net 0.025s\n",
      "eval: [3320/7902] | data 0.050s | net 0.025s\n",
      "eval: [3340/7902] | data 0.067s | net 0.024s\n",
      "eval: [3360/7902] | data 0.070s | net 0.025s\n",
      "eval: [3380/7902] | data 0.035s | net 0.024s\n",
      "eval: [3400/7902] | data 0.069s | net 0.024s\n",
      "eval: [3420/7902] | data 0.025s | net 0.024s\n",
      "eval: [3440/7902] | data 0.086s | net 0.026s\n",
      "eval: [3460/7902] | data 0.145s | net 0.023s\n",
      "eval: [3480/7902] | data 0.075s | net 0.023s\n",
      "eval: [3500/7902] | data 0.082s | net 0.024s\n",
      "eval: [3520/7902] | data 0.077s | net 0.024s\n",
      "eval: [3540/7902] | data 0.077s | net 0.023s\n",
      "eval: [3560/7902] | data 0.088s | net 0.025s\n",
      "eval: [3580/7902] | data 0.076s | net 0.024s\n",
      "eval: [3600/7902] | data 0.074s | net 0.024s\n",
      "eval: [3620/7902] | data 0.073s | net 0.023s\n",
      "eval: [3640/7902] | data 0.073s | net 0.023s\n",
      "eval: [3660/7902] | data 0.091s | net 0.023s\n",
      "eval: [3680/7902] | data 0.076s | net 0.024s\n",
      "eval: [3700/7902] | data 0.075s | net 0.024s\n",
      "eval: [3720/7902] | data 0.039s | net 0.023s\n",
      "eval: [3740/7902] | data 0.041s | net 0.023s\n",
      "eval: [3760/7902] | data 0.041s | net 0.023s\n",
      "eval: [3780/7902] | data 0.040s | net 0.023s\n",
      "eval: [3800/7902] | data 0.038s | net 0.024s\n",
      "eval: [3820/7902] | data 0.058s | net 0.024s\n",
      "eval: [3840/7902] | data 0.058s | net 0.025s\n",
      "eval: [3860/7902] | data 0.052s | net 0.023s\n",
      "eval: [3880/7902] | data 0.064s | net 0.023s\n",
      "eval: [3900/7902] | data 0.039s | net 0.024s\n",
      "eval: [3920/7902] | data 0.039s | net 0.024s\n",
      "eval: [3940/7902] | data 0.038s | net 0.023s\n",
      "eval: [3960/7902] | data 0.052s | net 0.024s\n",
      "eval: [3980/7902] | data 0.087s | net 0.024s\n",
      "eval: [4000/7902] | data 0.052s | net 0.023s\n",
      "eval: [4020/7902] | data 0.061s | net 0.023s\n",
      "eval: [4040/7902] | data 0.056s | net 0.024s\n",
      "eval: [4060/7902] | data 0.038s | net 0.024s\n",
      "eval: [4080/7902] | data 0.039s | net 0.024s\n",
      "eval: [4100/7902] | data 0.073s | net 0.024s\n",
      "eval: [4120/7902] | data 0.054s | net 0.023s\n",
      "eval: [4140/7902] | data 0.061s | net 0.024s\n",
      "eval: [4160/7902] | data 0.041s | net 0.024s\n",
      "eval: [4180/7902] | data 0.076s | net 0.024s\n",
      "eval: [4200/7902] | data 0.057s | net 0.025s\n",
      "eval: [4220/7902] | data 0.038s | net 0.024s\n",
      "eval: [4240/7902] | data 0.040s | net 0.024s\n",
      "eval: [4260/7902] | data 0.038s | net 0.024s\n",
      "eval: [4280/7902] | data 0.055s | net 0.023s\n",
      "eval: [4300/7902] | data 0.054s | net 0.023s\n",
      "eval: [4320/7902] | data 0.054s | net 0.023s\n",
      "eval: [4340/7902] | data 0.055s | net 0.023s\n",
      "eval: [4360/7902] | data 0.070s | net 0.024s\n",
      "eval: [4380/7902] | data 0.039s | net 0.024s\n",
      "eval: [4400/7902] | data 0.038s | net 0.023s\n",
      "eval: [4420/7902] | data 0.039s | net 0.024s\n",
      "eval: [4440/7902] | data 0.099s | net 0.024s\n",
      "eval: [4460/7902] | data 0.104s | net 0.024s\n",
      "eval: [4480/7902] | data 0.088s | net 0.023s\n",
      "eval: [4500/7902] | data 0.103s | net 0.023s\n",
      "eval: [4520/7902] | data 0.057s | net 0.023s\n",
      "eval: [4540/7902] | data 0.039s | net 0.022s\n",
      "eval: [4560/7902] | data 0.039s | net 0.023s\n",
      "eval: [4580/7902] | data 0.039s | net 0.023s\n",
      "eval: [4600/7902] | data 0.125s | net 0.023s\n",
      "eval: [4620/7902] | data 0.144s | net 0.022s\n",
      "eval: [4640/7902] | data 0.105s | net 0.023s\n",
      "eval: [4660/7902] | data 0.058s | net 0.023s\n",
      "eval: [4680/7902] | data 0.159s | net 0.023s\n",
      "eval: [4700/7902] | data 0.038s | net 0.023s\n",
      "eval: [4720/7902] | data 0.168s | net 0.023s\n",
      "eval: [4740/7902] | data 0.148s | net 0.023s\n",
      "eval: [4760/7902] | data 0.090s | net 0.024s\n",
      "eval: [4780/7902] | data 0.102s | net 0.024s\n",
      "eval: [4800/7902] | data 0.090s | net 0.023s\n",
      "eval: [4820/7902] | data 0.151s | net 0.023s\n",
      "eval: [4840/7902] | data 0.099s | net 0.024s\n",
      "eval: [4860/7902] | data 0.090s | net 0.024s\n",
      "eval: [4880/7902] | data 0.057s | net 0.023s\n",
      "eval: [4900/7902] | data 0.080s | net 0.023s\n",
      "eval: [4920/7902] | data 0.085s | net 0.023s\n",
      "eval: [4940/7902] | data 0.027s | net 0.023s\n",
      "eval: [4960/7902] | data 0.079s | net 0.023s\n",
      "eval: [4980/7902] | data 0.121s | net 0.023s\n",
      "eval: [5000/7902] | data 0.096s | net 0.023s\n",
      "eval: [5020/7902] | data 0.137s | net 0.022s\n",
      "eval: [5040/7902] | data 0.135s | net 0.023s\n",
      "eval: [5060/7902] | data 0.102s | net 0.023s\n",
      "eval: [5080/7902] | data 0.113s | net 0.023s\n",
      "eval: [5100/7902] | data 0.129s | net 0.022s\n",
      "eval: [5120/7902] | data 0.133s | net 0.022s\n",
      "eval: [5140/7902] | data 0.133s | net 0.023s\n",
      "eval: [5160/7902] | data 0.120s | net 0.023s\n",
      "eval: [5180/7902] | data 0.137s | net 0.022s\n",
      "eval: [5200/7902] | data 0.277s | net 0.022s\n",
      "eval: [5220/7902] | data 0.309s | net 0.022s\n",
      "eval: [5240/7902] | data 0.324s | net 0.022s\n",
      "eval: [5260/7902] | data 0.311s | net 0.022s\n",
      "eval: [5280/7902] | data 0.282s | net 0.023s\n",
      "eval: [5300/7902] | data 0.312s | net 0.023s\n",
      "eval: [5320/7902] | data 0.309s | net 0.022s\n",
      "eval: [5340/7902] | data 0.321s | net 0.023s\n",
      "eval: [5360/7902] | data 0.310s | net 0.023s\n",
      "eval: [5380/7902] | data 0.304s | net 0.023s\n",
      "eval: [5400/7902] | data 0.410s | net 0.023s\n",
      "eval: [5420/7902] | data 0.352s | net 0.023s\n",
      "eval: [5440/7902] | data 0.282s | net 0.023s\n",
      "eval: [5460/7902] | data 0.316s | net 0.023s\n",
      "eval: [5480/7902] | data 0.324s | net 0.023s\n",
      "eval: [5500/7902] | data 0.265s | net 0.022s\n",
      "eval: [5520/7902] | data 0.303s | net 0.022s\n",
      "eval: [5540/7902] | data 0.299s | net 0.022s\n",
      "eval: [5560/7902] | data 0.319s | net 0.022s\n",
      "eval: [5580/7902] | data 0.340s | net 0.022s\n",
      "eval: [5600/7902] | data 0.057s | net 0.023s\n",
      "eval: [5620/7902] | data 0.054s | net 0.023s\n",
      "eval: [5640/7902] | data 0.041s | net 0.022s\n",
      "eval: [5660/7902] | data 0.039s | net 0.022s\n",
      "eval: [5680/7902] | data 0.058s | net 0.023s\n",
      "eval: [5700/7902] | data 0.041s | net 0.024s\n",
      "eval: [5720/7902] | data 0.081s | net 0.023s\n",
      "eval: [5740/7902] | data 0.054s | net 0.023s\n",
      "eval: [5760/7902] | data 0.040s | net 0.023s\n",
      "eval: [5780/7902] | data 0.056s | net 0.023s\n",
      "eval: [5800/7902] | data 0.055s | net 0.024s\n",
      "eval: [5820/7902] | data 0.040s | net 0.024s\n",
      "eval: [5840/7902] | data 0.080s | net 0.023s\n",
      "eval: [5860/7902] | data 0.069s | net 0.025s\n",
      "eval: [5880/7902] | data 0.067s | net 0.023s\n",
      "eval: [5900/7902] | data 0.054s | net 0.022s\n",
      "eval: [5920/7902] | data 0.040s | net 0.024s\n",
      "eval: [5940/7902] | data 0.069s | net 0.024s\n",
      "eval: [5960/7902] | data 0.101s | net 0.023s\n",
      "eval: [5980/7902] | data 0.082s | net 0.023s\n",
      "eval: [6000/7902] | data 0.088s | net 0.023s\n",
      "eval: [6020/7902] | data 0.085s | net 0.023s\n",
      "eval: [6040/7902] | data 0.127s | net 0.023s\n",
      "eval: [6060/7902] | data 0.090s | net 0.023s\n",
      "eval: [6080/7902] | data 0.078s | net 0.022s\n",
      "eval: [6100/7902] | data 0.112s | net 0.023s\n",
      "eval: [6120/7902] | data 0.094s | net 0.022s\n",
      "eval: [6140/7902] | data 0.077s | net 0.023s\n",
      "eval: [6160/7902] | data 0.074s | net 0.023s\n",
      "eval: [6180/7902] | data 0.097s | net 0.023s\n",
      "eval: [6200/7902] | data 0.076s | net 0.023s\n",
      "eval: [6220/7902] | data 0.064s | net 0.023s\n",
      "eval: [6240/7902] | data 0.099s | net 0.023s\n",
      "eval: [6260/7902] | data 0.093s | net 0.023s\n",
      "eval: [6280/7902] | data 0.072s | net 0.023s\n",
      "eval: [6300/7902] | data 0.075s | net 0.023s\n",
      "eval: [6320/7902] | data 0.074s | net 0.023s\n",
      "eval: [6340/7902] | data 0.088s | net 0.023s\n",
      "eval: [6360/7902] | data 0.099s | net 0.024s\n",
      "eval: [6380/7902] | data 0.121s | net 0.023s\n",
      "eval: [6400/7902] | data 0.088s | net 0.024s\n",
      "eval: [6420/7902] | data 0.112s | net 0.023s\n",
      "eval: [6440/7902] | data 0.083s | net 0.023s\n",
      "eval: [6460/7902] | data 0.077s | net 0.025s\n",
      "eval: [6480/7902] | data 0.073s | net 0.023s\n",
      "eval: [6500/7902] | data 0.075s | net 0.023s\n",
      "eval: [6520/7902] | data 0.066s | net 0.025s\n",
      "eval: [6540/7902] | data 0.121s | net 0.023s\n",
      "eval: [6560/7902] | data 0.073s | net 0.023s\n",
      "eval: [6580/7902] | data 0.074s | net 0.023s\n",
      "eval: [6600/7902] | data 0.073s | net 0.023s\n",
      "eval: [6620/7902] | data 0.073s | net 0.023s\n",
      "eval: [6640/7902] | data 0.080s | net 0.023s\n",
      "eval: [6660/7902] | data 0.082s | net 0.023s\n",
      "eval: [6680/7902] | data 0.089s | net 0.023s\n",
      "eval: [6700/7902] | data 0.118s | net 0.023s\n",
      "eval: [6720/7902] | data 0.065s | net 0.023s\n",
      "eval: [6740/7902] | data 0.080s | net 0.023s\n",
      "eval: [6760/7902] | data 0.076s | net 0.023s\n",
      "eval: [6780/7902] | data 0.114s | net 0.024s\n",
      "eval: [6800/7902] | data 0.088s | net 0.023s\n",
      "eval: [6820/7902] | data 0.076s | net 0.023s\n",
      "eval: [6840/7902] | data 0.090s | net 0.023s\n",
      "eval: [6860/7902] | data 0.079s | net 0.023s\n",
      "eval: [6880/7902] | data 0.066s | net 0.023s\n",
      "eval: [6900/7902] | data 0.071s | net 0.023s\n",
      "eval: [6920/7902] | data 0.273s | net 0.022s\n",
      "eval: [6940/7902] | data 0.181s | net 0.022s\n",
      "eval: [6960/7902] | data 0.303s | net 0.022s\n",
      "eval: [6980/7902] | data 0.350s | net 0.022s\n",
      "eval: [7000/7902] | data 0.339s | net 0.022s\n",
      "eval: [7020/7902] | data 0.344s | net 0.022s\n",
      "eval: [7040/7902] | data 0.338s | net 0.022s\n",
      "eval: [7060/7902] | data 0.361s | net 0.022s\n",
      "eval: [7080/7902] | data 0.353s | net 0.023s\n",
      "eval: [7100/7902] | data 0.315s | net 0.025s\n",
      "eval: [7120/7902] | data 0.350s | net 0.023s\n",
      "eval: [7140/7902] | data 0.366s | net 0.023s\n",
      "eval: [7160/7902] | data 0.178s | net 0.022s\n",
      "eval: [7180/7902] | data 0.303s | net 0.022s\n",
      "eval: [7200/7902] | data 0.286s | net 0.022s\n",
      "eval: [7220/7902] | data 0.198s | net 0.023s\n",
      "eval: [7240/7902] | data 0.329s | net 0.022s\n",
      "eval: [7260/7902] | data 0.304s | net 0.022s\n",
      "eval: [7280/7902] | data 0.318s | net 0.025s\n",
      "eval: [7300/7902] | data 0.175s | net 0.023s\n",
      "eval: [7320/7902] | data 0.331s | net 0.022s\n",
      "eval: [7340/7902] | data 0.340s | net 0.023s\n",
      "eval: [7360/7902] | data 0.315s | net 0.023s\n",
      "eval: [7380/7902] | data 0.255s | net 0.022s\n",
      "eval: [7400/7902] | data 0.307s | net 0.022s\n",
      "eval: [7420/7902] | data 0.342s | net 0.023s\n",
      "eval: [7440/7902] | data 0.372s | net 0.023s\n",
      "eval: [7460/7902] | data 0.324s | net 0.023s\n",
      "eval: [7480/7902] | data 0.311s | net 0.022s\n",
      "eval: [7500/7902] | data 0.181s | net 0.023s\n",
      "eval: [7520/7902] | data 0.343s | net 0.023s\n",
      "eval: [7540/7902] | data 0.350s | net 0.022s\n",
      "eval: [7560/7902] | data 0.348s | net 0.022s\n",
      "eval: [7580/7902] | data 0.231s | net 0.023s\n",
      "eval: [7600/7902] | data 0.418s | net 0.022s\n",
      "eval: [7620/7902] | data 0.274s | net 0.022s\n",
      "eval: [7640/7902] | data 0.197s | net 0.024s\n",
      "eval: [7660/7902] | data 0.356s | net 0.022s\n",
      "eval: [7680/7902] | data 0.296s | net 0.022s\n",
      "eval: [7700/7902] | data 0.394s | net 0.022s\n",
      "eval: [7720/7902] | data 0.319s | net 0.022s\n",
      "eval: [7740/7902] | data 0.385s | net 0.022s\n",
      "eval: [7760/7902] | data 0.360s | net 0.022s\n",
      "eval: [7780/7902] | data 0.387s | net 0.023s\n",
      "eval: [7800/7902] | data 0.319s | net 0.022s\n",
      "eval: [7820/7902] | data 0.353s | net 0.022s\n",
      "eval: [7840/7902] | data 0.356s | net 0.023s\n",
      "eval: [7860/7902] | data 0.337s | net 0.022s\n",
      "eval: [7880/7902] | data 0.368s | net 0.023s\n",
      "eval: [7900/7902] | data 0.401s | net 0.022s\n",
      "Elapsed 17.45min (132.5ms/image, 7.5frames/s)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib/results/plot: File exists\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bike_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bike_orientation.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (car_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (car_orientation.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for participating in our evaluation!\n",
      "Loading detections...\n",
      "  done.\n",
      "Your evaluation results are available in /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib/results\n",
      "bike_easy            0.273\n",
      "bike_moderate        0.272\n",
      "bike_hard            0.272\n",
      "car_easy             0.740\n",
      "car_moderate         0.736\n",
      "car_hard             0.736\n",
      "bus_easy             0.391\n",
      "bus_moderate         0.391\n",
      "bus_hard             0.391\n",
      "mAP                  0.467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bus_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bus_orientation.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for method in [\"percentile\", \"mse\", \"entropy\"]:\n",
    "        percentile = 99.99\n",
    "        print(F\" ############  {method} calibration ######################\")\n",
    "        if(method == 'percentile'):\n",
    "            compute_amax(detector.model, method=method, percentile = percentile)\n",
    "        else:\n",
    "            compute_amax(detector.model, method=method)\n",
    "        update_exp_dir(cfg, f\"trt_calib_veh_det_{method}\")\n",
    "        results = detector.detect_dataset(eval_dataset, cfg)\n",
    "        eval_dataset.save_results(results)\n",
    "        aps = eval_dataset.evaluate()\n",
    "        for k, v in aps.items():\n",
    "                print('{:<20} {:.3f}'.format(k, v))\n",
    "        torch.save(detector.model.state_dict(), os.path.join(cfg.save_dir, f\"quant_veh_det_squeezedet_{method}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print (detector.model)\n",
    "# print (detector.model.base.features[0][0].input_quantizer.amax)\n",
    "# print (detector.model.base.features[0][0].weight_quantizer.amax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_dataset.save_results(results)\n",
    "# aps = eval_dataset.evaluate()\n",
    "# for k, v in aps.items():\n",
    "#         print('{:<20} {:.3f}'.format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(detector.model.state_dict(), \"../exp/quant_lp_squeezedet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = detector.model.base\n",
    "# test.cpu()\n",
    "# quant_nn.TensorQuantizer.use_fb_fake_quant = True\n",
    "# dummy_input = torch.randn(1, 3, 128, 128)\n",
    "\n",
    "# # input_names = [ \"network.0\" ]\n",
    "# # output_names = [ \"network.23\" ]\n",
    "\n",
    "# # enable_onnx_checker needs to be disabled. See notes below.\n",
    "# torch.onnx.export(\n",
    "#     test, dummy_input, \"../exp/test.onnx\", verbose=True, opset_version=13, enable_onnx_checker=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('squeezedet_qat_trt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3c2669bd7e07172b05d24bdf6d2bf9c1c04a6520ab7af118b1064f77a2781ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
