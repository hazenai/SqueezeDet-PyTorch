{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_quantization import tensor_quant\n",
    "\n",
    "from torch import nn, outer\n",
    "\n",
    "from pytorch_quantization import tensor_quant\n",
    "import pytorch_quantization.nn as quant_nn\n",
    "import pytorch_quantization\n",
    "pytorch_quantization.__version__\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.yolo import YOLO\n",
    "from engine.detector import Detector\n",
    "from model.squeezedet import SqueezeDet, SqueezeDetWithLoss\n",
    "from utils.config import Config\n",
    "from utils.model import load_model\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from utils.misc import init_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arch                           squeezedet\n",
      "batch_size                     1\n",
      "bbox_loss_weight               20.0\n",
      "chunk_sizes                    [32]\n",
      "class_loss_weight              1.0\n",
      "data_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/data\n",
      "dataset                        lpr\n",
      "debug                          2\n",
      "debug_dir                      /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/debug\n",
      "device                         cuda\n",
      "drift_prob                     1.0\n",
      "dropout_prob                   0\n",
      "exp_dir                        /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp\n",
      "exp_id                         test_lpd_sqdet_trt_calib\n",
      "flip_prob                      0.5\n",
      "forbid_resize                  False\n",
      "gpus                           [0]\n",
      "gpus_str                       0\n",
      "grad_norm                      0.5\n",
      "keep_top_k                     64\n",
      "load_model                     ../exp/alpr_det.pth\n",
      "load_pretrained                True\n",
      "log_file                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/training_logs.txt\n",
      "lr                             0.001\n",
      "master_batch_size              32\n",
      "mode                           eval\n",
      "momentum                       0.9\n",
      "negative_score_loss_weight     100.0\n",
      "nms_thresh                     0.4\n",
      "no_eval                        False\n",
      "not_cuda_benchmark             False\n",
      "num_epochs                     100\n",
      "num_iters                      -1\n",
      "num_workers                    0\n",
      "positive_score_loss_weight     3.75\n",
      "print_interval                 20\n",
      "qat                            False\n",
      "root_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch\n",
      "save_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib\n",
      "save_intervals                 1\n",
      "score_thresh                   0.5\n",
      "seed                           42\n",
      "stride                         16\n",
      "val_intervals                  1\n",
      "weight_decay                   0.0001\n"
     ]
    }
   ],
   "source": [
    "args = {'_': '_'}\n",
    "cfg = Config().parse(args)\n",
    "\n",
    "init_env(cfg) \n",
    " \n",
    "cfg.mode = 'eval'\n",
    "cfg.exp_id = \"test_lpd_sqdet_trt_calib\"\n",
    "cfg.dataset = 'lpr'\n",
    "cfg.load_model = '../exp/alpr_det.pth' \n",
    "cfg.batch_size = 1\n",
    "cfg.arch = 'squeezedet'\n",
    "cfg.num_workers = 0\n",
    "cfg.save_intervals = 1\n",
    "cfg.debug = 2\n",
    "cfg.load_pretrained = True\n",
    "\n",
    "def update_exp_dir(cfg, exp_id):\n",
    "    cfg.save_dir = os.path.join(cfg.exp_dir, exp_id)\n",
    "    os.makedirs(cfg.save_dir, exist_ok=True)\n",
    "    cfg.log_file = os.path.join(cfg.save_dir, 'training_logs.txt')\n",
    "    os.remove(cfg.log_file) if os.path.exists(cfg.log_file) else None\n",
    "    cfg.debug_dir = os.path.join(cfg.save_dir, 'debug')\n",
    "\n",
    "update_exp_dir(cfg, cfg.exp_id)\n",
    "\n",
    "Config().print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine.detector import Detector\n",
    "from model.squeezedet import SqueezeDetWithLoss\n",
    "from utils.model import load_model\n",
    "from utils.misc import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchors                        [[  8.   8.   6.   5.]\n",
      " [  8.   8.  12.  10.]\n",
      " [  8.   8.  18.  10.]\n",
      " ...\n",
      " [248. 248.  18.  18.]\n",
      " [248. 248.  20.  24.]\n",
      " [248. 248.  30.  15.]]\n",
      "anchors_per_grid               6\n",
      "arch                           squeezedet\n",
      "batch_size                     1\n",
      "bbox_loss_weight               20.0\n",
      "chunk_sizes                    [32]\n",
      "class_loss_weight              1.0\n",
      "class_names                    0\n",
      "data_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/data\n",
      "dataset                        lpr\n",
      "debug                          2\n",
      "debug_dir                      /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/debug\n",
      "device                         cuda\n",
      "drift_prob                     1.0\n",
      "dropout_prob                   0\n",
      "exp_dir                        /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp\n",
      "exp_id                         test_lpd_sqdet_trt_calib\n",
      "flip_prob                      0.5\n",
      "forbid_resize                  False\n",
      "gpus                           [0]\n",
      "gpus_str                       0\n",
      "grad_norm                      0.5\n",
      "grid_size                      (16, 16)\n",
      "input_size                     (256, 256)\n",
      "keep_top_k                     64\n",
      "load_model                     ../exp/alpr_det.pth\n",
      "load_pretrained                True\n",
      "log_file                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/training_logs.txt\n",
      "lr                             0.001\n",
      "master_batch_size              32\n",
      "mode                           eval\n",
      "momentum                       0.9\n",
      "negative_score_loss_weight     100.0\n",
      "nms_thresh                     0.4\n",
      "no_eval                        False\n",
      "not_cuda_benchmark             False\n",
      "num_anchors                    1536\n",
      "num_classes                    1\n",
      "num_epochs                     100\n",
      "num_iters                      -1\n",
      "num_workers                    0\n",
      "positive_score_loss_weight     3.75\n",
      "print_interval                 20\n",
      "qat                            False\n",
      "rgb_mean                       [[[97.631615 98.70732  98.41285 ]]]\n",
      "rgb_std                        [[[52.766678 52.63513  52.348827]]]\n",
      "root_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch\n",
      "save_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib\n",
      "save_intervals                 1\n",
      "score_thresh                   0.5\n",
      "seed                           42\n",
      "stride                         16\n",
      "val_intervals                  1\n",
      "weight_decay                   0.0001\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(cfg.dataset)('val', cfg)\n",
    "cfg = Config().update_dataset_info(cfg, dataset)\n",
    "Config().print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchors                        [[  8.   8.   6.   5.]\n",
      " [  8.   8.  12.  10.]\n",
      " [  8.   8.  18.  10.]\n",
      " ...\n",
      " [248. 248.  18.  18.]\n",
      " [248. 248.  20.  24.]\n",
      " [248. 248.  30.  15.]]\n",
      "anchors_per_grid               6\n",
      "arch                           squeezedet\n",
      "batch_size                     1\n",
      "bbox_loss_weight               20.0\n",
      "chunk_sizes                    [32]\n",
      "class_loss_weight              1.0\n",
      "class_names                    0\n",
      "data_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/data\n",
      "dataset                        lpr\n",
      "debug                          2\n",
      "debug_dir                      /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/debug\n",
      "device                         cuda\n",
      "drift_prob                     1.0\n",
      "dropout_prob                   0\n",
      "exp_dir                        /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp\n",
      "exp_id                         test_lpd_sqdet_trt_calib\n",
      "flip_prob                      0.5\n",
      "forbid_resize                  False\n",
      "gpus                           [0]\n",
      "gpus_str                       0\n",
      "grad_norm                      0.5\n",
      "grid_size                      (16, 16)\n",
      "input_size                     (256, 256)\n",
      "keep_top_k                     64\n",
      "load_model                     ../exp/alpr_det.pth\n",
      "load_pretrained                True\n",
      "log_file                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/training_logs.txt\n",
      "lr                             0.001\n",
      "master_batch_size              32\n",
      "mode                           eval\n",
      "momentum                       0.9\n",
      "negative_score_loss_weight     100.0\n",
      "nms_thresh                     0.4\n",
      "no_eval                        False\n",
      "not_cuda_benchmark             False\n",
      "num_anchors                    1536\n",
      "num_classes                    1\n",
      "num_epochs                     100\n",
      "num_iters                      -1\n",
      "num_workers                    0\n",
      "positive_score_loss_weight     3.75\n",
      "print_interval                 20\n",
      "qat                            False\n",
      "rgb_mean                       [[[97.631615 98.70732  98.41285 ]]]\n",
      "rgb_std                        [[[52.766678 52.63513  52.348827]]]\n",
      "root_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch\n",
      "save_dir                       /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib\n",
      "save_intervals                 1\n",
      "score_thresh                   0.5\n",
      "seed                           42\n",
      "stride                         16\n",
      "val_intervals                  1\n",
      "weight_decay                   0.0001\n",
      "loaded model ../exp/alpr_det.pth, epoch 268\n",
      "Model successfully loaded.\n",
      "eval: [0/1530] | data 0.038s | net 0.232s\n",
      "eval: [20/1530] | data 0.006s | net 0.012s\n",
      "eval: [40/1530] | data 0.007s | net 0.015s\n",
      "eval: [60/1530] | data 0.010s | net 0.004s\n",
      "eval: [80/1530] | data 0.014s | net 0.030s\n",
      "eval: [100/1530] | data 0.027s | net 0.060s\n",
      "eval: [120/1530] | data 0.005s | net 0.012s\n",
      "eval: [140/1530] | data 0.028s | net 0.066s\n",
      "eval: [160/1530] | data 0.007s | net 0.015s\n",
      "eval: [180/1530] | data 0.004s | net 0.005s\n",
      "eval: [200/1530] | data 0.013s | net 0.030s\n",
      "eval: [220/1530] | data 0.041s | net 0.111s\n",
      "eval: [240/1530] | data 0.018s | net 0.036s\n",
      "eval: [260/1530] | data 0.007s | net 0.014s\n",
      "eval: [280/1530] | data 0.003s | net 0.005s\n",
      "eval: [300/1530] | data 0.011s | net 0.025s\n",
      "eval: [320/1530] | data 0.005s | net 0.012s\n",
      "eval: [340/1530] | data 0.011s | net 0.024s\n",
      "eval: [360/1530] | data 0.021s | net 0.054s\n",
      "eval: [380/1530] | data 0.008s | net 0.019s\n",
      "eval: [400/1530] | data 0.020s | net 0.044s\n",
      "eval: [420/1530] | data 0.004s | net 0.010s\n",
      "eval: [440/1530] | data 0.033s | net 0.078s\n",
      "eval: [460/1530] | data 0.003s | net 0.006s\n",
      "eval: [480/1530] | data 0.003s | net 0.005s\n",
      "eval: [500/1530] | data 0.008s | net 0.017s\n",
      "eval: [520/1530] | data 0.006s | net 0.013s\n",
      "eval: [540/1530] | data 0.004s | net 0.009s\n",
      "eval: [560/1530] | data 0.015s | net 0.033s\n",
      "eval: [580/1530] | data 0.029s | net 0.067s\n",
      "eval: [600/1530] | data 0.009s | net 0.022s\n",
      "eval: [620/1530] | data 0.004s | net 0.006s\n",
      "eval: [640/1530] | data 0.006s | net 0.010s\n",
      "eval: [660/1530] | data 0.004s | net 0.007s\n",
      "eval: [680/1530] | data 0.007s | net 0.013s\n",
      "eval: [700/1530] | data 0.008s | net 0.019s\n",
      "eval: [720/1530] | data 0.006s | net 0.011s\n",
      "eval: [740/1530] | data 0.007s | net 0.015s\n",
      "eval: [760/1530] | data 0.007s | net 0.016s\n",
      "eval: [780/1530] | data 0.006s | net 0.014s\n",
      "eval: [800/1530] | data 0.005s | net 0.010s\n",
      "eval: [820/1530] | data 0.013s | net 0.031s\n",
      "eval: [840/1530] | data 0.008s | net 0.021s\n",
      "eval: [860/1530] | data 0.018s | net 0.040s\n",
      "eval: [880/1530] | data 0.007s | net 0.010s\n",
      "eval: [900/1530] | data 0.003s | net 0.004s\n",
      "eval: [920/1530] | data 0.007s | net 0.016s\n",
      "eval: [940/1530] | data 0.004s | net 0.008s\n",
      "eval: [960/1530] | data 0.015s | net 0.026s\n",
      "eval: [980/1530] | data 0.019s | net 0.045s\n",
      "eval: [1000/1530] | data 0.014s | net 0.031s\n",
      "eval: [1020/1530] | data 0.028s | net 0.065s\n",
      "eval: [1040/1530] | data 0.022s | net 0.049s\n",
      "eval: [1060/1530] | data 0.004s | net 0.008s\n",
      "eval: [1080/1530] | data 0.004s | net 0.007s\n",
      "eval: [1100/1530] | data 0.017s | net 0.041s\n",
      "eval: [1120/1530] | data 0.016s | net 0.038s\n",
      "eval: [1140/1530] | data 0.009s | net 0.019s\n",
      "eval: [1160/1530] | data 0.005s | net 0.011s\n",
      "eval: [1180/1530] | data 0.009s | net 0.019s\n",
      "eval: [1200/1530] | data 0.008s | net 0.021s\n",
      "eval: [1220/1530] | data 0.023s | net 0.053s\n",
      "eval: [1240/1530] | data 0.006s | net 0.012s\n",
      "eval: [1260/1530] | data 0.004s | net 0.007s\n",
      "eval: [1280/1530] | data 0.004s | net 0.008s\n",
      "eval: [1300/1530] | data 0.019s | net 0.041s\n",
      "eval: [1320/1530] | data 0.009s | net 0.021s\n",
      "eval: [1340/1530] | data 0.028s | net 0.066s\n",
      "eval: [1360/1530] | data 0.008s | net 0.018s\n",
      "eval: [1380/1530] | data 0.003s | net 0.005s\n",
      "eval: [1400/1530] | data 0.003s | net 0.007s\n",
      "eval: [1420/1530] | data 0.028s | net 0.065s\n",
      "eval: [1440/1530] | data 0.004s | net 0.009s\n",
      "eval: [1460/1530] | data 0.004s | net 0.010s\n",
      "eval: [1480/1530] | data 0.011s | net 0.025s\n",
      "eval: [1500/1530] | data 0.008s | net 0.015s\n",
      "eval: [1520/1530] | data 0.005s | net 0.009s\n",
      "Elapsed 0.86min (33.7ms/image, 29.7frames/s)\n",
      "--------------------------------------------------------------------------------\n",
      "/media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/src/utils/kitti-eval/cpp/evaluate_object /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data/val.txt /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/results 1530\n",
      "gt dir:/media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data/labels\n",
      "Thank you for participating in our evaluation!\n",
      "filename: /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/results/plot’: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading detections...\n",
      "  done.\n",
      "Your evaluation results are available in /media/gj_data/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/results\n",
      "0_easy               0.894\n",
      "0_moderate           0.894\n",
      "0_hard               0.894\n",
      "mAP                  0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (car_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:731/1123(ro)(G)--   --dict:0/20(G)--   --dict:75/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.50: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n"
     ]
    }
   ],
   "source": [
    "from utils.misc import init_env\n",
    "init_env(cfg)\n",
    "from eval import eval\n",
    "eval(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0902 22:06:11.508260 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.508705 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.509101 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.509482 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.517278 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.517872 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.518282 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.518712 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.526389 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.526901 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.527338 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.527746 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.535450 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.536286 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.536660 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.536981 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.544049 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.544536 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.545120 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.545526 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.553744 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.554245 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.554634 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.554992 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.564546 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.565126 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.565740 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.566281 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.574768 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.575340 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.575700 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.576106 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.582715 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.583349 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.583778 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.584129 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.591371 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.591856 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.592255 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.592636 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.601099 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.601575 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.602101 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.602637 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.610785 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.611294 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.611672 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.612110 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.620034 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.620524 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.620921 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.621322 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.628627 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.629090 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.629443 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.629770 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.637873 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.638361 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.638767 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.639199 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.647721 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.648210 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.648770 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.649181 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.658115 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.658719 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.659107 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.659483 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.667183 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.667674 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.668072 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.668462 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.675993 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.676565 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.676962 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.677325 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.686060 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.690202 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.690746 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.691430 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.698852 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.699383 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.699798 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.700174 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.708792 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.709541 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.709971 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.710336 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.720539 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.720989 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.721385 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.721811 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.730249 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.730716 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.731107 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.731467 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.741041 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.741513 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.741931 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.742332 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I0902 22:06:11.760286 139837141516480 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I0902 22:06:11.760866 139837141516480 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I0902 22:06:11.761411 139837141516480 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I0902 22:06:11.761745 139837141516480 tensor_quantizer.py:105] Creating Max calibrator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model ../exp/alpr_det.pth, epoch 268\n",
      "Model successfully loaded.\n",
      "SqueezeDetWithLoss(\n",
      "  (base): SqueezeDetBase(\n",
      "    (quant): QuantStub()\n",
      "    (dequant): DeQuantStub()\n",
      "    (conv1): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "      (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "      (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "    )\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (features): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (1): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          64, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          16, 64, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          128, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          16, 64, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (4): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          128, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          32, 128, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          256, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          32, 128, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (7): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          256, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          48, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (8): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          384, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          48, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (9): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (10): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          512, 64, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (convdet): QuantConv2d(\n",
      "      512, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "      (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "    )\n",
      "  )\n",
      "  (resolver): PredictionResolver()\n",
      "  (loss): Loss(\n",
      "    (resolver): PredictionResolver()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if cfg.mode=='eval':\n",
    "        model = SqueezeDetWithLoss(cfg)\n",
    "        model = load_model(model, cfg.load_model, cfg)\n",
    "\n",
    "\n",
    "model.detect = True\n",
    "detector = Detector(model, cfg)\n",
    "print(detector.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)  # Disable logging as they are too noisy in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_desc_input = QuantDescriptor(calib_method='histogram')\n",
    "quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)\n",
    "quant_nn.QuantLinear.set_default_quant_desc_input(quant_desc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import quant_modules\n",
    "quant_modules.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_stats(model, data_loader, num_batches):\n",
    "    \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "    # Enable calibrators\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.disable_quant()\n",
    "                module.enable_calib()\n",
    "            else:\n",
    "                module.disable()\n",
    "\n",
    "    # for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "    #     model(image.cuda())\n",
    "    #     if i >= num_batches:\n",
    "    #         break\n",
    "    # since lpr dataloader return a dict, so writing it in this way\n",
    "    for i, (batch) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "        for k in batch:\n",
    "                if 'image_meta' not in k:\n",
    "                    batch[k] = batch[k].to(device=cfg.device, non_blocking=True)\n",
    "        model(batch)\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "\n",
    "    # Disable calibrators\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.enable_quant()\n",
    "                module.disable_calib()\n",
    "            else:\n",
    "                module.enable()\n",
    "            \n",
    "def compute_amax(model, **kwargs):\n",
    "    # Load calib result\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                    module.load_calib_amax()\n",
    "                else:\n",
    "                    module.load_calib_amax(**kwargs)\n",
    "#             print(F\"{name:40}: {module}\")\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "\n",
    "from datasets.base import BaseDataset\n",
    "from utils.boxes import generate_anchors\n",
    "from PIL import Image\n",
    "from torchvision.datasets.folder import default_loader\n",
    "\n",
    "\n",
    "class LPR_CalibTRT(BaseDataset):\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(LPR_CalibTRT, self).__init__(phase, cfg)\n",
    "\n",
    "        # self.input_size = (128, 128)  # (height, width), both dividable by 16\n",
    "        #this model for sadaia works with (256,256)\n",
    "        self.input_size = (256, 256)  # (height, width), both dividable by 16\n",
    "        self.class_names = ('0')\n",
    "        # real_filtered mean and std\n",
    "        # self.rgb_mean = np.array([94.87347, 96.89165, 94.70493], dtype=np.float32).reshape(1, 1, 3)\n",
    "        # self.rgb_std = np.array([53.869507, 53.936283, 55.2807], dtype=np.float32).reshape(1, 1, 3)\n",
    "        \n",
    "        # real_filtered plus all_sites_seatbelt mean and std\n",
    "        # self.rgb_mean = np.array([104.90631, 105.41336, 104.70162], dtype=np.float32).reshape(1, 1, 3)\n",
    "        # self.rgb_std = np.array([50.69564, 49.60443, 50.158844], dtype=np.float32).reshape(1, 1, 3)\n",
    "\n",
    "        self.rgb_mean = np.array([97.631615, 98.70732, 98.41285], dtype=np.float32).reshape(1, 1, 3)\n",
    "        self.rgb_std = np.array([52.766678, 52.63513, 52.348827], dtype=np.float32).reshape(1, 1, 3)\n",
    "\n",
    "        self.num_classes = len(self.class_names)\n",
    "        self.class_ids_dict = {cls_name: cls_id for cls_id, cls_name in enumerate(self.class_names)}\n",
    "\n",
    "        self.data_dir = os.path.join(cfg.data_dir, 'lpr_crop/merged_data')\n",
    "        self.sample_ids, self.sample_set_path = self.get_sample_ids()\n",
    "        self.grid_size = tuple(x // cfg.stride for x in self.input_size)  # anchors grid \n",
    "        # self.anchors_seed = np.array([[ 29, 17], [46, 32], [69, 52],\n",
    "        #                                 [109, 68], [84, 127], [155, 106], \n",
    "        #                                 [255, 145], [183, 215], [371, 221]], dtype=np.float32) ## real_filtered anchors\n",
    "        \n",
    "        # self.anchors_seed = np.array( [[ 32, 20], [ 61, 42], [ 59, 97],\n",
    "        #                                 [103, 66], [122, 114], [183, 96],\n",
    "        #                                 [160, 152], [211, 201], [343, 205]], dtype=np.float32) ## real_filtered plus all_sites_seatbelt anchors\n",
    "\n",
    "        # self.anchors_seed = np.array([[6, 5], [12, 10], [18, 10], [18, 18], [20, 24], [30, 15]], dtype=np.float32)\n",
    "        self.anchors_seed = np.array([[3, 3], [6, 5], [9, 5], [10, 9], [10, 12], [15, 8]], dtype=np.float32)\n",
    "        # self.anchors = generate_anchors(self.grid_size, self.input_size, self.anchors_seed)\n",
    "        self.anchors = torch.load(\"../exp/alpr_det_anchors_256_exp_8.pt\")\n",
    "        self.anchors_per_grid = self.anchors_seed.shape[0]\n",
    "        self.num_anchors = self.anchors.shape[0]\n",
    "\n",
    "        self.results_dir = os.path.join(cfg.save_dir, 'results')\n",
    "\n",
    "    def get_sample_ids(self):\n",
    "        #a dirty duct tape to load preprocessing of val phase but load dataset for train phase for trt calib\n",
    "        sample_set_name = 'train.txt' if self.phase == 'train' \\\n",
    "            else 'train.txt' if self.phase == 'val' \\\n",
    "            else 'trainval.txt' if self.phase == 'trainval' \\\n",
    "            else None\n",
    "\n",
    "        sample_ids_path = os.path.join(self.data_dir, sample_set_name)\n",
    "        with open(sample_ids_path, 'r') as fp:\n",
    "            sample_ids = fp.readlines()\n",
    "        sample_ids = tuple(x.strip() for x in sample_ids)\n",
    "\n",
    "        return sample_ids, sample_ids_path\n",
    "\n",
    "    def load_image(self, index):\n",
    "        image_id = self.sample_ids[index]\n",
    "        image_path = os.path.join(self.data_dir, 'images', image_id + '.png')\n",
    "        image = default_loader(image_path)\n",
    "        if image.mode == 'L':\n",
    "            image = image.convert('RGB')\n",
    "        image = np.array(image).astype(np.float32)\n",
    "        # image = skimage.io.imread(image_path).astype(np.float32)\n",
    "        return image, image_id\n",
    "\n",
    "    def load_annotations(self, index):\n",
    "        ann_id = self.sample_ids[index]\n",
    "        ann_path = os.path.join(self.data_dir, 'labels', ann_id + '.txt')\n",
    "        with open(ann_path, 'r') as fp:\n",
    "            annotations = fp.readlines()\n",
    "\n",
    "        annotations = [ann.strip().split(' ') for ann in annotations]\n",
    "        class_ids, boxes = [], []\n",
    "        for ann in annotations:\n",
    "            if ann[0] not in self.class_names:\n",
    "                continue\n",
    "            class_ids.append(self.class_ids_dict[ann[0]])\n",
    "            box = [float(x) for x in ann[4:8]]\n",
    "            # if box[2] <= 0:\n",
    "            #     box[2] = 0.00001\n",
    "            # if box[3] <= 0:\n",
    "            #     box[3] = 0.00001\n",
    "            boxes.append(box)\n",
    "\n",
    "        class_ids = np.array(class_ids, dtype=np.int16)\n",
    "        boxes = np.array(boxes, dtype=np.float32)\n",
    "        if len(boxes):\n",
    "            return class_ids, boxes\n",
    "        boxes = None\n",
    "        return class_ids, boxes\n",
    "\n",
    "    # ========================================\n",
    "    #                evaluation\n",
    "    # ========================================\n",
    "\n",
    "    def save_results(self, results):\n",
    "        txt_dir = os.path.join(self.results_dir, 'data')\n",
    "        os.makedirs(txt_dir, exist_ok=True)\n",
    "\n",
    "        for res in results:\n",
    "            txt_path = os.path.join(txt_dir, res['image_meta']['image_id'] + '.txt')\n",
    "            if 'class_ids' not in res:\n",
    "                with open(txt_path, 'w') as fp:\n",
    "                    fp.write('')\n",
    "                continue\n",
    "\n",
    "            num_boxes = len(res['class_ids'])\n",
    "            with open(txt_path, 'w') as fp:\n",
    "                for i in range(num_boxes):\n",
    "                    class_name = self.class_names[res['class_ids'][i]].lower()\n",
    "                    score = res['scores'][i]\n",
    "                    bbox = res['boxes'][i, :]\n",
    "                    line = '{} -1 -1 0 {:.2f} {:.2f} {:.2f} {:.2f} 0 0 0 0 0 0 0 {:.3f}\\n'.format(\n",
    "                            class_name, *bbox, score)\n",
    "                    fp.write(line)\n",
    "\n",
    "    def evaluate(self):\n",
    "        kitti_eval_tool_path = os.path.join(self.cfg.root_dir, 'src/utils/kitti-eval/cpp/evaluate_object')\n",
    "        cmd = '{} {} {} {} {}'.format(kitti_eval_tool_path,\n",
    "                                      os.path.join(self.data_dir),\n",
    "                                      self.sample_set_path,\n",
    "                                      self.results_dir,\n",
    "                                      len(self.sample_ids))\n",
    "\n",
    "        print (cmd)\n",
    "        status = subprocess.call(cmd, shell=True)\n",
    "\n",
    "        aps = {}\n",
    "        for class_name in self.class_names:\n",
    "            map_path = os.path.join(self.results_dir, 'stats_{}_ap.txt'.format(class_name.lower()))\n",
    "            if os.path.exists(map_path):\n",
    "                with open(map_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                _aps = [float(line.split('=')[1].strip()) for line in lines]\n",
    "            else:\n",
    "                _aps = [0., 0., 0.]\n",
    "\n",
    "            aps[class_name + '_easy'] = _aps[0]\n",
    "            aps[class_name + '_moderate'] = _aps[1]\n",
    "            aps[class_name + '_hard'] = _aps[2]\n",
    "\n",
    "        aps['mAP'] = sum(aps.values()) / len(aps)\n",
    "\n",
    "        return aps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpr_calib_dataset = LPR_CalibTRT('val', cfg)\n",
    "calib_data_loader = torch.utils.data.DataLoader(lpr_calib_dataset,\n",
    "                                                  batch_size=cfg.batch_size,\n",
    "                                                  num_workers=cfg.num_workers,\n",
    "                                                  pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14068\n"
     ]
    }
   ],
   "source": [
    "print (len(lpr_calib_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute stats and Calibrate on Different schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0902 22:06:29.795573 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.796108 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.796442 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.796764 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.797045 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.797311 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.797579 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.798238 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.798545 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.798936 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.799295 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.799603 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.799892 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.800165 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.800654 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.800952 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.801275 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.801578 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.801866 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.802139 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.802430 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.802704 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.802967 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.803234 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.803936 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.804298 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.804615 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.804900 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.805181 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.805662 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.806004 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.806454 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.806841 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.807187 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.807528 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.807863 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.808187 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.808463 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.808728 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.809004 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.809274 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.809569 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.809919 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.810251 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.810537 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.811415 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.811718 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.812231 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.812543 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.812912 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.813169 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.813420 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.813701 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.813977 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.814302 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.814786 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.815106 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.815433 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.815781 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.816091 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.819107 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.819851 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.820751 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.821149 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.821749 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.822071 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.822361 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.822629 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.822902 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.826921 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.827465 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.827783 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.828078 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.828363 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.828666 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.829206 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.829524 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.829826 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.830153 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.830435 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.830736 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.831033 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.831308 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.831613 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.843406 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.844002 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.844779 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.845818 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.846275 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.846599 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.847192 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.847548 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.847856 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.848132 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.848405 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.848696 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.848996 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.849275 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.849550 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.849829 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I0902 22:06:29.850322 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.850680 139837141516480 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I0902 22:06:29.851080 139837141516480 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I0902 22:06:29.851430 139837141516480 tensor_quantizer.py:179] Enable MaxCalibrator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]I0902 22:06:29.945580 139837141516480 max.py:60] Calibrator encountered negative values. It shouldn't happen after ReLU. Make sure this is the right tensor to calibrate.\n",
      "100%|██████████| 2000/2000 [03:49<00:00,  8.71it/s]\n",
      "I0902 22:10:19.567061 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.567570 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.567900 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.568234 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.568527 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.569022 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.569306 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.569953 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.570300 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.570678 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.571048 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.571403 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.572019 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.572299 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.572573 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.572861 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.573403 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.573702 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.574044 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.574379 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.574745 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.575081 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.575361 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.576194 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.576502 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.576785 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.577055 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.577316 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.577589 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.578140 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.578433 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.578998 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.579275 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.579836 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.580106 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.580669 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.581020 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.581344 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.581695 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.581978 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.582261 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.582526 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.582866 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.583141 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.583432 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.583718 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.584174 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.584535 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.584951 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.585247 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.585541 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.587069 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.587420 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.587703 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.587975 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.588245 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.588503 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.588758 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.589019 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.589285 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.589550 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.589801 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.590069 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.590313 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.590577 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.590823 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.591113 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.591378 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.592517 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.592840 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.593121 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.593375 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.593644 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.593913 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.594168 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.594417 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.594701 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.594969 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.595232 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.595507 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.596037 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.597970 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.598579 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.598944 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.599435 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.599758 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.600049 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.600410 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.600852 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.601896 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.602313 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.603028 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.603420 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.603723 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.604008 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.604282 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.604559 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.604821 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.605089 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.605766 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I0902 22:10:19.606096 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.606446 139837141516480 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I0902 22:10:19.606772 139837141516480 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W0902 22:10:19.607059 139837141516480 tensor_quantizer.py:173] Disable MaxCalibrator\n"
     ]
    }
   ],
   "source": [
    "num_batches = int(len(lpr_calib_dataset)/cfg.batch_size)\n",
    "print (num_batches)\n",
    "\n",
    "detector.model.eval()\n",
    "detector.model.cuda()\n",
    "with torch.no_grad():\n",
    "    collect_stats(detector.model, calib_data_loader, num_batches=2000)\n",
    "    # compute_amax(detector.model, method=\"percentile\", percentile=99.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeDetWithLoss(\n",
      "  (base): SqueezeDetBase(\n",
      "    (quant): QuantStub()\n",
      "    (dequant): DeQuantStub()\n",
      "    (conv1): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "      (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "      (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "    )\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (features): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (1): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          64, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          16, 64, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          128, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          16, 64, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (4): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          128, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          32, 128, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          256, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          32, 128, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (7): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          256, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          48, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (8): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          384, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          48, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (9): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          384, 64, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (10): Fire(\n",
      "        (squeeze): QuantConv2d(\n",
      "          512, 64, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand1x1): QuantConv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (expand3x3): QuantConv2d(\n",
      "          64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "          (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "        )\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (convdet): QuantConv2d(\n",
      "      512, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "      (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "      (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
      "    )\n",
      "  )\n",
      "  (resolver): PredictionResolver()\n",
      "  (loss): Loss(\n",
      "    (resolver): PredictionResolver()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (detector.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.lpr import LPR\n",
    "\n",
    "eval_dataset = LPR('val', cfg)\n",
    "eval_dataset.phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0902 22:11:53.662745 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.663644 139837141516480 tensor_quantizer.py:238] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "W0902 22:11:53.664341 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:11:53.664942 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.665276 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0902 22:11:53.665915 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.666280 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:11:53.666913 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.667380 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:11:53.667989 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.668416 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0902 22:11:53.668968 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.669277 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:11:53.669785 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.670174 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:11:53.670646 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.670949 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0902 22:11:53.671444 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.671762 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0902 22:11:53.672298 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.672594 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0902 22:11:53.673106 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.673400 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0902 22:11:53.673914 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.674228 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0902 22:11:53.674726 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.675124 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0902 22:11:53.675609 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.675915 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([48, 1, 1, 1]).\n",
      "W0902 22:11:53.676410 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.676704 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0902 22:11:53.677198 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.677546 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0902 22:11:53.678191 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.678518 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([48, 1, 1, 1]).\n",
      "W0902 22:11:53.679091 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.679403 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0902 22:11:53.679933 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.680261 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0902 22:11:53.680807 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.681106 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:11:53.681613 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.681923 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0902 22:11:53.682622 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.683026 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0902 22:11:53.683796 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.684178 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:11:53.684728 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.685348 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0902 22:11:53.685934 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.686414 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0902 22:11:53.687152 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:11:53.687592 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([36, 1, 1, 1]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ############  percentile calibration ######################\n",
      "eval: [0/1530] | data 0.102s | net 0.050s\n",
      "eval: [20/1530] | data 0.120s | net 0.029s\n",
      "eval: [40/1530] | data 0.088s | net 0.031s\n",
      "eval: [60/1530] | data 0.013s | net 0.036s\n",
      "eval: [80/1530] | data 0.015s | net 0.049s\n",
      "eval: [100/1530] | data 0.031s | net 0.084s\n",
      "eval: [120/1530] | data 0.013s | net 0.028s\n",
      "eval: [140/1530] | data 0.033s | net 0.089s\n",
      "eval: [160/1530] | data 0.007s | net 0.031s\n",
      "eval: [180/1530] | data 0.006s | net 0.021s\n",
      "eval: [200/1530] | data 0.014s | net 0.048s\n",
      "eval: [220/1530] | data 0.048s | net 0.144s\n",
      "eval: [240/1530] | data 0.017s | net 0.056s\n",
      "eval: [260/1530] | data 0.007s | net 0.029s\n",
      "eval: [280/1530] | data 0.002s | net 0.019s\n",
      "eval: [300/1530] | data 0.019s | net 0.043s\n",
      "eval: [320/1530] | data 0.005s | net 0.027s\n",
      "eval: [340/1530] | data 0.012s | net 0.043s\n",
      "eval: [360/1530] | data 0.024s | net 0.078s\n",
      "eval: [380/1530] | data 0.009s | net 0.038s\n",
      "eval: [400/1530] | data 0.037s | net 0.066s\n",
      "eval: [420/1530] | data 0.004s | net 0.024s\n",
      "eval: [440/1530] | data 0.038s | net 0.105s\n",
      "eval: [460/1530] | data 0.003s | net 0.021s\n",
      "eval: [480/1530] | data 0.002s | net 0.019s\n",
      "eval: [500/1530] | data 0.009s | net 0.034s\n",
      "eval: [520/1530] | data 0.015s | net 0.028s\n",
      "eval: [540/1530] | data 0.005s | net 0.024s\n",
      "eval: [560/1530] | data 0.016s | net 0.052s\n",
      "eval: [580/1530] | data 0.034s | net 0.093s\n",
      "eval: [600/1530] | data 0.011s | net 0.038s\n",
      "eval: [620/1530] | data 0.002s | net 0.021s\n",
      "eval: [640/1530] | data 0.005s | net 0.025s\n",
      "eval: [660/1530] | data 0.003s | net 0.022s\n",
      "eval: [680/1530] | data 0.006s | net 0.029s\n",
      "eval: [700/1530] | data 0.008s | net 0.034s\n",
      "eval: [720/1530] | data 0.005s | net 0.027s\n",
      "eval: [740/1530] | data 0.007s | net 0.031s\n",
      "eval: [760/1530] | data 0.007s | net 0.032s\n",
      "eval: [780/1530] | data 0.006s | net 0.029s\n",
      "eval: [800/1530] | data 0.025s | net 0.026s\n",
      "eval: [820/1530] | data 0.029s | net 0.050s\n",
      "eval: [840/1530] | data 0.009s | net 0.039s\n",
      "eval: [860/1530] | data 0.021s | net 0.063s\n",
      "eval: [880/1530] | data 0.004s | net 0.024s\n",
      "eval: [900/1530] | data 0.002s | net 0.019s\n",
      "eval: [920/1530] | data 0.008s | net 0.031s\n",
      "eval: [940/1530] | data 0.056s | net 0.025s\n",
      "eval: [960/1530] | data 0.049s | net 0.046s\n",
      "eval: [980/1530] | data 0.022s | net 0.068s\n",
      "eval: [1000/1530] | data 0.016s | net 0.050s\n",
      "eval: [1020/1530] | data 0.032s | net 0.089s\n",
      "eval: [1040/1530] | data 0.025s | net 0.071s\n",
      "eval: [1060/1530] | data 0.003s | net 0.022s\n",
      "eval: [1080/1530] | data 0.019s | net 0.021s\n",
      "eval: [1100/1530] | data 0.019s | net 0.063s\n",
      "eval: [1120/1530] | data 0.022s | net 0.057s\n",
      "eval: [1140/1530] | data 0.009s | net 0.036s\n",
      "eval: [1160/1530] | data 0.010s | net 0.027s\n",
      "eval: [1180/1530] | data 0.009s | net 0.036s\n",
      "eval: [1200/1530] | data 0.065s | net 0.044s\n",
      "eval: [1220/1530] | data 0.027s | net 0.076s\n",
      "eval: [1240/1530] | data 0.006s | net 0.028s\n",
      "eval: [1260/1530] | data 0.029s | net 0.022s\n",
      "eval: [1280/1530] | data 0.003s | net 0.022s\n",
      "eval: [1300/1530] | data 0.020s | net 0.060s\n",
      "eval: [1320/1530] | data 0.010s | net 0.037s\n",
      "eval: [1340/1530] | data 0.046s | net 0.091s\n",
      "eval: [1360/1530] | data 0.009s | net 0.034s\n",
      "eval: [1380/1530] | data 0.051s | net 0.022s\n",
      "eval: [1400/1530] | data 0.003s | net 0.021s\n",
      "eval: [1420/1530] | data 0.033s | net 0.090s\n",
      "eval: [1440/1530] | data 0.004s | net 0.023s\n",
      "eval: [1460/1530] | data 0.004s | net 0.026s\n",
      "eval: [1480/1530] | data 0.013s | net 0.043s\n",
      "eval: [1500/1530] | data 0.008s | net 0.033s\n",
      "eval: [1520/1530] | data 0.057s | net 0.024s\n",
      "Elapsed 1.54min (60.5ms/image, 16.5frames/s)\n",
      "--------------------------------------------------------------------------------\n",
      "/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/utils/kitti-eval/cpp/evaluate_object /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data/val.txt /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/results 1530\n",
      "gt dir:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data/labels\n",
      "Thank you for participating in our evaluation!\n",
      "filename: /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/results/plot’: File exists\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (car_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading detections...\n",
      "  done.\n",
      "Your evaluation results are available in /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/results\n",
      "0_easy               0.893\n",
      "0_moderate           0.893\n",
      "0_hard               0.893\n",
      "mAP                  0.893\n",
      " ############  mse calibration ######################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0902 22:13:28.884643 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:13:28.885464 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:13:31.608424 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:13:31.609170 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0902 22:13:36.137655 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:13:36.138330 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:13:40.481978 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:13:40.482854 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:13:43.874020 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:13:43.874677 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0902 22:13:46.749476 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:13:46.750265 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:13:49.550080 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:13:49.550725 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:13:51.364149 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:13:51.364799 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0902 22:13:53.540243 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:13:53.540923 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0902 22:13:55.806927 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:13:55.807579 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0902 22:13:57.900927 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:13:57.901654 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0902 22:13:59.093256 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:13:59.093961 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0902 22:14:00.491036 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:00.491752 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0902 22:14:02.542423 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:02.543109 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([48, 1, 1, 1]).\n",
      "W0902 22:14:05.009653 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:05.010343 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0902 22:14:07.154449 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:07.155100 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0902 22:14:08.530896 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:08.531630 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([48, 1, 1, 1]).\n",
      "W0902 22:14:10.273992 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:10.274731 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0902 22:14:12.078948 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:12.079663 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0902 22:14:14.705516 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:14.706267 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:14:17.264386 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:17.265043 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0902 22:14:19.683236 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:19.683913 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0902 22:14:21.799710 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:21.800385 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:14:23.685377 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:23.686309 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0902 22:14:25.416956 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:25.417727 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0902 22:14:31.634244 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:14:31.635005 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([36, 1, 1, 1]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: [0/1530] | data 0.003s | net 0.022s\n",
      "eval: [20/1530] | data 0.091s | net 0.028s\n",
      "eval: [40/1530] | data 0.078s | net 0.035s\n",
      "eval: [60/1530] | data 0.009s | net 0.036s\n",
      "eval: [80/1530] | data 0.012s | net 0.048s\n",
      "eval: [100/1530] | data 0.031s | net 0.084s\n",
      "eval: [120/1530] | data 0.011s | net 0.028s\n",
      "eval: [140/1530] | data 0.098s | net 0.091s\n",
      "eval: [160/1530] | data 0.006s | net 0.031s\n",
      "eval: [180/1530] | data 0.007s | net 0.020s\n",
      "eval: [200/1530] | data 0.028s | net 0.048s\n",
      "eval: [220/1530] | data 0.048s | net 0.145s\n",
      "eval: [240/1530] | data 0.017s | net 0.057s\n",
      "eval: [260/1530] | data 0.006s | net 0.029s\n",
      "eval: [280/1530] | data 0.002s | net 0.020s\n",
      "eval: [300/1530] | data 0.011s | net 0.043s\n",
      "eval: [320/1530] | data 0.005s | net 0.027s\n",
      "eval: [340/1530] | data 0.031s | net 0.043s\n",
      "eval: [360/1530] | data 0.023s | net 0.077s\n",
      "eval: [380/1530] | data 0.009s | net 0.036s\n",
      "eval: [400/1530] | data 0.024s | net 0.066s\n",
      "eval: [420/1530] | data 0.005s | net 0.024s\n",
      "eval: [440/1530] | data 0.037s | net 0.105s\n",
      "eval: [460/1530] | data 0.040s | net 0.022s\n",
      "eval: [480/1530] | data 0.002s | net 0.020s\n",
      "eval: [500/1530] | data 0.008s | net 0.034s\n",
      "eval: [520/1530] | data 0.006s | net 0.029s\n",
      "eval: [540/1530] | data 0.005s | net 0.024s\n",
      "eval: [560/1530] | data 0.016s | net 0.053s\n",
      "eval: [580/1530] | data 0.034s | net 0.093s\n",
      "eval: [600/1530] | data 0.010s | net 0.039s\n",
      "eval: [620/1530] | data 0.002s | net 0.021s\n",
      "eval: [640/1530] | data 0.004s | net 0.024s\n",
      "eval: [660/1530] | data 0.002s | net 0.021s\n",
      "eval: [680/1530] | data 0.031s | net 0.029s\n",
      "eval: [700/1530] | data 0.008s | net 0.034s\n",
      "eval: [720/1530] | data 0.005s | net 0.026s\n",
      "eval: [740/1530] | data 0.007s | net 0.030s\n",
      "eval: [760/1530] | data 0.007s | net 0.031s\n",
      "eval: [780/1530] | data 0.006s | net 0.029s\n",
      "eval: [800/1530] | data 0.004s | net 0.025s\n",
      "eval: [820/1530] | data 0.013s | net 0.049s\n",
      "eval: [840/1530] | data 0.008s | net 0.038s\n",
      "eval: [860/1530] | data 0.089s | net 0.061s\n",
      "eval: [880/1530] | data 0.004s | net 0.025s\n",
      "eval: [900/1530] | data 0.002s | net 0.021s\n",
      "eval: [920/1530] | data 0.007s | net 0.031s\n",
      "eval: [940/1530] | data 0.003s | net 0.022s\n",
      "eval: [960/1530] | data 0.012s | net 0.044s\n",
      "eval: [980/1530] | data 0.022s | net 0.067s\n",
      "eval: [1000/1530] | data 0.015s | net 0.049s\n",
      "eval: [1020/1530] | data 0.031s | net 0.088s\n",
      "eval: [1040/1530] | data 0.024s | net 0.071s\n",
      "eval: [1060/1530] | data 0.003s | net 0.023s\n",
      "eval: [1080/1530] | data 0.003s | net 0.022s\n",
      "eval: [1100/1530] | data 0.019s | net 0.062s\n",
      "eval: [1120/1530] | data 0.018s | net 0.059s\n",
      "eval: [1140/1530] | data 0.009s | net 0.035s\n",
      "eval: [1160/1530] | data 0.005s | net 0.026s\n",
      "eval: [1180/1530] | data 0.009s | net 0.036s\n",
      "eval: [1200/1530] | data 0.009s | net 0.038s\n",
      "eval: [1220/1530] | data 0.026s | net 0.075s\n",
      "eval: [1240/1530] | data 0.010s | net 0.027s\n",
      "eval: [1260/1530] | data 0.003s | net 0.021s\n",
      "eval: [1280/1530] | data 0.025s | net 0.022s\n",
      "eval: [1300/1530] | data 0.019s | net 0.061s\n",
      "eval: [1320/1530] | data 0.009s | net 0.036s\n",
      "eval: [1340/1530] | data 0.034s | net 0.091s\n",
      "eval: [1360/1530] | data 0.008s | net 0.035s\n",
      "eval: [1380/1530] | data 0.002s | net 0.020s\n",
      "eval: [1400/1530] | data 0.003s | net 0.022s\n",
      "eval: [1420/1530] | data 0.036s | net 0.091s\n",
      "eval: [1440/1530] | data 0.004s | net 0.024s\n",
      "eval: [1460/1530] | data 0.006s | net 0.025s\n",
      "eval: [1480/1530] | data 0.012s | net 0.043s\n",
      "eval: [1500/1530] | data 0.008s | net 0.032s\n",
      "eval: [1520/1530] | data 0.004s | net 0.024s\n",
      "Elapsed 1.43min (56.2ms/image, 17.8frames/s)\n",
      "--------------------------------------------------------------------------------\n",
      "/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/utils/kitti-eval/cpp/evaluate_object /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data/val.txt /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/results 1530\n",
      "gt dir:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data/labels\n",
      "Thank you for participating in our evaluation!\n",
      "filename: /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/results/plot’: File exists\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (car_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading detections...\n",
      "  done.\n",
      "Your evaluation results are available in /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/results\n",
      "0_easy               0.888\n",
      "0_moderate           0.888\n",
      "0_hard               0.888\n",
      "mAP                  0.888\n",
      " ############  entropy calibration ######################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0902 22:16:03.796549 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:16:03.797331 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:16:43.217256 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:16:43.223551 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0902 22:18:04.357078 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:18:04.363376 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:19:25.722566 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:19:25.728924 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:20:03.887575 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:20:03.894164 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0902 22:20:53.042223 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:20:53.053114 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:21:42.121750 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:21:42.127431 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:22:03.988647 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:22:03.994557 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0902 22:22:34.387175 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:22:34.393052 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0902 22:23:04.796147 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:23:04.802217 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0902 22:23:24.724753 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:23:24.730437 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0902 22:23:34.478897 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:23:34.479546 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0902 22:23:44.216159 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:23:44.216802 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0902 22:24:07.107063 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:24:07.112818 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([48, 1, 1, 1]).\n",
      "W0902 22:24:32.337302 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:24:32.343488 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0902 22:24:57.561378 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:24:57.569041 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0902 22:25:08.147491 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:25:08.148159 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([48, 1, 1, 1]).\n",
      "W0902 22:25:26.653778 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:25:26.657698 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0902 22:25:45.171121 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:25:45.175061 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0902 22:25:59.680740 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:25:59.681393 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:26:31.414562 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:26:31.420432 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0902 22:27:03.171884 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:27:03.181840 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0902 22:27:24.321012 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:27:24.326962 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0902 22:27:43.768410 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:27:43.772061 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0902 22:28:03.190653 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:28:03.196775 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0902 22:30:47.989151 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0902 22:30:47.994795 139837141516480 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([36, 1, 1, 1]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: [0/1530] | data 0.005s | net 0.022s\n",
      "eval: [20/1530] | data 0.005s | net 0.027s\n",
      "eval: [40/1530] | data 0.020s | net 0.031s\n",
      "eval: [60/1530] | data 0.101s | net 0.020s\n",
      "eval: [80/1530] | data 0.016s | net 0.050s\n",
      "eval: [100/1530] | data 0.146s | net 0.085s\n",
      "eval: [120/1530] | data 0.005s | net 0.029s\n",
      "eval: [140/1530] | data 0.032s | net 0.089s\n",
      "eval: [160/1530] | data 0.007s | net 0.030s\n",
      "eval: [180/1530] | data 0.002s | net 0.021s\n",
      "eval: [200/1530] | data 0.025s | net 0.049s\n",
      "eval: [220/1530] | data 0.048s | net 0.145s\n",
      "eval: [240/1530] | data 0.018s | net 0.056s\n",
      "eval: [260/1530] | data 0.006s | net 0.029s\n",
      "eval: [280/1530] | data 0.002s | net 0.019s\n",
      "eval: [300/1530] | data 0.029s | net 0.045s\n",
      "eval: [320/1530] | data 0.006s | net 0.027s\n",
      "eval: [340/1530] | data 0.012s | net 0.042s\n",
      "eval: [360/1530] | data 0.098s | net 0.072s\n",
      "eval: [380/1530] | data 0.009s | net 0.035s\n",
      "eval: [400/1530] | data 0.049s | net 0.066s\n",
      "eval: [420/1530] | data 0.004s | net 0.024s\n",
      "eval: [440/1530] | data 0.038s | net 0.105s\n",
      "eval: [460/1530] | data 0.003s | net 0.021s\n",
      "eval: [480/1530] | data 0.004s | net 0.019s\n",
      "eval: [500/1530] | data 0.024s | net 0.035s\n",
      "eval: [520/1530] | data 0.006s | net 0.028s\n",
      "eval: [540/1530] | data 0.003s | net 0.024s\n",
      "eval: [560/1530] | data 0.017s | net 0.051s\n",
      "eval: [580/1530] | data 0.033s | net 0.092s\n",
      "eval: [600/1530] | data 0.010s | net 0.038s\n",
      "eval: [620/1530] | data 0.002s | net 0.021s\n",
      "eval: [640/1530] | data 0.005s | net 0.024s\n",
      "eval: [660/1530] | data 0.003s | net 0.022s\n",
      "eval: [680/1530] | data 0.006s | net 0.028s\n",
      "eval: [700/1530] | data 0.008s | net 0.034s\n",
      "eval: [720/1530] | data 0.005s | net 0.026s\n",
      "eval: [740/1530] | data 0.007s | net 0.031s\n",
      "eval: [760/1530] | data 0.007s | net 0.032s\n",
      "eval: [780/1530] | data 0.006s | net 0.030s\n",
      "eval: [800/1530] | data 0.005s | net 0.025s\n",
      "eval: [820/1530] | data 0.013s | net 0.049s\n",
      "eval: [840/1530] | data 0.009s | net 0.038s\n",
      "eval: [860/1530] | data 0.020s | net 0.061s\n",
      "eval: [880/1530] | data 0.004s | net 0.025s\n",
      "eval: [900/1530] | data 0.002s | net 0.019s\n",
      "eval: [920/1530] | data 0.008s | net 0.032s\n",
      "eval: [940/1530] | data 0.003s | net 0.022s\n",
      "eval: [960/1530] | data 0.026s | net 0.045s\n",
      "eval: [980/1530] | data 0.029s | net 0.067s\n",
      "eval: [1000/1530] | data 0.020s | net 0.050s\n",
      "eval: [1020/1530] | data 0.032s | net 0.088s\n",
      "eval: [1040/1530] | data 0.025s | net 0.072s\n",
      "eval: [1060/1530] | data 0.003s | net 0.023s\n",
      "eval: [1080/1530] | data 0.003s | net 0.022s\n",
      "eval: [1100/1530] | data 0.019s | net 0.064s\n",
      "eval: [1120/1530] | data 0.019s | net 0.057s\n",
      "eval: [1140/1530] | data 0.009s | net 0.035s\n",
      "eval: [1160/1530] | data 0.005s | net 0.027s\n",
      "eval: [1180/1530] | data 0.009s | net 0.037s\n",
      "eval: [1200/1530] | data 0.009s | net 0.040s\n",
      "eval: [1220/1530] | data 0.026s | net 0.076s\n",
      "eval: [1240/1530] | data 0.006s | net 0.027s\n",
      "eval: [1260/1530] | data 0.003s | net 0.022s\n",
      "eval: [1280/1530] | data 0.030s | net 0.023s\n",
      "eval: [1300/1530] | data 0.020s | net 0.061s\n",
      "eval: [1320/1530] | data 0.010s | net 0.038s\n",
      "eval: [1340/1530] | data 0.033s | net 0.091s\n",
      "eval: [1360/1530] | data 0.009s | net 0.034s\n",
      "eval: [1380/1530] | data 0.002s | net 0.020s\n",
      "eval: [1400/1530] | data 0.003s | net 0.022s\n",
      "eval: [1420/1530] | data 0.033s | net 0.090s\n",
      "eval: [1440/1530] | data 0.009s | net 0.023s\n",
      "eval: [1460/1530] | data 0.004s | net 0.025s\n",
      "eval: [1480/1530] | data 0.026s | net 0.044s\n",
      "eval: [1500/1530] | data 0.007s | net 0.032s\n",
      "eval: [1520/1530] | data 0.004s | net 0.023s\n",
      "Elapsed 1.46min (57.1ms/image, 17.5frames/s)\n",
      "--------------------------------------------------------------------------------\n",
      "/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/src/utils/kitti-eval/cpp/evaluate_object /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data/val.txt /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/results 1530\n",
      "gt dir:/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data/labels\n",
      "Thank you for participating in our evaluation!\n",
      "filename: /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/data/lpr_crop/merged_data/val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/results/plot’: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading detections...\n",
      "  done.\n",
      "Your evaluation results are available in /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_lpd_sqdet_trt_calib/results\n",
      "0_easy               0.892\n",
      "0_moderate           0.892\n",
      "0_hard               0.892\n",
      "mAP                  0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (car_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for method in [\"percentile\", \"mse\", \"entropy\"]:\n",
    "        percentile = 99.99\n",
    "        print(F\" ############  {method} calibration ######################\")\n",
    "        if(method == 'percentile'):\n",
    "            compute_amax(detector.model, method=method, percentile = percentile)\n",
    "        else:\n",
    "            compute_amax(detector.model, method=method)\n",
    "        update_exp_dir(cfg, f\"trt_calib_lpd_sadaia_sqdet_{method}\")\n",
    "        results = detector.detect_dataset(eval_dataset, cfg)\n",
    "        eval_dataset.save_results(results)\n",
    "        aps = eval_dataset.evaluate()\n",
    "        for k, v in aps.items():\n",
    "                print('{:<20} {:.3f}'.format(k, v))\n",
    "        torch.save(detector.model.state_dict(), os.path.join(cfg.save_dir, f\"quant_lp_squeezedet_sadaia_{method}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (detector.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add scales to the quantized state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = torch.load(\"../exp/trt_calib_lpd_sadaia_sqdet_percentile/quant_lp_squeezedet_sadaia_percentile.pth\")\n",
    "print (dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (alpr)\n",
    "def get_scales_input_per_tensor(amax, _num_bits = 8 , _unsigned = False):\n",
    "    bound = (1 << (_num_bits - 1 + int(_unsigned))) - 1    \n",
    "    zero_point_per_tensor = 0 #since symmertric quant\n",
    "    scale_per_tensor = amax / bound\n",
    "    return scale_per_tensor, zero_point_per_tensor\n",
    "\n",
    "def get_scales_weight_per_channel(amax, _num_bits = 8, _unsigned = False):\n",
    "    bound = (1 << (_num_bits - 1 + int(_unsigned))) - 1\n",
    "    amax_sequeeze = amax.squeeze().detach()\n",
    "    scale_per_channel =  amax_sequeeze/bound\n",
    "    zero_point_per_channel = torch.zeros_like(scale_per_channel, dtype=torch.int32).data\n",
    "    quant_axis = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
    "    return scale_per_channel, zero_point_per_channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['base.conv1.weight', 'base.conv1.bias', 'base.conv1._input_quantizer._amax.scales', 'base.conv1._input_quantizer._amax', 'base.conv1._weight_quantizer._amax.scales', 'base.conv1._weight_quantizer._amax', 'base.features.1.squeeze.weight', 'base.features.1.squeeze.bias', 'base.features.1.squeeze._input_quantizer._amax.scales', 'base.features.1.squeeze._input_quantizer._amax', 'base.features.1.squeeze._weight_quantizer._amax.scales', 'base.features.1.squeeze._weight_quantizer._amax', 'base.features.1.expand1x1.weight', 'base.features.1.expand1x1.bias', 'base.features.1.expand1x1._input_quantizer._amax.scales', 'base.features.1.expand1x1._input_quantizer._amax', 'base.features.1.expand1x1._weight_quantizer._amax.scales', 'base.features.1.expand1x1._weight_quantizer._amax', 'base.features.1.expand3x3.weight', 'base.features.1.expand3x3.bias', 'base.features.1.expand3x3._input_quantizer._amax.scales', 'base.features.1.expand3x3._input_quantizer._amax', 'base.features.1.expand3x3._weight_quantizer._amax.scales', 'base.features.1.expand3x3._weight_quantizer._amax', 'base.features.2.squeeze.weight', 'base.features.2.squeeze.bias', 'base.features.2.squeeze._input_quantizer._amax.scales', 'base.features.2.squeeze._input_quantizer._amax', 'base.features.2.squeeze._weight_quantizer._amax.scales', 'base.features.2.squeeze._weight_quantizer._amax', 'base.features.2.expand1x1.weight', 'base.features.2.expand1x1.bias', 'base.features.2.expand1x1._input_quantizer._amax.scales', 'base.features.2.expand1x1._input_quantizer._amax', 'base.features.2.expand1x1._weight_quantizer._amax.scales', 'base.features.2.expand1x1._weight_quantizer._amax', 'base.features.2.expand3x3.weight', 'base.features.2.expand3x3.bias', 'base.features.2.expand3x3._input_quantizer._amax.scales', 'base.features.2.expand3x3._input_quantizer._amax', 'base.features.2.expand3x3._weight_quantizer._amax.scales', 'base.features.2.expand3x3._weight_quantizer._amax', 'base.features.4.squeeze.weight', 'base.features.4.squeeze.bias', 'base.features.4.squeeze._input_quantizer._amax.scales', 'base.features.4.squeeze._input_quantizer._amax', 'base.features.4.squeeze._weight_quantizer._amax.scales', 'base.features.4.squeeze._weight_quantizer._amax', 'base.features.4.expand1x1.weight', 'base.features.4.expand1x1.bias', 'base.features.4.expand1x1._input_quantizer._amax.scales', 'base.features.4.expand1x1._input_quantizer._amax', 'base.features.4.expand1x1._weight_quantizer._amax.scales', 'base.features.4.expand1x1._weight_quantizer._amax', 'base.features.4.expand3x3.weight', 'base.features.4.expand3x3.bias', 'base.features.4.expand3x3._input_quantizer._amax.scales', 'base.features.4.expand3x3._input_quantizer._amax', 'base.features.4.expand3x3._weight_quantizer._amax.scales', 'base.features.4.expand3x3._weight_quantizer._amax', 'base.features.5.squeeze.weight', 'base.features.5.squeeze.bias', 'base.features.5.squeeze._input_quantizer._amax.scales', 'base.features.5.squeeze._input_quantizer._amax', 'base.features.5.squeeze._weight_quantizer._amax.scales', 'base.features.5.squeeze._weight_quantizer._amax', 'base.features.5.expand1x1.weight', 'base.features.5.expand1x1.bias', 'base.features.5.expand1x1._input_quantizer._amax.scales', 'base.features.5.expand1x1._input_quantizer._amax', 'base.features.5.expand1x1._weight_quantizer._amax.scales', 'base.features.5.expand1x1._weight_quantizer._amax', 'base.features.5.expand3x3.weight', 'base.features.5.expand3x3.bias', 'base.features.5.expand3x3._input_quantizer._amax.scales', 'base.features.5.expand3x3._input_quantizer._amax', 'base.features.5.expand3x3._weight_quantizer._amax.scales', 'base.features.5.expand3x3._weight_quantizer._amax', 'base.features.7.squeeze.weight', 'base.features.7.squeeze.bias', 'base.features.7.squeeze._input_quantizer._amax.scales', 'base.features.7.squeeze._input_quantizer._amax', 'base.features.7.squeeze._weight_quantizer._amax.scales', 'base.features.7.squeeze._weight_quantizer._amax', 'base.features.7.expand1x1.weight', 'base.features.7.expand1x1.bias', 'base.features.7.expand1x1._input_quantizer._amax.scales', 'base.features.7.expand1x1._input_quantizer._amax', 'base.features.7.expand1x1._weight_quantizer._amax.scales', 'base.features.7.expand1x1._weight_quantizer._amax', 'base.features.7.expand3x3.weight', 'base.features.7.expand3x3.bias', 'base.features.7.expand3x3._input_quantizer._amax.scales', 'base.features.7.expand3x3._input_quantizer._amax', 'base.features.7.expand3x3._weight_quantizer._amax.scales', 'base.features.7.expand3x3._weight_quantizer._amax', 'base.features.8.squeeze.weight', 'base.features.8.squeeze.bias', 'base.features.8.squeeze._input_quantizer._amax.scales', 'base.features.8.squeeze._input_quantizer._amax', 'base.features.8.squeeze._weight_quantizer._amax.scales', 'base.features.8.squeeze._weight_quantizer._amax', 'base.features.8.expand1x1.weight', 'base.features.8.expand1x1.bias', 'base.features.8.expand1x1._input_quantizer._amax.scales', 'base.features.8.expand1x1._input_quantizer._amax', 'base.features.8.expand1x1._weight_quantizer._amax.scales', 'base.features.8.expand1x1._weight_quantizer._amax', 'base.features.8.expand3x3.weight', 'base.features.8.expand3x3.bias', 'base.features.8.expand3x3._input_quantizer._amax.scales', 'base.features.8.expand3x3._input_quantizer._amax', 'base.features.8.expand3x3._weight_quantizer._amax.scales', 'base.features.8.expand3x3._weight_quantizer._amax', 'base.features.9.squeeze.weight', 'base.features.9.squeeze.bias', 'base.features.9.squeeze._input_quantizer._amax.scales', 'base.features.9.squeeze._input_quantizer._amax', 'base.features.9.squeeze._weight_quantizer._amax.scales', 'base.features.9.squeeze._weight_quantizer._amax', 'base.features.9.expand1x1.weight', 'base.features.9.expand1x1.bias', 'base.features.9.expand1x1._input_quantizer._amax.scales', 'base.features.9.expand1x1._input_quantizer._amax', 'base.features.9.expand1x1._weight_quantizer._amax.scales', 'base.features.9.expand1x1._weight_quantizer._amax', 'base.features.9.expand3x3.weight', 'base.features.9.expand3x3.bias', 'base.features.9.expand3x3._input_quantizer._amax.scales', 'base.features.9.expand3x3._input_quantizer._amax', 'base.features.9.expand3x3._weight_quantizer._amax.scales', 'base.features.9.expand3x3._weight_quantizer._amax', 'base.features.10.squeeze.weight', 'base.features.10.squeeze.bias', 'base.features.10.squeeze._input_quantizer._amax.scales', 'base.features.10.squeeze._input_quantizer._amax', 'base.features.10.squeeze._weight_quantizer._amax.scales', 'base.features.10.squeeze._weight_quantizer._amax', 'base.features.10.expand1x1.weight', 'base.features.10.expand1x1.bias', 'base.features.10.expand1x1._input_quantizer._amax.scales', 'base.features.10.expand1x1._input_quantizer._amax', 'base.features.10.expand1x1._weight_quantizer._amax.scales', 'base.features.10.expand1x1._weight_quantizer._amax', 'base.features.10.expand3x3.weight', 'base.features.10.expand3x3.bias', 'base.features.10.expand3x3._input_quantizer._amax.scales', 'base.features.10.expand3x3._input_quantizer._amax', 'base.features.10.expand3x3._weight_quantizer._amax.scales', 'base.features.10.expand3x3._weight_quantizer._amax', 'base.convdet.weight', 'base.convdet.bias', 'base.convdet._input_quantizer._amax.scales', 'base.convdet._input_quantizer._amax', 'base.convdet._weight_quantizer._amax.scales', 'base.convdet._weight_quantizer._amax'])\n"
     ]
    }
   ],
   "source": [
    "lp_det_sadaia_dict_with_scales = {}\n",
    "\n",
    "for key in dict:\n",
    "    if key.find('_input_quantizer._amax') != -1:\n",
    "        amax = dict[key]\n",
    "        scales, zero_point = get_scales_input_per_tensor(amax)\n",
    "        new_key = key + '.scales'\n",
    "        lp_det_sadaia_dict_with_scales[new_key] = scales\n",
    "    elif key.find('_weight_quantizer._amax') != -1:\n",
    "        amax = dict[key]\n",
    "        scales, zero_point = get_scales_weight_per_channel(amax)\n",
    "        new_key = key + '.scales'\n",
    "        lp_det_sadaia_dict_with_scales[new_key] = scales\n",
    "    \n",
    "    lp_det_sadaia_dict_with_scales[key] = dict[key]\n",
    "\n",
    "print (lp_det_sadaia_dict_with_scales.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lp_det_sadaia_dict_with_scales, \"../exp/quant_lp_det_sadaia_with_scales.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ocr-qat-clone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e089903189396571af52d43610369d46655a332e0d6c0850202b6a0cbdca0f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
