{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_quantization import tensor_quant\n",
    "\n",
    "from torch import nn, outer\n",
    "\n",
    "from pytorch_quantization import tensor_quant\n",
    "import pytorch_quantization.nn as quant_nn\n",
    "import pytorch_quantization\n",
    "pytorch_quantization.__version__\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.yolo import YOLO\n",
    "from engine.detector import Detector\n",
    "from model.squeezedet import SqueezeDet, SqueezeDetWithLoss\n",
    "from utils.config import Config\n",
    "from utils.model import load_model\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from utils.misc import init_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arch                           squeezedet\n",
      "batch_size                     1\n",
      "bbox_loss_weight               20.0\n",
      "chunk_sizes                    [32]\n",
      "class_loss_weight              1.0\n",
      "data_dir                       /home/hazen/data/datasets\n",
      "dataset                        yolo\n",
      "debug                          0\n",
      "debug_dir                      /home/hazen/data/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib_sqdet/debug\n",
      "device                         cuda\n",
      "drift_prob                     1.0\n",
      "dropout_prob                   0\n",
      "exp_dir                        /home/hazen/data/SqueezeDet-PyTorch/exp\n",
      "exp_id                         test_veh_det_trt_calib_sqdet\n",
      "flip_prob                      0.5\n",
      "forbid_resize                  False\n",
      "gpus                           [0]\n",
      "gpus_str                       0\n",
      "grad_norm                      0.5\n",
      "keep_top_k                     64\n",
      "load_model                     ../exp/model_41.pth\n",
      "load_pretrained                True\n",
      "log_file                       /home/hazen/data/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib_sqdet/training_logs.txt\n",
      "lr                             0.001\n",
      "master_batch_size              32\n",
      "mode                           eval\n",
      "momentum                       0.9\n",
      "negative_score_loss_weight     100.0\n",
      "nms_thresh                     0.4\n",
      "no_eval                        False\n",
      "not_cuda_benchmark             False\n",
      "num_epochs                     100\n",
      "num_iters                      -1\n",
      "num_workers                    0\n",
      "positive_score_loss_weight     3.75\n",
      "print_interval                 20\n",
      "qat                            False\n",
      "root_dir                       /home/hazen/data/SqueezeDet-PyTorch\n",
      "save_dir                       /home/hazen/data/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib_sqdet\n",
      "save_intervals                 1\n",
      "score_thresh                   0.5\n",
      "seed                           42\n",
      "stride                         16\n",
      "val_intervals                  1\n",
      "weight_decay                   0.0001\n"
     ]
    }
   ],
   "source": [
    "args = {'_': '_'}\n",
    "cfg = Config().parse(args)\n",
    "\n",
    "init_env(cfg) \n",
    " \n",
    "cfg.mode = 'eval'\n",
    "cfg.exp_id = \"test_veh_det_trt_calib_sqdet\"\n",
    "cfg.dataset = 'yolo'\n",
    "cfg.load_model = '../exp/model_41.pth' \n",
    "cfg.batch_size = 1\n",
    "cfg.arch = 'squeezedet'\n",
    "cfg.num_workers = 0\n",
    "cfg.save_intervals = 1\n",
    "# cfg.stride = 8\n",
    "cfg.debug = 0\n",
    "cfg.device = 'cuda'\n",
    "cfg.load_pretrained = True\n",
    "\n",
    "def update_exp_dir(cfg, exp_id):\n",
    "    cfg.save_dir = os.path.join(cfg.exp_dir, exp_id)\n",
    "    os.makedirs(cfg.save_dir, exist_ok=True)\n",
    "    cfg.log_file = os.path.join(cfg.save_dir, 'training_logs.txt')\n",
    "    os.remove(cfg.log_file) if os.path.exists(cfg.log_file) else None\n",
    "    cfg.debug_dir = os.path.join(cfg.save_dir, 'debug')\n",
    "\n",
    "update_exp_dir(cfg, cfg.exp_id)\n",
    "\n",
    "Config().print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from eval import eval\n",
    "# eval(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine.detector import Detector\n",
    "from model.squeezedet import SqueezeDetWithLoss\n",
    "from utils.model import load_model\n",
    "from utils.misc import load_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchors                        [[  8.   8.  32.  20.]\n",
      " [  8.   8.  61.  42.]\n",
      " [  8.   8.  59.  97.]\n",
      " ...\n",
      " [440. 248. 160. 152.]\n",
      " [440. 248. 211. 201.]\n",
      " [440. 248. 343. 205.]]\n",
      "anchors_per_grid               9\n",
      "arch                           squeezedet\n",
      "batch_size                     1\n",
      "bbox_loss_weight               20.0\n",
      "chunk_sizes                    [32]\n",
      "class_loss_weight              1.0\n",
      "class_names                    ('bike', 'car', 'bus')\n",
      "data_dir                       /home/hazen/data/datasets\n",
      "dataset                        yolo\n",
      "debug                          0\n",
      "debug_dir                      /home/hazen/data/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib_sqdet/debug\n",
      "device                         cuda\n",
      "drift_prob                     1.0\n",
      "dropout_prob                   0\n",
      "exp_dir                        /home/hazen/data/SqueezeDet-PyTorch/exp\n",
      "exp_id                         test_veh_det_trt_calib_sqdet\n",
      "flip_prob                      0.5\n",
      "forbid_resize                  False\n",
      "gpus                           [0]\n",
      "gpus_str                       0\n",
      "grad_norm                      0.5\n",
      "grid_size                      (16, 28)\n",
      "input_size                     (256, 448)\n",
      "keep_top_k                     64\n",
      "load_model                     ../exp/model_41.pth\n",
      "load_pretrained                True\n",
      "log_file                       /home/hazen/data/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib_sqdet/training_logs.txt\n",
      "lr                             0.001\n",
      "master_batch_size              32\n",
      "mode                           eval\n",
      "momentum                       0.9\n",
      "negative_score_loss_weight     100.0\n",
      "nms_thresh                     0.4\n",
      "no_eval                        False\n",
      "not_cuda_benchmark             False\n",
      "num_anchors                    4032\n",
      "num_classes                    3\n",
      "num_epochs                     100\n",
      "num_iters                      -1\n",
      "num_workers                    0\n",
      "positive_score_loss_weight     3.75\n",
      "print_interval                 20\n",
      "qat                            False\n",
      "rgb_mean                       [[[104.90631 105.41336 104.70162]]]\n",
      "rgb_std                        [[[50.69564  49.60443  50.158844]]]\n",
      "root_dir                       /home/hazen/data/SqueezeDet-PyTorch\n",
      "save_dir                       /home/hazen/data/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib_sqdet\n",
      "save_intervals                 1\n",
      "score_thresh                   0.5\n",
      "seed                           42\n",
      "stride                         16\n",
      "val_intervals                  1\n",
      "weight_decay                   0.0001\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(cfg.dataset)('val', cfg)\n",
    "cfg = Config().update_dataset_info(cfg, dataset)\n",
    "Config().print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n"
     ]
    }
   ],
   "source": [
    "print (dataset.phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model ../exp/model_41.pth, epoch 41\n",
      "state_dict: \n",
      " dict_keys(['base.conv1.weight', 'base.conv1.bias', 'base.features.1.squeeze.weight', 'base.features.1.squeeze.bias', 'base.features.1.expand1x1.weight', 'base.features.1.expand1x1.bias', 'base.features.1.expand3x3.weight', 'base.features.1.expand3x3.bias', 'base.features.2.squeeze.weight', 'base.features.2.squeeze.bias', 'base.features.2.expand1x1.weight', 'base.features.2.expand1x1.bias', 'base.features.2.expand3x3.weight', 'base.features.2.expand3x3.bias', 'base.features.4.squeeze.weight', 'base.features.4.squeeze.bias', 'base.features.4.expand1x1.weight', 'base.features.4.expand1x1.bias', 'base.features.4.expand3x3.weight', 'base.features.4.expand3x3.bias', 'base.features.5.squeeze.weight', 'base.features.5.squeeze.bias', 'base.features.5.expand1x1.weight', 'base.features.5.expand1x1.bias', 'base.features.5.expand3x3.weight', 'base.features.5.expand3x3.bias', 'base.features.7.squeeze.weight', 'base.features.7.squeeze.bias', 'base.features.7.expand1x1.weight', 'base.features.7.expand1x1.bias', 'base.features.7.expand3x3.weight', 'base.features.7.expand3x3.bias', 'base.features.8.squeeze.weight', 'base.features.8.squeeze.bias', 'base.features.8.expand1x1.weight', 'base.features.8.expand1x1.bias', 'base.features.8.expand3x3.weight', 'base.features.8.expand3x3.bias', 'base.features.9.squeeze.weight', 'base.features.9.squeeze.bias', 'base.features.9.expand1x1.weight', 'base.features.9.expand1x1.bias', 'base.features.9.expand3x3.weight', 'base.features.9.expand3x3.bias', 'base.features.10.squeeze.weight', 'base.features.10.squeeze.bias', 'base.features.10.expand1x1.weight', 'base.features.10.expand1x1.bias', 'base.features.10.expand3x3.weight', 'base.features.10.expand3x3.bias', 'base.features.11.squeeze.weight', 'base.features.11.squeeze.bias', 'base.features.11.expand1x1.weight', 'base.features.11.expand1x1.bias', 'base.features.11.expand3x3.weight', 'base.features.11.expand3x3.bias', 'base.features.12.squeeze.weight', 'base.features.12.squeeze.bias', 'base.features.12.expand1x1.weight', 'base.features.12.expand1x1.bias', 'base.features.12.expand3x3.weight', 'base.features.12.expand3x3.bias', 'base.convdet.weight', 'base.convdet.bias'])\n",
      "Model successfully loaded.\n",
      "SqueezeDetWithLoss(\n",
      "  (base): SqueezeDetBase(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (features): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (1): Fire(\n",
      "        (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Fire(\n",
      "        (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (4): Fire(\n",
      "        (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): Fire(\n",
      "        (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (7): Fire(\n",
      "        (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (8): Fire(\n",
      "        (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (9): Fire(\n",
      "        (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (10): Fire(\n",
      "        (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (11): Fire(\n",
      "        (squeeze): Conv2d(512, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (12): Fire(\n",
      "        (squeeze): Conv2d(768, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (convdet): Conv2d(768, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resolver): PredictionResolver()\n",
      "  (loss): Loss(\n",
      "    (resolver): PredictionResolver()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if cfg.mode=='eval':\n",
    "        model = SqueezeDetWithLoss(cfg)\n",
    "        model = load_model(model, cfg.load_model, cfg)\n",
    "\n",
    "\n",
    "detect = model.detect\n",
    "model.detect = True\n",
    "detector = Detector(model, cfg)\n",
    "print(detector.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)  # Disable logging as they are too noisy in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_desc_input = QuantDescriptor(calib_method='histogram')\n",
    "quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)\n",
    "quant_nn.QuantLinear.set_default_quant_desc_input(quant_desc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import quant_modules\n",
    "quant_modules.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeDetWithLoss(\n",
      "  (base): SqueezeDetBase(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (features): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (1): Fire(\n",
      "        (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Fire(\n",
      "        (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (4): Fire(\n",
      "        (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): Fire(\n",
      "        (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "      (7): Fire(\n",
      "        (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (8): Fire(\n",
      "        (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (9): Fire(\n",
      "        (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (10): Fire(\n",
      "        (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation_1): ReLU(inplace=True)\n",
      "        (activation_2): ReLU(inplace=True)\n",
      "        (activation_3): ReLU(inplace=True)\n",
      "        (float_functional_simple): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (convdet): Conv2d(512, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (resolver): PredictionResolver()\n",
      "  (loss): Loss(\n",
      "    (resolver): PredictionResolver()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(detector.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_stats(model, data_loader, num_batches):\n",
    "    \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "    # Enable calibrators\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.disable_quant()\n",
    "                module.enable_calib()\n",
    "            else:\n",
    "                module.disable()\n",
    "\n",
    "    # for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "    #     model(image.cuda())\n",
    "    #     if i >= num_batches:\n",
    "    #         break\n",
    "    # since yolo/lpr dataloader return a dict, so writing it in this way\n",
    "    for i, (batch) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "        print(batch.keys())\n",
    "        for k in batch:\n",
    "                if 'image_meta' not in k:\n",
    "                    batch[k] = batch[k].to(device='cuda', non_blocking=True)\n",
    "        model(batch)\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "\n",
    "    # Disable calibrators\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.enable_quant()\n",
    "                module.disable_calib()\n",
    "            else:\n",
    "                module.enable()\n",
    "            \n",
    "def compute_amax(model, **kwargs):\n",
    "    # Load calib result\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                    module.load_calib_amax()\n",
    "                else:\n",
    "                    module.load_calib_amax(**kwargs)\n",
    "#             print(F\"{name:40}: {module}\")\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "\n",
    "from datasets.base import BaseDataset\n",
    "from utils.boxes import generate_anchors\n",
    "from PIL import Image\n",
    "from torchvision.datasets.folder import default_loader\n",
    "\n",
    "\n",
    "class YOLO_CalibTRT(BaseDataset):\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(YOLO_CalibTRT, self).__init__(phase, cfg)\n",
    "\n",
    "        self.input_size = (256, 448)  # (height, width), both dividable by 16\n",
    "        self.class_names = ('bike', 'car', 'bus')\n",
    "        # real_filtered mean and std\n",
    "        # self.rgb_mean = np.array([94.87347, 96.89165, 94.70493], dtype=np.float32).reshape(1, 1, 3)\n",
    "        # self.rgb_std = np.array([53.869507, 53.936283, 55.2807], dtype=np.float32).reshape(1, 1, 3)\n",
    "        \n",
    "        # real_filtered plus all_sites_seatbelt mean and std\n",
    "        self.rgb_mean = np.array([104.90631, 105.41336, 104.70162], dtype=np.float32).reshape(1, 1, 3)\n",
    "        self.rgb_std = np.array([50.69564, 49.60443, 50.158844], dtype=np.float32).reshape(1, 1, 3)\n",
    "        self.num_classes = len(self.class_names)\n",
    "        self.class_ids_dict = {cls_name: cls_id for cls_id, cls_name in enumerate(self.class_names)}\n",
    "\n",
    "        self.data_dir = os.path.join(cfg.data_dir, 'all_real_plus_synth_8sites_plus_SVsynth_plus_seatbelt_plus_new_trajectory_data_kitti_format_5percentofwidth_filtered')\n",
    "        self.sample_ids, self.sample_set_path = self.get_sample_ids()\n",
    "\n",
    "        self.grid_size = tuple(x //cfg.stride  for x in self.input_size)  # anchors grid \n",
    "        # self.anchors_seed = np.array([[ 29, 17], [46, 32], [69, 52],\n",
    "        #                                 [109, 68], [84, 127], [155, 106], \n",
    "        #                                 [255, 145], [183, 215], [371, 221]], dtype=np.float32) ## real_filtered anchors\n",
    "        \n",
    "        self.anchors_seed = np.array( [[ 32, 20], [ 61, 42], [ 59, 97],\n",
    "                                        [103, 66], [122, 114], [183, 96],\n",
    "                                        [160, 152], [211, 201], [343, 205]], dtype=np.float32) ## real_filtered plus all_sites_seatbelt anchors\n",
    "\n",
    "        self.anchors = generate_anchors(self.grid_size, self.input_size, self.anchors_seed)\n",
    "        self.anchors_per_grid = self.anchors_seed.shape[0]\n",
    "        self.num_anchors = self.anchors.shape[0]\n",
    "\n",
    "        self.results_dir = os.path.join(cfg.save_dir, 'results')\n",
    "\n",
    "    def get_sample_ids(self):\n",
    "        #a dirty duct tape to load preprocessing of val phase but load dataset for train phase for trt calib\n",
    "        sample_set_name = 'train.txt' if self.phase == 'train' \\\n",
    "            else 'train.txt' if self.phase == 'val' \\\n",
    "            else 'trainval.txt' if self.phase == 'trainval' \\\n",
    "            else None\n",
    "\n",
    "        sample_ids_path = os.path.join(self.data_dir, 'image_sets', sample_set_name)\n",
    "        with open(sample_ids_path, 'r') as fp:\n",
    "            sample_ids = fp.readlines()\n",
    "        sample_ids = tuple(x.strip() for x in sample_ids)\n",
    "\n",
    "        return sample_ids, sample_ids_path\n",
    "\n",
    "    def load_image(self, index):\n",
    "        image_id = self.sample_ids[index]\n",
    "        image_path = os.path.join(self.data_dir, 'training/image_2', image_id + '.jpg')\n",
    "        image = default_loader(image_path)\n",
    "        if image.mode == 'L':\n",
    "            image = image.convert('RGB')\n",
    "        image = np.array(image).astype(np.float32)\n",
    "        # image = skimage.io.imread(image_path).astype(np.float32)\n",
    "        return image, image_id\n",
    "\n",
    "    def load_annotations(self, index):\n",
    "        ann_id = self.sample_ids[index]\n",
    "        ann_path = os.path.join(self.data_dir, 'training/label_2', ann_id + '.txt')\n",
    "        with open(ann_path, 'r') as fp:\n",
    "            annotations = fp.readlines()\n",
    "\n",
    "        annotations = [ann.strip().split(' ') for ann in annotations]\n",
    "        class_ids, boxes = [], []\n",
    "        for ann in annotations:\n",
    "            if ann[0] not in self.class_names:\n",
    "                continue\n",
    "            class_ids.append(self.class_ids_dict[ann[0]])\n",
    "            box = [float(x) for x in ann[4:8]]\n",
    "            # if box[2] <= 0:\n",
    "            #     box[2] = 0.00001\n",
    "            # if box[3] <= 0:\n",
    "            #     box[3] = 0.00001\n",
    "            boxes.append(box)\n",
    "\n",
    "        class_ids = np.array(class_ids, dtype=np.int16)\n",
    "        boxes = np.array(boxes, dtype=np.float32)\n",
    "        if len(boxes):\n",
    "            return class_ids, boxes\n",
    "        boxes = None\n",
    "        return class_ids, boxes\n",
    "\n",
    "    # ========================================\n",
    "    #                evaluation\n",
    "    # ========================================\n",
    "\n",
    "    def save_results(self, results):\n",
    "        txt_dir = os.path.join(self.results_dir, 'data')\n",
    "        os.makedirs(txt_dir, exist_ok=True)\n",
    "\n",
    "        for res in results:\n",
    "            txt_path = os.path.join(txt_dir, res['image_meta']['image_id'] + '.txt')\n",
    "            if 'class_ids' not in res:\n",
    "                with open(txt_path, 'w') as fp:\n",
    "                    fp.write('')\n",
    "                continue\n",
    "\n",
    "            num_boxes = len(res['class_ids'])\n",
    "            with open(txt_path, 'w') as fp:\n",
    "                for i in range(num_boxes):\n",
    "                    class_name = self.class_names[res['class_ids'][i]].lower()\n",
    "                    score = res['scores'][i]\n",
    "                    bbox = res['boxes'][i, :]\n",
    "                    line = '{} -1 -1 0 {:.2f} {:.2f} {:.2f} {:.2f} 0 0 0 0 0 0 0 {:.3f}\\n'.format(\n",
    "                            class_name, *bbox, score)\n",
    "                    fp.write(line)\n",
    "\n",
    "    def evaluate(self):\n",
    "        kitti_eval_tool_path = os.path.join(self.cfg.root_dir, 'src/utils/kitti-eval/cpp/evaluate_object')\n",
    "        cmd = '{} {} {} {} {}'.format(kitti_eval_tool_path,\n",
    "                                      os.path.join(self.data_dir, 'training'),\n",
    "                                      self.sample_set_path,\n",
    "                                      self.results_dir,\n",
    "                                      len(self.sample_ids))\n",
    "\n",
    "        status = subprocess.call(cmd, shell=True)\n",
    "\n",
    "        aps = {}\n",
    "        for class_name in self.class_names:\n",
    "            map_path = os.path.join(self.results_dir, 'stats_{}_ap.txt'.format(class_name.lower()))\n",
    "            if os.path.exists(map_path):\n",
    "                with open(map_path, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                _aps = [float(line.split('=')[1].strip()) for line in lines]\n",
    "            else:\n",
    "                _aps = [0., 0., 0.]\n",
    "\n",
    "            aps[class_name + '_easy'] = _aps[0]\n",
    "            aps[class_name + '_moderate'] = _aps[1]\n",
    "            aps[class_name + '_hard'] = _aps[2]\n",
    "\n",
    "        aps['mAP'] = sum(aps.values()) / len(aps)\n",
    "\n",
    "        return aps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh_det_calib_dataset = YOLO_CalibTRT('val', cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_data_loader = torch.utils.data.DataLoader(veh_det_calib_dataset,\n",
    "                                                  batch_size=cfg.batch_size,\n",
    "                                                  num_workers=cfg.num_workers,\n",
    "                                                  pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (len(calib_data_loader))\n",
    "# inp  = next(iter(calib_data_loader))\n",
    "# print(inp['image'].shape)\n",
    "\n",
    "# for i, inp in enumerate(calib_data_loader, 0):\n",
    "#         print(inp['image'].shape)\n",
    "#         if i >= 10:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = int(len(veh_det_calib_dataset)/cfg.batch_size)\n",
    "print (num_batches)\n",
    "detector.model.eval()\n",
    "detector.model.cuda()\n",
    "with torch.no_grad():\n",
    "    collect_stats(detector.model, calib_data_loader, num_batches=1000)\n",
    "    # compute_amax(detector.model, method=\"percentile\", percentile=99.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (detector.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,256,448) (1,1,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/hazen/data/SqueezeDet-PyTorch/src/veh_det_trt_calib_sqdet.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hazen/data/SqueezeDet-PyTorch/src/veh_det_trt_calib_sqdet.ipynb#X52sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0.41139729\u001b[39m, \u001b[39m0.41338573\u001b[39m, \u001b[39m0.41059459\u001b[39m], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat16)\u001b[39m.\u001b[39mreshape( \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hazen/data/SqueezeDet-PyTorch/src/veh_det_trt_calib_sqdet.ipynb#X52sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m std \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0.19880643\u001b[39m, \u001b[39m0.19452718\u001b[39m, \u001b[39m0.19670135\u001b[39m], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat16)\u001b[39m.\u001b[39mreshape(\u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hazen/data/SqueezeDet-PyTorch/src/veh_det_trt_calib_sqdet.ipynb#X52sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m img \u001b[39m=\u001b[39m (img\u001b[39m-\u001b[39;49mmean)\u001b[39m/\u001b[39mstd\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hazen/data/SqueezeDet-PyTorch/src/veh_det_trt_calib_sqdet.ipynb#X52sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m convdet \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(convdet_dir\u001b[39m+\u001b[39mpath\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hazen/data/SqueezeDet-PyTorch/src/veh_det_trt_calib_sqdet.ipynb#X52sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(orignal_dir\u001b[39m+\u001b[39mpath\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,256,448) (1,1,3) "
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from os import *\n",
    "from utils import image\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "import cv2\n",
    "\n",
    "images_dir = \"/home/hazen/data/SqueezeDet-PyTorch/data/test_trt_2\"\n",
    "convdet_dir = \"/home/hazen/data/SqueezeDet-PyTorch/data/wrong_convdet/\"\n",
    "orignal_dir = \"/home/hazen/data/SqueezeDet-PyTorch/data/wrong_orignal/\"\n",
    "model = model.cuda()\n",
    "image_paths = glob(path.join(images_dir,\"*\"))\n",
    "image_paths.sort()\n",
    "for i, path in enumerate(image_paths):\n",
    "        # print(path)\n",
    "        img = default_loader(path)\n",
    "        #print(img)\n",
    "        # input_image = np.array(img, dtype=np.float32, order='C')\n",
    "        # if img.mode == 'L':\n",
    "        #         img = img.convert('RGB')\n",
    "        # print(np.array(img).shape)\n",
    "        # gray_input = np.load(orignal_dir+path.split(\"/\")[-1].split(\".\")[0]+\".npy\")\n",
    "        # trt_xl = trt_xl/255\n",
    "        # trt_xl = rgb2gray(trt_xl)\n",
    "        # print(trt_xl.shape)\n",
    "        # img = trt_xl.transpose(2, 0, 1)\n",
    "\n",
    "        # trt_xl2 = np.load(orignal_dir+path.split(\"/\")[-1].split(\".\")[0]+\".npy\")\n",
    "\n",
    "        # print(np.max(img-trt_xl2))\n",
    "\n",
    "\n",
    "        # print(trt_xl.shape)\n",
    "        img = transforms.ToTensor()(img)\n",
    "        \n",
    "        img = transforms.Resize((256,448),interpolation=InterpolationMode.NEAREST) (img)\n",
    "        \n",
    "        # img = transforms.Grayscale(num_output_channels=3) (img)\n",
    "\n",
    "        \n",
    "\n",
    "        mean = np.array([0.41139729, 0.41338573, 0.41059459], dtype=np.float16).reshape(3, 1, 1)\n",
    "        std = np.array([0.19880643, 0.19452718, 0.19670135], dtype=np.float16).reshape(3, 1, 1)\n",
    "\n",
    "        img = (img-mean)/std\n",
    "\n",
    "        convdet = np.load(convdet_dir+path.split(\"/\")[-1].split(\".\")[0]+\".npy\")\n",
    "        orig = np.load(orignal_dir+path.split(\"/\")[-1].split(\".\")[0]+\".npy\")\n",
    "        # print(orig.shape)\n",
    "        print(torch.max(img-orig))\n",
    "\n",
    "        # print(orig.shape)\n",
    "        # x = img.numpy()-trt_xl\n",
    "        # print(np.max(x))\n",
    "        # # img = img.permute(2, 0, 1)\n",
    "        # print(gray_input.shape)\n",
    "        img = orig.reshape(1,3,256,448)\n",
    "        # trt_xl = trt_xl.reshape(1,3,256,256)\n",
    "        # x = img.numpy()-trt_xl\n",
    "        # # print(\"2\",np.max(x))\n",
    "        img = torch.tensor(img,dtype=torch.float32)\n",
    "        # img = torch.reshape(img, (1,3,256,256))\n",
    "        # img = torch.rand(1,3,256,448)\n",
    "\n",
    "        img = img.cuda()\n",
    "        \n",
    "        x,xl = model.base(img)\n",
    "        # xl = xl.reshape(36,16,16)\n",
    "        xl = xl.to('cpu').detach().numpy()\n",
    "        # print(xl)\n",
    "        # print(\"TRT: \",trt_xl)\n",
    "        # print(\"PyTorch: \", xl)\n",
    "        print(np.max(xl-convdet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['base.features.0.weight', 'base.features.0.bias', 'base.features.3.squeeze.weight', 'base.features.3.squeeze.bias', 'base.features.3.expand1x1.weight', 'base.features.3.expand1x1.bias', 'base.features.3.expand3x3.weight', 'base.features.3.expand3x3.bias', 'base.features.4.squeeze.weight', 'base.features.4.squeeze.bias', 'base.features.4.expand1x1.weight', 'base.features.4.expand1x1.bias', 'base.features.4.expand3x3.weight', 'base.features.4.expand3x3.bias', 'base.features.6.squeeze.weight', 'base.features.6.squeeze.bias', 'base.features.6.expand1x1.weight', 'base.features.6.expand1x1.bias', 'base.features.6.expand3x3.weight', 'base.features.6.expand3x3.bias', 'base.features.7.squeeze.weight', 'base.features.7.squeeze.bias', 'base.features.7.expand1x1.weight', 'base.features.7.expand1x1.bias', 'base.features.7.expand3x3.weight', 'base.features.7.expand3x3.bias', 'base.features.9.squeeze.weight', 'base.features.9.squeeze.bias', 'base.features.9.expand1x1.weight', 'base.features.9.expand1x1.bias', 'base.features.9.expand3x3.weight', 'base.features.9.expand3x3.bias', 'base.features.10.squeeze.weight', 'base.features.10.squeeze.bias', 'base.features.10.expand1x1.weight', 'base.features.10.expand1x1.bias', 'base.features.10.expand3x3.weight', 'base.features.10.expand3x3.bias', 'base.features.11.squeeze.weight', 'base.features.11.squeeze.bias', 'base.features.11.expand1x1.weight', 'base.features.11.expand1x1.bias', 'base.features.11.expand3x3.weight', 'base.features.11.expand3x3.bias', 'base.features.12.squeeze.weight', 'base.features.12.squeeze.bias', 'base.features.12.expand1x1.weight', 'base.features.12.expand1x1.bias', 'base.features.12.expand3x3.weight', 'base.features.12.expand3x3.bias', 'base.convdet.weight', 'base.convdet.bias'])\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"/home/hazen/data/test_weights/alpr_det.pth\")\n",
    "print(model['state_dict'].keys()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Different Scehmes and Eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.yolo import YOLO\n",
    "\n",
    "eval_dataset = YOLO('val', cfg)\n",
    "eval_dataset.phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ############  mse calibration ######################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 16:11:01.860282 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:01.860819 139799529214144 tensor_quantizer.py:238] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "W0818 16:11:01.861232 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0818 16:11:02.864593 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:02.865229 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0818 16:11:05.107809 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:05.108374 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0818 16:11:06.245361 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:06.246005 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0818 16:11:07.482669 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:07.483326 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0818 16:11:08.598116 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:08.598975 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0818 16:11:09.640844 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:09.641473 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0818 16:11:10.622186 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:10.622804 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0818 16:11:11.684049 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:11.684694 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0818 16:11:12.662281 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:12.662931 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0818 16:11:13.732143 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:13.732789 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0818 16:11:14.607926 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:14.608559 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0818 16:11:15.487545 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:15.488166 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0818 16:11:16.643306 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:16.644345 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([48, 1, 1, 1]).\n",
      "W0818 16:11:17.806428 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:17.807436 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0818 16:11:19.031940 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:19.033000 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0818 16:11:20.246186 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:20.246811 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([48, 1, 1, 1]).\n",
      "W0818 16:11:21.342731 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:21.343290 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0818 16:11:22.475795 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:22.476373 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([192, 1, 1, 1]).\n",
      "W0818 16:11:23.877048 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:23.877678 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0818 16:11:24.872657 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:24.873734 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0818 16:11:25.908659 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:25.909217 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0818 16:11:26.817631 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:26.818229 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0818 16:11:27.761283 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:27.761891 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0818 16:11:28.676432 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:28.676995 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0818 16:11:29.295790 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:29.296352 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([96, 1, 1, 1]).\n",
      "W0818 16:11:29.915462 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:29.916020 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0818 16:11:30.512578 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:30.513128 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0818 16:11:31.099130 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:31.099692 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([96, 1, 1, 1]).\n",
      "W0818 16:11:31.723545 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:31.724092 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0818 16:11:32.293178 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:32.293732 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([384, 1, 1, 1]).\n",
      "W0818 16:11:32.902753 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0818 16:11:32.903308 139799529214144 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([72, 1, 1, 1]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: [0/7902] | data 0.051s | net 0.037s\n",
      "eval: [20/7902] | data 0.089s | net 0.021s\n",
      "eval: [40/7902] | data 0.046s | net 0.021s\n",
      "eval: [60/7902] | data 0.059s | net 0.022s\n",
      "eval: [80/7902] | data 0.074s | net 0.021s\n",
      "eval: [100/7902] | data 0.093s | net 0.021s\n",
      "eval: [120/7902] | data 0.075s | net 0.022s\n",
      "eval: [140/7902] | data 0.094s | net 0.021s\n",
      "eval: [160/7902] | data 0.104s | net 0.021s\n",
      "eval: [180/7902] | data 0.106s | net 0.022s\n",
      "eval: [200/7902] | data 0.086s | net 0.020s\n",
      "eval: [220/7902] | data 0.105s | net 0.021s\n",
      "eval: [240/7902] | data 0.090s | net 0.020s\n",
      "eval: [260/7902] | data 0.084s | net 0.021s\n",
      "eval: [280/7902] | data 0.087s | net 0.020s\n",
      "eval: [300/7902] | data 0.074s | net 0.021s\n",
      "eval: [320/7902] | data 0.104s | net 0.020s\n",
      "eval: [340/7902] | data 0.083s | net 0.021s\n",
      "eval: [360/7902] | data 0.106s | net 0.022s\n",
      "eval: [380/7902] | data 0.073s | net 0.020s\n",
      "eval: [400/7902] | data 0.070s | net 0.020s\n",
      "eval: [420/7902] | data 0.071s | net 0.020s\n",
      "eval: [440/7902] | data 0.090s | net 0.021s\n",
      "eval: [460/7902] | data 0.022s | net 0.022s\n",
      "eval: [480/7902] | data 0.018s | net 0.021s\n",
      "eval: [500/7902] | data 0.020s | net 0.021s\n",
      "eval: [520/7902] | data 0.021s | net 0.020s\n",
      "eval: [540/7902] | data 0.018s | net 0.020s\n",
      "eval: [560/7902] | data 0.017s | net 0.020s\n",
      "eval: [580/7902] | data 0.018s | net 0.021s\n",
      "eval: [600/7902] | data 0.022s | net 0.021s\n",
      "eval: [620/7902] | data 0.021s | net 0.021s\n",
      "eval: [640/7902] | data 0.017s | net 0.020s\n",
      "eval: [660/7902] | data 0.017s | net 0.020s\n",
      "eval: [680/7902] | data 0.018s | net 0.020s\n",
      "eval: [700/7902] | data 0.018s | net 0.020s\n",
      "eval: [720/7902] | data 0.018s | net 0.020s\n",
      "eval: [740/7902] | data 0.018s | net 0.021s\n",
      "eval: [760/7902] | data 0.019s | net 0.021s\n",
      "eval: [780/7902] | data 0.017s | net 0.021s\n",
      "eval: [800/7902] | data 0.018s | net 0.021s\n",
      "eval: [820/7902] | data 0.017s | net 0.020s\n",
      "eval: [840/7902] | data 0.018s | net 0.021s\n",
      "eval: [860/7902] | data 0.018s | net 0.020s\n",
      "eval: [880/7902] | data 0.017s | net 0.020s\n",
      "eval: [900/7902] | data 0.022s | net 0.023s\n",
      "eval: [920/7902] | data 0.021s | net 0.022s\n",
      "eval: [940/7902] | data 0.022s | net 0.022s\n",
      "eval: [960/7902] | data 0.020s | net 0.022s\n",
      "eval: [980/7902] | data 0.017s | net 0.020s\n",
      "eval: [1000/7902] | data 0.018s | net 0.021s\n",
      "eval: [1020/7902] | data 0.021s | net 0.021s\n",
      "eval: [1040/7902] | data 0.021s | net 0.022s\n",
      "eval: [1060/7902] | data 0.018s | net 0.021s\n",
      "eval: [1080/7902] | data 0.018s | net 0.021s\n",
      "eval: [1100/7902] | data 0.017s | net 0.021s\n",
      "eval: [1120/7902] | data 0.017s | net 0.020s\n",
      "eval: [1140/7902] | data 0.017s | net 0.021s\n",
      "eval: [1160/7902] | data 0.017s | net 0.021s\n",
      "eval: [1180/7902] | data 0.018s | net 0.022s\n",
      "eval: [1200/7902] | data 0.033s | net 0.022s\n",
      "eval: [1220/7902] | data 0.022s | net 0.023s\n",
      "eval: [1240/7902] | data 0.019s | net 0.021s\n",
      "eval: [1260/7902] | data 0.021s | net 0.023s\n",
      "eval: [1280/7902] | data 0.021s | net 0.022s\n",
      "eval: [1300/7902] | data 0.020s | net 0.022s\n",
      "eval: [1320/7902] | data 0.023s | net 0.024s\n",
      "eval: [1340/7902] | data 0.022s | net 0.022s\n",
      "eval: [1360/7902] | data 0.020s | net 0.022s\n",
      "eval: [1380/7902] | data 0.022s | net 0.022s\n",
      "eval: [1400/7902] | data 0.042s | net 0.022s\n",
      "eval: [1420/7902] | data 0.021s | net 0.023s\n",
      "eval: [1440/7902] | data 0.018s | net 0.020s\n",
      "eval: [1460/7902] | data 0.012s | net 0.020s\n",
      "eval: [1480/7902] | data 0.012s | net 0.020s\n",
      "eval: [1500/7902] | data 0.012s | net 0.020s\n",
      "eval: [1520/7902] | data 0.018s | net 0.027s\n",
      "eval: [1540/7902] | data 0.048s | net 0.025s\n",
      "eval: [1560/7902] | data 0.014s | net 0.022s\n",
      "eval: [1580/7902] | data 0.014s | net 0.022s\n",
      "eval: [1600/7902] | data 0.015s | net 0.023s\n",
      "eval: [1620/7902] | data 0.015s | net 0.022s\n",
      "eval: [1640/7902] | data 0.014s | net 0.021s\n",
      "eval: [1660/7902] | data 0.014s | net 0.022s\n",
      "eval: [1680/7902] | data 0.014s | net 0.022s\n",
      "eval: [1700/7902] | data 0.020s | net 0.024s\n",
      "eval: [1720/7902] | data 0.016s | net 0.023s\n",
      "eval: [1740/7902] | data 0.020s | net 0.033s\n",
      "eval: [1760/7902] | data 0.015s | net 0.024s\n",
      "eval: [1780/7902] | data 0.015s | net 0.023s\n",
      "eval: [1800/7902] | data 0.052s | net 0.024s\n",
      "eval: [1820/7902] | data 0.014s | net 0.024s\n",
      "eval: [1840/7902] | data 0.015s | net 0.024s\n",
      "eval: [1860/7902] | data 0.016s | net 0.023s\n",
      "eval: [1880/7902] | data 0.014s | net 0.023s\n",
      "eval: [1900/7902] | data 0.021s | net 0.024s\n",
      "eval: [1920/7902] | data 0.015s | net 0.024s\n",
      "eval: [1940/7902] | data 0.014s | net 0.023s\n",
      "eval: [1960/7902] | data 0.014s | net 0.023s\n",
      "eval: [1980/7902] | data 0.052s | net 0.025s\n",
      "eval: [2000/7902] | data 0.052s | net 0.028s\n",
      "eval: [2020/7902] | data 0.014s | net 0.025s\n",
      "eval: [2040/7902] | data 0.017s | net 0.028s\n",
      "eval: [2060/7902] | data 0.014s | net 0.022s\n",
      "eval: [2080/7902] | data 0.013s | net 0.021s\n",
      "eval: [2100/7902] | data 0.025s | net 0.024s\n",
      "eval: [2120/7902] | data 0.014s | net 0.024s\n",
      "eval: [2140/7902] | data 0.011s | net 0.021s\n",
      "eval: [2160/7902] | data 0.012s | net 0.021s\n",
      "eval: [2180/7902] | data 0.011s | net 0.021s\n",
      "eval: [2200/7902] | data 0.012s | net 0.021s\n",
      "eval: [2220/7902] | data 0.014s | net 0.021s\n",
      "eval: [2240/7902] | data 0.011s | net 0.021s\n",
      "eval: [2260/7902] | data 0.024s | net 0.021s\n",
      "eval: [2280/7902] | data 0.012s | net 0.020s\n",
      "eval: [2300/7902] | data 0.011s | net 0.022s\n",
      "eval: [2320/7902] | data 0.012s | net 0.021s\n",
      "eval: [2340/7902] | data 0.014s | net 0.022s\n",
      "eval: [2360/7902] | data 0.014s | net 0.022s\n",
      "eval: [2380/7902] | data 0.037s | net 0.027s\n",
      "eval: [2400/7902] | data 0.014s | net 0.022s\n",
      "eval: [2420/7902] | data 0.014s | net 0.022s\n",
      "eval: [2440/7902] | data 0.014s | net 0.023s\n",
      "eval: [2460/7902] | data 0.037s | net 0.024s\n",
      "eval: [2480/7902] | data 0.059s | net 0.024s\n",
      "eval: [2500/7902] | data 0.057s | net 0.022s\n",
      "eval: [2520/7902] | data 0.057s | net 0.022s\n",
      "eval: [2540/7902] | data 0.058s | net 0.022s\n",
      "eval: [2560/7902] | data 0.058s | net 0.022s\n",
      "eval: [2580/7902] | data 0.044s | net 0.021s\n",
      "eval: [2600/7902] | data 0.051s | net 0.026s\n",
      "eval: [2620/7902] | data 0.059s | net 0.023s\n",
      "eval: [2640/7902] | data 0.051s | net 0.024s\n",
      "eval: [2660/7902] | data 0.057s | net 0.022s\n",
      "eval: [2680/7902] | data 0.051s | net 0.021s\n",
      "eval: [2700/7902] | data 0.035s | net 0.023s\n",
      "eval: [2720/7902] | data 0.028s | net 0.020s\n",
      "eval: [2740/7902] | data 0.046s | net 0.021s\n",
      "eval: [2760/7902] | data 0.047s | net 0.022s\n",
      "eval: [2780/7902] | data 0.053s | net 0.021s\n",
      "eval: [2800/7902] | data 0.044s | net 0.022s\n",
      "eval: [2820/7902] | data 0.081s | net 0.027s\n",
      "eval: [2840/7902] | data 0.057s | net 0.022s\n",
      "eval: [2860/7902] | data 0.082s | net 0.024s\n",
      "eval: [2880/7902] | data 0.056s | net 0.022s\n",
      "eval: [2900/7902] | data 0.031s | net 0.021s\n",
      "eval: [2920/7902] | data 0.066s | net 0.023s\n",
      "eval: [2940/7902] | data 0.093s | net 0.026s\n",
      "eval: [2960/7902] | data 0.058s | net 0.023s\n",
      "eval: [2980/7902] | data 0.063s | net 0.022s\n",
      "eval: [3000/7902] | data 0.045s | net 0.022s\n",
      "eval: [3020/7902] | data 0.076s | net 0.026s\n",
      "eval: [3040/7902] | data 0.054s | net 0.020s\n",
      "eval: [3060/7902] | data 0.057s | net 0.021s\n",
      "eval: [3080/7902] | data 0.052s | net 0.023s\n",
      "eval: [3100/7902] | data 0.057s | net 0.023s\n",
      "eval: [3120/7902] | data 0.072s | net 0.023s\n",
      "eval: [3140/7902] | data 0.058s | net 0.024s\n",
      "eval: [3160/7902] | data 0.057s | net 0.021s\n",
      "eval: [3180/7902] | data 0.058s | net 0.022s\n",
      "eval: [3200/7902] | data 0.075s | net 0.024s\n",
      "eval: [3220/7902] | data 0.058s | net 0.024s\n",
      "eval: [3240/7902] | data 0.063s | net 0.024s\n",
      "eval: [3260/7902] | data 0.062s | net 0.024s\n",
      "eval: [3280/7902] | data 0.049s | net 0.023s\n",
      "eval: [3300/7902] | data 0.046s | net 0.021s\n",
      "eval: [3320/7902] | data 0.037s | net 0.021s\n",
      "eval: [3340/7902] | data 0.045s | net 0.022s\n",
      "eval: [3360/7902] | data 0.049s | net 0.023s\n",
      "eval: [3380/7902] | data 0.037s | net 0.023s\n",
      "eval: [3400/7902] | data 0.055s | net 0.022s\n",
      "eval: [3420/7902] | data 0.022s | net 0.021s\n",
      "eval: [3440/7902] | data 0.074s | net 0.022s\n",
      "eval: [3460/7902] | data 0.068s | net 0.021s\n",
      "eval: [3480/7902] | data 0.064s | net 0.023s\n",
      "eval: [3500/7902] | data 0.064s | net 0.023s\n",
      "eval: [3520/7902] | data 0.063s | net 0.024s\n",
      "eval: [3540/7902] | data 0.066s | net 0.024s\n",
      "eval: [3560/7902] | data 0.063s | net 0.024s\n",
      "eval: [3580/7902] | data 0.097s | net 0.025s\n",
      "eval: [3600/7902] | data 0.080s | net 0.026s\n",
      "eval: [3620/7902] | data 0.070s | net 0.025s\n",
      "eval: [3640/7902] | data 0.075s | net 0.027s\n",
      "eval: [3660/7902] | data 0.063s | net 0.025s\n",
      "eval: [3680/7902] | data 0.082s | net 0.029s\n",
      "eval: [3700/7902] | data 0.076s | net 0.024s\n",
      "eval: [3720/7902] | data 0.042s | net 0.026s\n",
      "eval: [3740/7902] | data 0.059s | net 0.024s\n",
      "eval: [3760/7902] | data 0.043s | net 0.025s\n",
      "eval: [3780/7902] | data 0.042s | net 0.023s\n",
      "eval: [3800/7902] | data 0.041s | net 0.023s\n",
      "eval: [3820/7902] | data 0.041s | net 0.024s\n",
      "eval: [3840/7902] | data 0.041s | net 0.025s\n",
      "eval: [3860/7902] | data 0.042s | net 0.023s\n",
      "eval: [3880/7902] | data 0.041s | net 0.023s\n",
      "eval: [3900/7902] | data 0.041s | net 0.023s\n",
      "eval: [3920/7902] | data 0.063s | net 0.022s\n",
      "eval: [3940/7902] | data 0.040s | net 0.023s\n",
      "eval: [3960/7902] | data 0.056s | net 0.023s\n",
      "eval: [3980/7902] | data 0.059s | net 0.024s\n",
      "eval: [4000/7902] | data 0.041s | net 0.024s\n",
      "eval: [4020/7902] | data 0.040s | net 0.022s\n",
      "eval: [4040/7902] | data 0.042s | net 0.023s\n",
      "eval: [4060/7902] | data 0.035s | net 0.022s\n",
      "eval: [4080/7902] | data 0.068s | net 0.025s\n",
      "eval: [4100/7902] | data 0.041s | net 0.022s\n",
      "eval: [4120/7902] | data 0.052s | net 0.024s\n",
      "eval: [4140/7902] | data 0.041s | net 0.022s\n",
      "eval: [4160/7902] | data 0.041s | net 0.022s\n",
      "eval: [4180/7902] | data 0.042s | net 0.023s\n",
      "eval: [4200/7902] | data 0.042s | net 0.023s\n",
      "eval: [4220/7902] | data 0.073s | net 0.024s\n",
      "eval: [4240/7902] | data 0.066s | net 0.023s\n",
      "eval: [4260/7902] | data 0.042s | net 0.023s\n",
      "eval: [4280/7902] | data 0.073s | net 0.023s\n",
      "eval: [4300/7902] | data 0.041s | net 0.023s\n",
      "eval: [4320/7902] | data 0.048s | net 0.024s\n",
      "eval: [4340/7902] | data 0.043s | net 0.023s\n",
      "eval: [4360/7902] | data 0.042s | net 0.022s\n",
      "eval: [4380/7902] | data 0.066s | net 0.023s\n",
      "eval: [4400/7902] | data 0.066s | net 0.023s\n",
      "eval: [4420/7902] | data 0.060s | net 0.024s\n",
      "eval: [4440/7902] | data 0.055s | net 0.024s\n",
      "eval: [4460/7902] | data 0.055s | net 0.023s\n",
      "eval: [4480/7902] | data 0.041s | net 0.023s\n",
      "eval: [4500/7902] | data 0.039s | net 0.024s\n",
      "eval: [4520/7902] | data 0.042s | net 0.023s\n",
      "eval: [4540/7902] | data 0.042s | net 0.023s\n",
      "eval: [4560/7902] | data 0.042s | net 0.024s\n",
      "eval: [4580/7902] | data 0.041s | net 0.024s\n",
      "eval: [4600/7902] | data 0.042s | net 0.023s\n",
      "eval: [4620/7902] | data 0.045s | net 0.023s\n",
      "eval: [4640/7902] | data 0.042s | net 0.023s\n",
      "eval: [4660/7902] | data 0.042s | net 0.022s\n",
      "eval: [4680/7902] | data 0.042s | net 0.024s\n",
      "eval: [4700/7902] | data 0.047s | net 0.021s\n",
      "eval: [4720/7902] | data 0.096s | net 0.022s\n",
      "eval: [4740/7902] | data 0.050s | net 0.022s\n",
      "eval: [4760/7902] | data 0.077s | net 0.023s\n",
      "eval: [4780/7902] | data 0.096s | net 0.023s\n",
      "eval: [4800/7902] | data 0.033s | net 0.023s\n",
      "eval: [4820/7902] | data 0.065s | net 0.023s\n",
      "eval: [4840/7902] | data 0.074s | net 0.022s\n",
      "eval: [4860/7902] | data 0.049s | net 0.021s\n",
      "eval: [4880/7902] | data 0.047s | net 0.021s\n",
      "eval: [4900/7902] | data 0.062s | net 0.021s\n",
      "eval: [4920/7902] | data 0.065s | net 0.022s\n",
      "eval: [4940/7902] | data 0.029s | net 0.021s\n",
      "eval: [4960/7902] | data 0.091s | net 0.022s\n",
      "eval: [4980/7902] | data 0.151s | net 0.022s\n",
      "eval: [5000/7902] | data 0.091s | net 0.023s\n",
      "eval: [5020/7902] | data 0.106s | net 0.022s\n",
      "eval: [5040/7902] | data 0.067s | net 0.022s\n",
      "eval: [5060/7902] | data 0.125s | net 0.023s\n",
      "eval: [5080/7902] | data 0.111s | net 0.022s\n",
      "eval: [5100/7902] | data 0.101s | net 0.022s\n",
      "eval: [5120/7902] | data 0.104s | net 0.022s\n",
      "eval: [5140/7902] | data 0.114s | net 0.022s\n",
      "eval: [5160/7902] | data 0.130s | net 0.021s\n",
      "eval: [5180/7902] | data 0.088s | net 0.022s\n",
      "eval: [5200/7902] | data 0.259s | net 0.022s\n",
      "eval: [5220/7902] | data 0.225s | net 0.021s\n",
      "eval: [5240/7902] | data 0.216s | net 0.021s\n",
      "eval: [5260/7902] | data 0.228s | net 0.020s\n",
      "eval: [5280/7902] | data 0.228s | net 0.023s\n",
      "eval: [5300/7902] | data 0.250s | net 0.022s\n",
      "eval: [5320/7902] | data 0.174s | net 0.021s\n",
      "eval: [5340/7902] | data 0.227s | net 0.022s\n",
      "eval: [5360/7902] | data 0.224s | net 0.022s\n",
      "eval: [5380/7902] | data 0.196s | net 0.022s\n",
      "eval: [5400/7902] | data 0.225s | net 0.023s\n",
      "eval: [5420/7902] | data 0.251s | net 0.023s\n",
      "eval: [5440/7902] | data 0.179s | net 0.020s\n",
      "eval: [5460/7902] | data 0.229s | net 0.022s\n",
      "eval: [5480/7902] | data 0.254s | net 0.023s\n",
      "eval: [5500/7902] | data 0.179s | net 0.021s\n",
      "eval: [5520/7902] | data 0.214s | net 0.022s\n",
      "eval: [5540/7902] | data 0.231s | net 0.021s\n",
      "eval: [5560/7902] | data 0.228s | net 0.022s\n",
      "eval: [5580/7902] | data 0.204s | net 0.023s\n",
      "eval: [5600/7902] | data 0.041s | net 0.022s\n",
      "eval: [5620/7902] | data 0.043s | net 0.023s\n",
      "eval: [5640/7902] | data 0.042s | net 0.023s\n",
      "eval: [5660/7902] | data 0.069s | net 0.024s\n",
      "eval: [5680/7902] | data 0.041s | net 0.023s\n",
      "eval: [5700/7902] | data 0.039s | net 0.023s\n",
      "eval: [5720/7902] | data 0.041s | net 0.021s\n",
      "eval: [5740/7902] | data 0.033s | net 0.021s\n",
      "eval: [5760/7902] | data 0.032s | net 0.021s\n",
      "eval: [5780/7902] | data 0.033s | net 0.022s\n",
      "eval: [5800/7902] | data 0.041s | net 0.022s\n",
      "eval: [5820/7902] | data 0.054s | net 0.022s\n",
      "eval: [5840/7902] | data 0.066s | net 0.021s\n",
      "eval: [5860/7902] | data 0.042s | net 0.022s\n",
      "eval: [5880/7902] | data 0.055s | net 0.023s\n",
      "eval: [5900/7902] | data 0.042s | net 0.022s\n",
      "eval: [5920/7902] | data 0.041s | net 0.023s\n",
      "eval: [5940/7902] | data 0.045s | net 0.021s\n",
      "eval: [5960/7902] | data 0.045s | net 0.021s\n",
      "eval: [5980/7902] | data 0.078s | net 0.021s\n",
      "eval: [6000/7902] | data 0.057s | net 0.022s\n",
      "eval: [6020/7902] | data 0.057s | net 0.023s\n",
      "eval: [6040/7902] | data 0.073s | net 0.023s\n",
      "eval: [6060/7902] | data 0.058s | net 0.023s\n",
      "eval: [6080/7902] | data 0.059s | net 0.023s\n",
      "eval: [6100/7902] | data 0.076s | net 0.022s\n",
      "eval: [6120/7902] | data 0.059s | net 0.023s\n",
      "eval: [6140/7902] | data 0.058s | net 0.022s\n",
      "eval: [6160/7902] | data 0.051s | net 0.023s\n",
      "eval: [6180/7902] | data 0.046s | net 0.022s\n",
      "eval: [6200/7902] | data 0.059s | net 0.022s\n",
      "eval: [6220/7902] | data 0.058s | net 0.023s\n",
      "eval: [6240/7902] | data 0.059s | net 0.025s\n",
      "eval: [6260/7902] | data 0.059s | net 0.025s\n",
      "eval: [6280/7902] | data 0.072s | net 0.025s\n",
      "eval: [6300/7902] | data 0.062s | net 0.024s\n",
      "eval: [6320/7902] | data 0.075s | net 0.025s\n",
      "eval: [6340/7902] | data 0.062s | net 0.023s\n",
      "eval: [6360/7902] | data 0.062s | net 0.023s\n",
      "eval: [6380/7902] | data 0.060s | net 0.022s\n",
      "eval: [6400/7902] | data 0.060s | net 0.024s\n",
      "eval: [6420/7902] | data 0.061s | net 0.023s\n",
      "eval: [6440/7902] | data 0.060s | net 0.023s\n",
      "eval: [6460/7902] | data 0.061s | net 0.025s\n",
      "eval: [6480/7902] | data 0.061s | net 0.022s\n",
      "eval: [6500/7902] | data 0.062s | net 0.021s\n",
      "eval: [6520/7902] | data 0.061s | net 0.022s\n",
      "eval: [6540/7902] | data 0.063s | net 0.031s\n",
      "eval: [6560/7902] | data 0.072s | net 0.024s\n",
      "eval: [6580/7902] | data 0.089s | net 0.024s\n",
      "eval: [6600/7902] | data 0.102s | net 0.027s\n",
      "eval: [6620/7902] | data 0.101s | net 0.028s\n",
      "eval: [6640/7902] | data 0.070s | net 0.023s\n",
      "eval: [6660/7902] | data 0.071s | net 0.023s\n",
      "eval: [6680/7902] | data 0.071s | net 0.023s\n",
      "eval: [6700/7902] | data 0.070s | net 0.023s\n",
      "eval: [6720/7902] | data 0.069s | net 0.022s\n",
      "eval: [6740/7902] | data 0.069s | net 0.022s\n",
      "eval: [6760/7902] | data 0.067s | net 0.023s\n",
      "eval: [6780/7902] | data 0.097s | net 0.024s\n",
      "eval: [6800/7902] | data 0.069s | net 0.022s\n",
      "eval: [6820/7902] | data 0.069s | net 0.022s\n",
      "eval: [6840/7902] | data 0.078s | net 0.023s\n",
      "eval: [6860/7902] | data 0.070s | net 0.024s\n",
      "eval: [6880/7902] | data 0.069s | net 0.023s\n",
      "eval: [6900/7902] | data 0.070s | net 0.023s\n",
      "eval: [6920/7902] | data 0.327s | net 0.023s\n",
      "eval: [6940/7902] | data 0.142s | net 0.022s\n",
      "eval: [6960/7902] | data 0.291s | net 0.023s\n",
      "eval: [6980/7902] | data 0.288s | net 0.024s\n",
      "eval: [7000/7902] | data 0.317s | net 0.023s\n",
      "eval: [7020/7902] | data 0.269s | net 0.023s\n",
      "eval: [7040/7902] | data 0.270s | net 0.022s\n",
      "eval: [7060/7902] | data 0.278s | net 0.024s\n",
      "eval: [7080/7902] | data 0.270s | net 0.023s\n",
      "eval: [7100/7902] | data 0.269s | net 0.023s\n",
      "eval: [7120/7902] | data 0.262s | net 0.024s\n",
      "eval: [7140/7902] | data 0.249s | net 0.024s\n",
      "eval: [7160/7902] | data 0.160s | net 0.023s\n",
      "eval: [7180/7902] | data 0.252s | net 0.023s\n",
      "eval: [7200/7902] | data 0.251s | net 0.024s\n",
      "eval: [7220/7902] | data 0.145s | net 0.023s\n",
      "eval: [7240/7902] | data 0.249s | net 0.024s\n",
      "eval: [7260/7902] | data 0.265s | net 0.023s\n",
      "eval: [7280/7902] | data 0.249s | net 0.024s\n",
      "eval: [7300/7902] | data 0.147s | net 0.023s\n",
      "eval: [7320/7902] | data 0.245s | net 0.023s\n",
      "eval: [7340/7902] | data 0.257s | net 0.023s\n",
      "eval: [7360/7902] | data 0.275s | net 0.023s\n",
      "eval: [7380/7902] | data 0.164s | net 0.023s\n",
      "eval: [7400/7902] | data 0.262s | net 0.024s\n",
      "eval: [7420/7902] | data 0.274s | net 0.024s\n",
      "eval: [7440/7902] | data 0.274s | net 0.025s\n",
      "eval: [7460/7902] | data 0.262s | net 0.023s\n",
      "eval: [7480/7902] | data 0.243s | net 0.023s\n",
      "eval: [7500/7902] | data 0.169s | net 0.023s\n",
      "eval: [7520/7902] | data 0.250s | net 0.025s\n",
      "eval: [7540/7902] | data 0.237s | net 0.023s\n",
      "eval: [7560/7902] | data 0.243s | net 0.025s\n",
      "eval: [7580/7902] | data 0.167s | net 0.027s\n",
      "eval: [7600/7902] | data 0.241s | net 0.025s\n",
      "eval: [7620/7902] | data 0.248s | net 0.023s\n",
      "eval: [7640/7902] | data 0.148s | net 0.025s\n",
      "eval: [7660/7902] | data 0.260s | net 0.025s\n",
      "eval: [7680/7902] | data 0.281s | net 0.023s\n",
      "eval: [7700/7902] | data 0.277s | net 0.022s\n",
      "eval: [7720/7902] | data 0.306s | net 0.023s\n",
      "eval: [7740/7902] | data 0.279s | net 0.023s\n",
      "eval: [7760/7902] | data 0.234s | net 0.022s\n",
      "eval: [7780/7902] | data 0.296s | net 0.023s\n",
      "eval: [7800/7902] | data 0.259s | net 0.022s\n",
      "eval: [7820/7902] | data 0.265s | net 0.022s\n",
      "eval: [7840/7902] | data 0.259s | net 0.022s\n",
      "eval: [7860/7902] | data 0.203s | net 0.020s\n",
      "eval: [7880/7902] | data 0.207s | net 0.020s\n",
      "eval: [7900/7902] | data 0.232s | net 0.020s\n",
      "Elapsed 13.96min (106.0ms/image, 9.4frames/s)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bike_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bike_orientation.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (car_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (car_orientation.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for participating in our evaluation!\n",
      "Loading detections...\n",
      "  done.\n",
      "Your evaluation results are available in /home/gj/hazen/QAT_Squeezedet/SqueezeDet-PyTorch/exp/test_veh_det_trt_calib_sqdet/results\n",
      "bike_easy            0.525\n",
      "bike_moderate        0.525\n",
      "bike_hard            0.525\n",
      "car_easy             0.765\n",
      "car_moderate         0.762\n",
      "car_hard             0.762\n",
      "bus_easy             0.489\n",
      "bus_moderate         0.488\n",
      "bus_hard             0.488\n",
      "mAP                  0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bus_detection.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n",
      "sh: 1: gnuplot: not found\n",
      "sh: 1: gnuplot: not found\n",
      "Error: /undefinedfilename in (bus_orientation.eps)\n",
      "Operand stack:\n",
      "\n",
      "Execution stack:\n",
      "   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push\n",
      "Dictionary stack:\n",
      "   --dict:956/1684(ro)(G)--   --dict:0/20(G)--   --dict:77/200(L)--\n",
      "Current allocation mode is local\n",
      "Last OS error: No such file or directory\n",
      "GPL Ghostscript 9.26: Unrecoverable error, exit code 1\n",
      "sh: 1: pdfcrop: not found\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # for method in [\"percentile\", \"mse\", \"entropy\"]:\n",
    "    for method in [\"mse\"]:\n",
    "        percentile = 99.99\n",
    "        print(F\" ############  {method} calibration ######################\")\n",
    "        if(method == 'percentile'):\n",
    "            compute_amax(detector.model, method=method, percentile = percentile)\n",
    "        else:\n",
    "            compute_amax(detector.model, method=method)\n",
    "        update_exp_dir(cfg, f\"trt_calib_veh_det_{method}\")\n",
    "        results = detector.detect_dataset(eval_dataset, cfg)\n",
    "        eval_dataset.save_results(results)\n",
    "        aps = eval_dataset.evaluate()\n",
    "        for k, v in aps.items():\n",
    "                print('{:<20} {:.3f}'.format(k, v))\n",
    "        torch.save(detector.model.state_dict(), os.path.join(cfg.save_dir, f\"quant_veh_det_squeezedet_{method}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print (detector.model)\n",
    "# print (detector.model.base.features[0][0].input_quantizer.amax)\n",
    "# print (detector.model.base.features[0][0].weight_quantizer.amax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_dataset.save_results(results)\n",
    "# aps = eval_dataset.evaluate()\n",
    "# for k, v in aps.items():\n",
    "#         print('{:<20} {:.3f}'.format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(detector.model.state_dict(), \"../exp/quant_veh_det_squeezedet_model_41.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0818 16:44:35.580255 139799529214144 tensor_quantizer.py:120] Fake quantize mode doesn't use scale explicitly!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# print (dir(detector.model.base.conv1.weight_quantizer))\n",
    "# print (detector.model.base.conv1.weight_quantizer.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = detector.model.base\n",
    "# test.cpu()\n",
    "# quant_nn.TensorQuantizer.use_fb_fake_quant = True\n",
    "# dummy_input = torch.randn(1, 3, 128, 128)\n",
    "\n",
    "# # input_names = [ \"network.0\" ]\n",
    "# # output_names = [ \"network.23\" ]\n",
    "\n",
    "# # enable_onnx_checker needs to be disabled. See notes below.\n",
    "# torch.onnx.export(\n",
    "#     test, dummy_input, \"../exp/test.onnx\", verbose=True, opset_version=13, enable_onnx_checker=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['base.conv1.weight', 'base.conv1.bias', 'base.conv1._input_quantizer._amax', 'base.conv1._weight_quantizer._amax', 'base.features.1.squeeze.weight', 'base.features.1.squeeze.bias', 'base.features.1.squeeze._input_quantizer._amax', 'base.features.1.squeeze._weight_quantizer._amax', 'base.features.1.expand1x1.weight', 'base.features.1.expand1x1.bias', 'base.features.1.expand1x1._input_quantizer._amax', 'base.features.1.expand1x1._weight_quantizer._amax', 'base.features.1.expand3x3.weight', 'base.features.1.expand3x3.bias', 'base.features.1.expand3x3._input_quantizer._amax', 'base.features.1.expand3x3._weight_quantizer._amax', 'base.features.2.squeeze.weight', 'base.features.2.squeeze.bias', 'base.features.2.squeeze._input_quantizer._amax', 'base.features.2.squeeze._weight_quantizer._amax', 'base.features.2.expand1x1.weight', 'base.features.2.expand1x1.bias', 'base.features.2.expand1x1._input_quantizer._amax', 'base.features.2.expand1x1._weight_quantizer._amax', 'base.features.2.expand3x3.weight', 'base.features.2.expand3x3.bias', 'base.features.2.expand3x3._input_quantizer._amax', 'base.features.2.expand3x3._weight_quantizer._amax', 'base.features.4.squeeze.weight', 'base.features.4.squeeze.bias', 'base.features.4.squeeze._input_quantizer._amax', 'base.features.4.squeeze._weight_quantizer._amax', 'base.features.4.expand1x1.weight', 'base.features.4.expand1x1.bias', 'base.features.4.expand1x1._input_quantizer._amax', 'base.features.4.expand1x1._weight_quantizer._amax', 'base.features.4.expand3x3.weight', 'base.features.4.expand3x3.bias', 'base.features.4.expand3x3._input_quantizer._amax', 'base.features.4.expand3x3._weight_quantizer._amax', 'base.features.5.squeeze.weight', 'base.features.5.squeeze.bias', 'base.features.5.squeeze._input_quantizer._amax', 'base.features.5.squeeze._weight_quantizer._amax', 'base.features.5.expand1x1.weight', 'base.features.5.expand1x1.bias', 'base.features.5.expand1x1._input_quantizer._amax', 'base.features.5.expand1x1._weight_quantizer._amax', 'base.features.5.expand3x3.weight', 'base.features.5.expand3x3.bias', 'base.features.5.expand3x3._input_quantizer._amax', 'base.features.5.expand3x3._weight_quantizer._amax', 'base.features.7.squeeze.weight', 'base.features.7.squeeze.bias', 'base.features.7.squeeze._input_quantizer._amax', 'base.features.7.squeeze._weight_quantizer._amax', 'base.features.7.expand1x1.weight', 'base.features.7.expand1x1.bias', 'base.features.7.expand1x1._input_quantizer._amax', 'base.features.7.expand1x1._weight_quantizer._amax', 'base.features.7.expand3x3.weight', 'base.features.7.expand3x3.bias', 'base.features.7.expand3x3._input_quantizer._amax', 'base.features.7.expand3x3._weight_quantizer._amax', 'base.features.8.squeeze.weight', 'base.features.8.squeeze.bias', 'base.features.8.squeeze._input_quantizer._amax', 'base.features.8.squeeze._weight_quantizer._amax', 'base.features.8.expand1x1.weight', 'base.features.8.expand1x1.bias', 'base.features.8.expand1x1._input_quantizer._amax', 'base.features.8.expand1x1._weight_quantizer._amax', 'base.features.8.expand3x3.weight', 'base.features.8.expand3x3.bias', 'base.features.8.expand3x3._input_quantizer._amax', 'base.features.8.expand3x3._weight_quantizer._amax', 'base.features.9.squeeze.weight', 'base.features.9.squeeze.bias', 'base.features.9.squeeze._input_quantizer._amax', 'base.features.9.squeeze._weight_quantizer._amax', 'base.features.9.expand1x1.weight', 'base.features.9.expand1x1.bias', 'base.features.9.expand1x1._input_quantizer._amax', 'base.features.9.expand1x1._weight_quantizer._amax', 'base.features.9.expand3x3.weight', 'base.features.9.expand3x3.bias', 'base.features.9.expand3x3._input_quantizer._amax', 'base.features.9.expand3x3._weight_quantizer._amax', 'base.features.10.squeeze.weight', 'base.features.10.squeeze.bias', 'base.features.10.squeeze._input_quantizer._amax', 'base.features.10.squeeze._weight_quantizer._amax', 'base.features.10.expand1x1.weight', 'base.features.10.expand1x1.bias', 'base.features.10.expand1x1._input_quantizer._amax', 'base.features.10.expand1x1._weight_quantizer._amax', 'base.features.10.expand3x3.weight', 'base.features.10.expand3x3.bias', 'base.features.10.expand3x3._input_quantizer._amax', 'base.features.10.expand3x3._weight_quantizer._amax', 'base.features.11.squeeze.weight', 'base.features.11.squeeze.bias', 'base.features.11.squeeze._input_quantizer._amax', 'base.features.11.squeeze._weight_quantizer._amax', 'base.features.11.expand1x1.weight', 'base.features.11.expand1x1.bias', 'base.features.11.expand1x1._input_quantizer._amax', 'base.features.11.expand1x1._weight_quantizer._amax', 'base.features.11.expand3x3.weight', 'base.features.11.expand3x3.bias', 'base.features.11.expand3x3._input_quantizer._amax', 'base.features.11.expand3x3._weight_quantizer._amax', 'base.features.12.squeeze.weight', 'base.features.12.squeeze.bias', 'base.features.12.squeeze._input_quantizer._amax', 'base.features.12.squeeze._weight_quantizer._amax', 'base.features.12.expand1x1.weight', 'base.features.12.expand1x1.bias', 'base.features.12.expand1x1._input_quantizer._amax', 'base.features.12.expand1x1._weight_quantizer._amax', 'base.features.12.expand3x3.weight', 'base.features.12.expand3x3.bias', 'base.features.12.expand3x3._input_quantizer._amax', 'base.features.12.expand3x3._weight_quantizer._amax', 'base.convdet.weight', 'base.convdet.bias', 'base.convdet._input_quantizer._amax', 'base.convdet._weight_quantizer._amax'])\n"
     ]
    }
   ],
   "source": [
    "dict = torch.load(\"../exp/quant_veh_det_squeezedet_model_41.pth\")\n",
    "print (dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (alpr)\n",
    "def get_scales_input_per_tensor(amax, _num_bits = 8 , _unsigned = False):\n",
    "    bound = (1 << (_num_bits - 1 + int(_unsigned))) - 1    \n",
    "    zero_point_per_tensor = 0 #since symmertric quant\n",
    "    scale_per_tensor = amax / bound\n",
    "    return scale_per_tensor, zero_point_per_tensor\n",
    "\n",
    "def get_scales_weight_per_channel(amax, _num_bits = 8, _unsigned = False):\n",
    "    bound = (1 << (_num_bits - 1 + int(_unsigned))) - 1\n",
    "    amax_sequeeze = amax.squeeze().detach()\n",
    "    scale_per_channel =  amax_sequeeze/bound\n",
    "    zero_point_per_channel = torch.zeros_like(scale_per_channel, dtype=torch.int32).data\n",
    "    quant_axis = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
    "    return scale_per_channel, zero_point_per_channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['base.conv1.weight', 'base.conv1.bias', 'base.conv1._input_quantizer._amax.scales', 'base.conv1._input_quantizer._amax', 'base.conv1._weight_quantizer._amax.scales', 'base.conv1._weight_quantizer._amax', 'base.features.1.squeeze.weight', 'base.features.1.squeeze.bias', 'base.features.1.squeeze._input_quantizer._amax.scales', 'base.features.1.squeeze._input_quantizer._amax', 'base.features.1.squeeze._weight_quantizer._amax.scales', 'base.features.1.squeeze._weight_quantizer._amax', 'base.features.1.expand1x1.weight', 'base.features.1.expand1x1.bias', 'base.features.1.expand1x1._input_quantizer._amax.scales', 'base.features.1.expand1x1._input_quantizer._amax', 'base.features.1.expand1x1._weight_quantizer._amax.scales', 'base.features.1.expand1x1._weight_quantizer._amax', 'base.features.1.expand3x3.weight', 'base.features.1.expand3x3.bias', 'base.features.1.expand3x3._input_quantizer._amax.scales', 'base.features.1.expand3x3._input_quantizer._amax', 'base.features.1.expand3x3._weight_quantizer._amax.scales', 'base.features.1.expand3x3._weight_quantizer._amax', 'base.features.2.squeeze.weight', 'base.features.2.squeeze.bias', 'base.features.2.squeeze._input_quantizer._amax.scales', 'base.features.2.squeeze._input_quantizer._amax', 'base.features.2.squeeze._weight_quantizer._amax.scales', 'base.features.2.squeeze._weight_quantizer._amax', 'base.features.2.expand1x1.weight', 'base.features.2.expand1x1.bias', 'base.features.2.expand1x1._input_quantizer._amax.scales', 'base.features.2.expand1x1._input_quantizer._amax', 'base.features.2.expand1x1._weight_quantizer._amax.scales', 'base.features.2.expand1x1._weight_quantizer._amax', 'base.features.2.expand3x3.weight', 'base.features.2.expand3x3.bias', 'base.features.2.expand3x3._input_quantizer._amax.scales', 'base.features.2.expand3x3._input_quantizer._amax', 'base.features.2.expand3x3._weight_quantizer._amax.scales', 'base.features.2.expand3x3._weight_quantizer._amax', 'base.features.4.squeeze.weight', 'base.features.4.squeeze.bias', 'base.features.4.squeeze._input_quantizer._amax.scales', 'base.features.4.squeeze._input_quantizer._amax', 'base.features.4.squeeze._weight_quantizer._amax.scales', 'base.features.4.squeeze._weight_quantizer._amax', 'base.features.4.expand1x1.weight', 'base.features.4.expand1x1.bias', 'base.features.4.expand1x1._input_quantizer._amax.scales', 'base.features.4.expand1x1._input_quantizer._amax', 'base.features.4.expand1x1._weight_quantizer._amax.scales', 'base.features.4.expand1x1._weight_quantizer._amax', 'base.features.4.expand3x3.weight', 'base.features.4.expand3x3.bias', 'base.features.4.expand3x3._input_quantizer._amax.scales', 'base.features.4.expand3x3._input_quantizer._amax', 'base.features.4.expand3x3._weight_quantizer._amax.scales', 'base.features.4.expand3x3._weight_quantizer._amax', 'base.features.5.squeeze.weight', 'base.features.5.squeeze.bias', 'base.features.5.squeeze._input_quantizer._amax.scales', 'base.features.5.squeeze._input_quantizer._amax', 'base.features.5.squeeze._weight_quantizer._amax.scales', 'base.features.5.squeeze._weight_quantizer._amax', 'base.features.5.expand1x1.weight', 'base.features.5.expand1x1.bias', 'base.features.5.expand1x1._input_quantizer._amax.scales', 'base.features.5.expand1x1._input_quantizer._amax', 'base.features.5.expand1x1._weight_quantizer._amax.scales', 'base.features.5.expand1x1._weight_quantizer._amax', 'base.features.5.expand3x3.weight', 'base.features.5.expand3x3.bias', 'base.features.5.expand3x3._input_quantizer._amax.scales', 'base.features.5.expand3x3._input_quantizer._amax', 'base.features.5.expand3x3._weight_quantizer._amax.scales', 'base.features.5.expand3x3._weight_quantizer._amax', 'base.features.7.squeeze.weight', 'base.features.7.squeeze.bias', 'base.features.7.squeeze._input_quantizer._amax.scales', 'base.features.7.squeeze._input_quantizer._amax', 'base.features.7.squeeze._weight_quantizer._amax.scales', 'base.features.7.squeeze._weight_quantizer._amax', 'base.features.7.expand1x1.weight', 'base.features.7.expand1x1.bias', 'base.features.7.expand1x1._input_quantizer._amax.scales', 'base.features.7.expand1x1._input_quantizer._amax', 'base.features.7.expand1x1._weight_quantizer._amax.scales', 'base.features.7.expand1x1._weight_quantizer._amax', 'base.features.7.expand3x3.weight', 'base.features.7.expand3x3.bias', 'base.features.7.expand3x3._input_quantizer._amax.scales', 'base.features.7.expand3x3._input_quantizer._amax', 'base.features.7.expand3x3._weight_quantizer._amax.scales', 'base.features.7.expand3x3._weight_quantizer._amax', 'base.features.8.squeeze.weight', 'base.features.8.squeeze.bias', 'base.features.8.squeeze._input_quantizer._amax.scales', 'base.features.8.squeeze._input_quantizer._amax', 'base.features.8.squeeze._weight_quantizer._amax.scales', 'base.features.8.squeeze._weight_quantizer._amax', 'base.features.8.expand1x1.weight', 'base.features.8.expand1x1.bias', 'base.features.8.expand1x1._input_quantizer._amax.scales', 'base.features.8.expand1x1._input_quantizer._amax', 'base.features.8.expand1x1._weight_quantizer._amax.scales', 'base.features.8.expand1x1._weight_quantizer._amax', 'base.features.8.expand3x3.weight', 'base.features.8.expand3x3.bias', 'base.features.8.expand3x3._input_quantizer._amax.scales', 'base.features.8.expand3x3._input_quantizer._amax', 'base.features.8.expand3x3._weight_quantizer._amax.scales', 'base.features.8.expand3x3._weight_quantizer._amax', 'base.features.9.squeeze.weight', 'base.features.9.squeeze.bias', 'base.features.9.squeeze._input_quantizer._amax.scales', 'base.features.9.squeeze._input_quantizer._amax', 'base.features.9.squeeze._weight_quantizer._amax.scales', 'base.features.9.squeeze._weight_quantizer._amax', 'base.features.9.expand1x1.weight', 'base.features.9.expand1x1.bias', 'base.features.9.expand1x1._input_quantizer._amax.scales', 'base.features.9.expand1x1._input_quantizer._amax', 'base.features.9.expand1x1._weight_quantizer._amax.scales', 'base.features.9.expand1x1._weight_quantizer._amax', 'base.features.9.expand3x3.weight', 'base.features.9.expand3x3.bias', 'base.features.9.expand3x3._input_quantizer._amax.scales', 'base.features.9.expand3x3._input_quantizer._amax', 'base.features.9.expand3x3._weight_quantizer._amax.scales', 'base.features.9.expand3x3._weight_quantizer._amax', 'base.features.10.squeeze.weight', 'base.features.10.squeeze.bias', 'base.features.10.squeeze._input_quantizer._amax.scales', 'base.features.10.squeeze._input_quantizer._amax', 'base.features.10.squeeze._weight_quantizer._amax.scales', 'base.features.10.squeeze._weight_quantizer._amax', 'base.features.10.expand1x1.weight', 'base.features.10.expand1x1.bias', 'base.features.10.expand1x1._input_quantizer._amax.scales', 'base.features.10.expand1x1._input_quantizer._amax', 'base.features.10.expand1x1._weight_quantizer._amax.scales', 'base.features.10.expand1x1._weight_quantizer._amax', 'base.features.10.expand3x3.weight', 'base.features.10.expand3x3.bias', 'base.features.10.expand3x3._input_quantizer._amax.scales', 'base.features.10.expand3x3._input_quantizer._amax', 'base.features.10.expand3x3._weight_quantizer._amax.scales', 'base.features.10.expand3x3._weight_quantizer._amax', 'base.features.11.squeeze.weight', 'base.features.11.squeeze.bias', 'base.features.11.squeeze._input_quantizer._amax.scales', 'base.features.11.squeeze._input_quantizer._amax', 'base.features.11.squeeze._weight_quantizer._amax.scales', 'base.features.11.squeeze._weight_quantizer._amax', 'base.features.11.expand1x1.weight', 'base.features.11.expand1x1.bias', 'base.features.11.expand1x1._input_quantizer._amax.scales', 'base.features.11.expand1x1._input_quantizer._amax', 'base.features.11.expand1x1._weight_quantizer._amax.scales', 'base.features.11.expand1x1._weight_quantizer._amax', 'base.features.11.expand3x3.weight', 'base.features.11.expand3x3.bias', 'base.features.11.expand3x3._input_quantizer._amax.scales', 'base.features.11.expand3x3._input_quantizer._amax', 'base.features.11.expand3x3._weight_quantizer._amax.scales', 'base.features.11.expand3x3._weight_quantizer._amax', 'base.features.12.squeeze.weight', 'base.features.12.squeeze.bias', 'base.features.12.squeeze._input_quantizer._amax.scales', 'base.features.12.squeeze._input_quantizer._amax', 'base.features.12.squeeze._weight_quantizer._amax.scales', 'base.features.12.squeeze._weight_quantizer._amax', 'base.features.12.expand1x1.weight', 'base.features.12.expand1x1.bias', 'base.features.12.expand1x1._input_quantizer._amax.scales', 'base.features.12.expand1x1._input_quantizer._amax', 'base.features.12.expand1x1._weight_quantizer._amax.scales', 'base.features.12.expand1x1._weight_quantizer._amax', 'base.features.12.expand3x3.weight', 'base.features.12.expand3x3.bias', 'base.features.12.expand3x3._input_quantizer._amax.scales', 'base.features.12.expand3x3._input_quantizer._amax', 'base.features.12.expand3x3._weight_quantizer._amax.scales', 'base.features.12.expand3x3._weight_quantizer._amax', 'base.convdet.weight', 'base.convdet.bias', 'base.convdet._input_quantizer._amax.scales', 'base.convdet._input_quantizer._amax', 'base.convdet._weight_quantizer._amax.scales', 'base.convdet._weight_quantizer._amax'])\n"
     ]
    }
   ],
   "source": [
    "veh_det_epoch41_dict_with_scales = {}\n",
    "\n",
    "for key in dict:\n",
    "    if key.find('_input_quantizer._amax') != -1:\n",
    "        amax = dict[key]\n",
    "        scales, zero_point = get_scales_input_per_tensor(amax)\n",
    "        new_key = key + '.scales'\n",
    "        veh_det_epoch41_dict_with_scales[new_key] = scales\n",
    "    elif key.find('_weight_quantizer._amax') != -1:\n",
    "        amax = dict[key]\n",
    "        scales, zero_point = get_scales_weight_per_channel(amax)\n",
    "        new_key = key + '.scales'\n",
    "        veh_det_epoch41_dict_with_scales[new_key] = scales\n",
    "    \n",
    "    veh_det_epoch41_dict_with_scales[key] = dict[key]\n",
    "\n",
    "print (veh_det_epoch41_dict_with_scales.keys())\n",
    "# print (veh_det_epoch41_dict_with_scales['conv1._input_quantizer._amax.scales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(veh_det_epoch41_dict_with_scales, \"../exp/quant_veh_det_squeezedet_model_41_w_scales.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base.conv1.weight', 'base.conv1.bias', 'base.conv1._input_quantizer._amax.scales', 'base.conv1._input_quantizer._amax', 'base.conv1._weight_quantizer._amax.scales', 'base.conv1._weight_quantizer._amax', 'base.features.1.squeeze.weight', 'base.features.1.squeeze.bias', 'base.features.1.squeeze._input_quantizer._amax.scales', 'base.features.1.squeeze._input_quantizer._amax', 'base.features.1.squeeze._weight_quantizer._amax.scales', 'base.features.1.squeeze._weight_quantizer._amax', 'base.features.1.expand1x1.weight', 'base.features.1.expand1x1.bias', 'base.features.1.expand1x1._input_quantizer._amax.scales', 'base.features.1.expand1x1._input_quantizer._amax', 'base.features.1.expand1x1._weight_quantizer._amax.scales', 'base.features.1.expand1x1._weight_quantizer._amax', 'base.features.1.expand3x3.weight', 'base.features.1.expand3x3.bias', 'base.features.1.expand3x3._input_quantizer._amax.scales', 'base.features.1.expand3x3._input_quantizer._amax', 'base.features.1.expand3x3._weight_quantizer._amax.scales', 'base.features.1.expand3x3._weight_quantizer._amax', 'base.features.2.squeeze.weight', 'base.features.2.squeeze.bias', 'base.features.2.squeeze._input_quantizer._amax.scales', 'base.features.2.squeeze._input_quantizer._amax', 'base.features.2.squeeze._weight_quantizer._amax.scales', 'base.features.2.squeeze._weight_quantizer._amax', 'base.features.2.expand1x1.weight', 'base.features.2.expand1x1.bias', 'base.features.2.expand1x1._input_quantizer._amax.scales', 'base.features.2.expand1x1._input_quantizer._amax', 'base.features.2.expand1x1._weight_quantizer._amax.scales', 'base.features.2.expand1x1._weight_quantizer._amax', 'base.features.2.expand3x3.weight', 'base.features.2.expand3x3.bias', 'base.features.2.expand3x3._input_quantizer._amax.scales', 'base.features.2.expand3x3._input_quantizer._amax', 'base.features.2.expand3x3._weight_quantizer._amax.scales', 'base.features.2.expand3x3._weight_quantizer._amax', 'base.features.4.squeeze.weight', 'base.features.4.squeeze.bias', 'base.features.4.squeeze._input_quantizer._amax.scales', 'base.features.4.squeeze._input_quantizer._amax', 'base.features.4.squeeze._weight_quantizer._amax.scales', 'base.features.4.squeeze._weight_quantizer._amax', 'base.features.4.expand1x1.weight', 'base.features.4.expand1x1.bias', 'base.features.4.expand1x1._input_quantizer._amax.scales', 'base.features.4.expand1x1._input_quantizer._amax', 'base.features.4.expand1x1._weight_quantizer._amax.scales', 'base.features.4.expand1x1._weight_quantizer._amax', 'base.features.4.expand3x3.weight', 'base.features.4.expand3x3.bias', 'base.features.4.expand3x3._input_quantizer._amax.scales', 'base.features.4.expand3x3._input_quantizer._amax', 'base.features.4.expand3x3._weight_quantizer._amax.scales', 'base.features.4.expand3x3._weight_quantizer._amax', 'base.features.5.squeeze.weight', 'base.features.5.squeeze.bias', 'base.features.5.squeeze._input_quantizer._amax.scales', 'base.features.5.squeeze._input_quantizer._amax', 'base.features.5.squeeze._weight_quantizer._amax.scales', 'base.features.5.squeeze._weight_quantizer._amax', 'base.features.5.expand1x1.weight', 'base.features.5.expand1x1.bias', 'base.features.5.expand1x1._input_quantizer._amax.scales', 'base.features.5.expand1x1._input_quantizer._amax', 'base.features.5.expand1x1._weight_quantizer._amax.scales', 'base.features.5.expand1x1._weight_quantizer._amax', 'base.features.5.expand3x3.weight', 'base.features.5.expand3x3.bias', 'base.features.5.expand3x3._input_quantizer._amax.scales', 'base.features.5.expand3x3._input_quantizer._amax', 'base.features.5.expand3x3._weight_quantizer._amax.scales', 'base.features.5.expand3x3._weight_quantizer._amax', 'base.features.7.squeeze.weight', 'base.features.7.squeeze.bias', 'base.features.7.squeeze._input_quantizer._amax.scales', 'base.features.7.squeeze._input_quantizer._amax', 'base.features.7.squeeze._weight_quantizer._amax.scales', 'base.features.7.squeeze._weight_quantizer._amax', 'base.features.7.expand1x1.weight', 'base.features.7.expand1x1.bias', 'base.features.7.expand1x1._input_quantizer._amax.scales', 'base.features.7.expand1x1._input_quantizer._amax', 'base.features.7.expand1x1._weight_quantizer._amax.scales', 'base.features.7.expand1x1._weight_quantizer._amax', 'base.features.7.expand3x3.weight', 'base.features.7.expand3x3.bias', 'base.features.7.expand3x3._input_quantizer._amax.scales', 'base.features.7.expand3x3._input_quantizer._amax', 'base.features.7.expand3x3._weight_quantizer._amax.scales', 'base.features.7.expand3x3._weight_quantizer._amax', 'base.features.8.squeeze.weight', 'base.features.8.squeeze.bias', 'base.features.8.squeeze._input_quantizer._amax.scales', 'base.features.8.squeeze._input_quantizer._amax', 'base.features.8.squeeze._weight_quantizer._amax.scales', 'base.features.8.squeeze._weight_quantizer._amax', 'base.features.8.expand1x1.weight', 'base.features.8.expand1x1.bias', 'base.features.8.expand1x1._input_quantizer._amax.scales', 'base.features.8.expand1x1._input_quantizer._amax', 'base.features.8.expand1x1._weight_quantizer._amax.scales', 'base.features.8.expand1x1._weight_quantizer._amax', 'base.features.8.expand3x3.weight', 'base.features.8.expand3x3.bias', 'base.features.8.expand3x3._input_quantizer._amax.scales', 'base.features.8.expand3x3._input_quantizer._amax', 'base.features.8.expand3x3._weight_quantizer._amax.scales', 'base.features.8.expand3x3._weight_quantizer._amax', 'base.features.9.squeeze.weight', 'base.features.9.squeeze.bias', 'base.features.9.squeeze._input_quantizer._amax.scales', 'base.features.9.squeeze._input_quantizer._amax', 'base.features.9.squeeze._weight_quantizer._amax.scales', 'base.features.9.squeeze._weight_quantizer._amax', 'base.features.9.expand1x1.weight', 'base.features.9.expand1x1.bias', 'base.features.9.expand1x1._input_quantizer._amax.scales', 'base.features.9.expand1x1._input_quantizer._amax', 'base.features.9.expand1x1._weight_quantizer._amax.scales', 'base.features.9.expand1x1._weight_quantizer._amax', 'base.features.9.expand3x3.weight', 'base.features.9.expand3x3.bias', 'base.features.9.expand3x3._input_quantizer._amax.scales', 'base.features.9.expand3x3._input_quantizer._amax', 'base.features.9.expand3x3._weight_quantizer._amax.scales', 'base.features.9.expand3x3._weight_quantizer._amax', 'base.features.10.squeeze.weight', 'base.features.10.squeeze.bias', 'base.features.10.squeeze._input_quantizer._amax.scales', 'base.features.10.squeeze._input_quantizer._amax', 'base.features.10.squeeze._weight_quantizer._amax.scales', 'base.features.10.squeeze._weight_quantizer._amax', 'base.features.10.expand1x1.weight', 'base.features.10.expand1x1.bias', 'base.features.10.expand1x1._input_quantizer._amax.scales', 'base.features.10.expand1x1._input_quantizer._amax', 'base.features.10.expand1x1._weight_quantizer._amax.scales', 'base.features.10.expand1x1._weight_quantizer._amax', 'base.features.10.expand3x3.weight', 'base.features.10.expand3x3.bias', 'base.features.10.expand3x3._input_quantizer._amax.scales', 'base.features.10.expand3x3._input_quantizer._amax', 'base.features.10.expand3x3._weight_quantizer._amax.scales', 'base.features.10.expand3x3._weight_quantizer._amax', 'base.features.11.squeeze.weight', 'base.features.11.squeeze.bias', 'base.features.11.squeeze._input_quantizer._amax.scales', 'base.features.11.squeeze._input_quantizer._amax', 'base.features.11.squeeze._weight_quantizer._amax.scales', 'base.features.11.squeeze._weight_quantizer._amax', 'base.features.11.expand1x1.weight', 'base.features.11.expand1x1.bias', 'base.features.11.expand1x1._input_quantizer._amax.scales', 'base.features.11.expand1x1._input_quantizer._amax', 'base.features.11.expand1x1._weight_quantizer._amax.scales', 'base.features.11.expand1x1._weight_quantizer._amax', 'base.features.11.expand3x3.weight', 'base.features.11.expand3x3.bias', 'base.features.11.expand3x3._input_quantizer._amax.scales', 'base.features.11.expand3x3._input_quantizer._amax', 'base.features.11.expand3x3._weight_quantizer._amax.scales', 'base.features.11.expand3x3._weight_quantizer._amax', 'base.features.12.squeeze.weight', 'base.features.12.squeeze.bias', 'base.features.12.squeeze._input_quantizer._amax.scales', 'base.features.12.squeeze._input_quantizer._amax', 'base.features.12.squeeze._weight_quantizer._amax.scales', 'base.features.12.squeeze._weight_quantizer._amax', 'base.features.12.expand1x1.weight', 'base.features.12.expand1x1.bias', 'base.features.12.expand1x1._input_quantizer._amax.scales', 'base.features.12.expand1x1._input_quantizer._amax', 'base.features.12.expand1x1._weight_quantizer._amax.scales', 'base.features.12.expand1x1._weight_quantizer._amax', 'base.features.12.expand3x3.weight', 'base.features.12.expand3x3.bias', 'base.features.12.expand3x3._input_quantizer._amax.scales', 'base.features.12.expand3x3._input_quantizer._amax', 'base.features.12.expand3x3._weight_quantizer._amax.scales', 'base.features.12.expand3x3._weight_quantizer._amax', 'base.convdet.weight', 'base.convdet.bias', 'base.convdet._input_quantizer._amax.scales', 'base.convdet._input_quantizer._amax', 'base.convdet._weight_quantizer._amax.scales', 'base.convdet._weight_quantizer._amax'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = torch.load(\"../exp/quant_veh_det_squeezedet_model_41_w_scales.pth\")\n",
    "# a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['base.features.0.weight', 'base.features.0.bias', 'base.features.3.squeeze.weight', 'base.features.3.squeeze.bias', 'base.features.3.expand1x1.weight', 'base.features.3.expand1x1.bias', 'base.features.3.expand3x3.weight', 'base.features.3.expand3x3.bias', 'base.features.4.squeeze.weight', 'base.features.4.squeeze.bias', 'base.features.4.expand1x1.weight', 'base.features.4.expand1x1.bias', 'base.features.4.expand3x3.weight', 'base.features.4.expand3x3.bias', 'base.features.6.squeeze.weight', 'base.features.6.squeeze.bias', 'base.features.6.expand1x1.weight', 'base.features.6.expand1x1.bias', 'base.features.6.expand3x3.weight', 'base.features.6.expand3x3.bias', 'base.features.7.squeeze.weight', 'base.features.7.squeeze.bias', 'base.features.7.expand1x1.weight', 'base.features.7.expand1x1.bias', 'base.features.7.expand3x3.weight', 'base.features.7.expand3x3.bias', 'base.features.9.squeeze.weight', 'base.features.9.squeeze.bias', 'base.features.9.expand1x1.weight', 'base.features.9.expand1x1.bias', 'base.features.9.expand3x3.weight', 'base.features.9.expand3x3.bias', 'base.features.10.squeeze.weight', 'base.features.10.squeeze.bias', 'base.features.10.expand1x1.weight', 'base.features.10.expand1x1.bias', 'base.features.10.expand3x3.weight', 'base.features.10.expand3x3.bias', 'base.features.11.squeeze.weight', 'base.features.11.squeeze.bias', 'base.features.11.expand1x1.weight', 'base.features.11.expand1x1.bias', 'base.features.11.expand3x3.weight', 'base.features.11.expand3x3.bias', 'base.features.12.squeeze.weight', 'base.features.12.squeeze.bias', 'base.features.12.expand1x1.weight', 'base.features.12.expand1x1.bias', 'base.features.12.expand3x3.weight', 'base.features.12.expand3x3.bias', 'base.features.13.squeeze.weight', 'base.features.13.squeeze.bias', 'base.features.13.expand1x1.weight', 'base.features.13.expand1x1.bias', 'base.features.13.expand3x3.weight', 'base.features.13.expand3x3.bias', 'base.features.14.squeeze.weight', 'base.features.14.squeeze.bias', 'base.features.14.expand1x1.weight', 'base.features.14.expand1x1.bias', 'base.features.14.expand3x3.weight', 'base.features.14.expand3x3.bias', 'base.convdet.weight', 'base.convdet.bias'])\n"
     ]
    }
   ],
   "source": [
    "c = torch.load('../exp/model_41.pth')\n",
    "print (c['state_dict'].keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ocr-qat-clone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed7a881ff41a78f071bc8310ea2e885dbdfc33c63737541739e546362a580f91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
